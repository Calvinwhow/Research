{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Provide Path to your API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key_path = r'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/openai_key.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - This will accept the .txt file of abstracts generated from a PubMed search and group every result into a CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class AbstractSeparator:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            self.content = file.read()\n",
    "        self.abstracts = []\n",
    "    \n",
    "    def separate_abstracts(self):\n",
    "        \"\"\"Separate the content into individual abstracts based on the described pattern.\"\"\"\n",
    "        abstract_entries = re.finditer(r'\\n(\\d+\\.\\s)', self.content)\n",
    "        start_positions = [match.start() for match in abstract_entries]\n",
    "        \n",
    "        # Create abstract chunks based on the start positions\n",
    "        abstract_chunks = [self.content[start_positions[i]:start_positions[i + 1]].strip() for i in range(len(start_positions) - 1)]\n",
    "        abstract_chunks.append(self.content[start_positions[-1]:].strip())\n",
    "        \n",
    "        self.abstracts = abstract_chunks\n",
    "    \n",
    "    def to_csv(self, output_path):\n",
    "        \"\"\"Save the separated abstracts to a CSV.\"\"\"\n",
    "        df = pd.DataFrame(self.abstracts, columns=[\"Abstract\"])\n",
    "        df.to_csv(output_path, index=False)\n",
    "        \n",
    "    def get_abstracts(self):\n",
    "        \"\"\"Return the list of separated abstracts.\"\"\"\n",
    "        return self.abstracts\n",
    "\n",
    "# Example usage:\n",
    "# separator = AbstractSeparator(\"/path/to/your/textfile.txt\")\n",
    "# separator.separate_abstracts()\n",
    "# separator.to_csv(\"/path/to/save/csvfile.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Only Evaluate Abstracts with Positive Title Hits (from notebook 00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleReviewFilter:\n",
    "    \"\"\"\n",
    "    A class to filter abstracts based on title review results.\n",
    "\n",
    "    Methods:\n",
    "    - load_data: Loads the title review results and abstracts data.\n",
    "    - filter_abstracts: Filters the abstracts based on a specified column from the title review results.\n",
    "    - save_filtered_data: Saves the filtered abstracts to a specified path.\n",
    "    - get_filtered_dataframe: Returns the filtered abstracts dataframe for visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, title_review_path, abstracts_path):\n",
    "        \"\"\"\n",
    "        Initializes the TitleReviewFilter class with paths to the title review results and abstracts CSVs.\n",
    "\n",
    "        Parameters:\n",
    "        - title_review_path (str): Path to the title review results CSV.\n",
    "        - abstracts_path (str): Path to the abstracts CSV.\n",
    "        \"\"\"\n",
    "        self.title_review_path = title_review_path\n",
    "        self.abstracts_path = abstracts_path\n",
    "        self.title_df, self.abstracts_df = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the title review results and abstracts data from CSVs.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame, DataFrame: DataFrames containing the title review results and abstracts.\n",
    "        \"\"\"\n",
    "        title_df = pd.read_csv(self.title_review_path)\n",
    "        abstracts_df = pd.read_csv(self.abstracts_path)\n",
    "        return title_df, abstracts_df\n",
    "\n",
    "    def filter_abstracts(self, column_name):\n",
    "        \"\"\"\n",
    "        Filters the abstracts based on a specified column from the title review results.\n",
    "\n",
    "        Parameters:\n",
    "        - column_name (str): The column name in the title review results to use for filtering.\n",
    "        \"\"\"\n",
    "        # Find the indices of the rows in title review results where the specified column has a value of 1\n",
    "        mask_indices = self.title_df[self.title_df[column_name] == 1].index\n",
    "        # Filter the abstracts dataframe using the mask indices\n",
    "        self.filtered_df = self.abstracts_df.iloc[mask_indices]\n",
    "\n",
    "    def save_filtered_data(self, output_path):\n",
    "        \"\"\"\n",
    "        Saves the filtered abstracts to a specified path.\n",
    "\n",
    "        Parameters:\n",
    "        - output_path (str): Path to save the filtered abstracts CSV.\n",
    "        \"\"\"\n",
    "        if not output_path.endswith('.csv'):\n",
    "            output_path += '.csv'\n",
    "        self.filtered_df.to_csv(output_path, index=False)\n",
    "\n",
    "    def get_filtered_dataframe(self):\n",
    "        \"\"\"\n",
    "        Returns the filtered abstracts dataframe for visualization.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: DataFrame containing the filtered abstracts.\n",
    "        \"\"\"\n",
    "        return self.filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your paths and column name\n",
    "title_review_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/lnm_brain_death/systematic_review/raw/review_results.csv\"\n",
    "abstracts_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/lnm_brain_death/systematic_review/raw/separated_abstracts.csv\"\n",
    "column_name_to_filter = \"Passes Title Screen (Very Sensitive)\"\n",
    "output_path_for_filtered_data = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/lnm_brain_death/systematic_review/sensitive_masked_abstracts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3. Epilepsia. 2021 Jun;62(6):1306-1317. doi: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6. Neurol India. 2022 Mar-Apr;70(2):670-675. d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7. Surg Radiol Anat. 2022 Mar;44(3):443-446. d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10. N Engl J Med. 2008 Mar 27;358(13):1327-35....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14. Arthroscopy. 1999 Apr;15(3):333-7. doi: 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9941</th>\n",
       "      <td>9353. Am Heart J. 1976 Feb;91(2):240-8. doi: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>9376. Pract Radiat Oncol. 2014 Nov-Dec;4(6):40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>9378. Trans R Soc Trop Med Hyg. 2021 Jan 7;115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>9404. Biomech Model Mechanobiol. 2022 Feb;21(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9408. Cancer Manag Res. 2018 Jul 5;10:1901-190...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Abstract\n",
       "1     3. Epilepsia. 2021 Jun;62(6):1306-1317. doi: 1...\n",
       "4     6. Neurol India. 2022 Mar-Apr;70(2):670-675. d...\n",
       "5     7. Surg Radiol Anat. 2022 Mar;44(3):443-446. d...\n",
       "8     10. N Engl J Med. 2008 Mar 27;358(13):1327-35....\n",
       "12    14. Arthroscopy. 1999 Apr;15(3):333-7. doi: 10...\n",
       "...                                                 ...\n",
       "9941  9353. Am Heart J. 1976 Feb;91(2):240-8. doi: 1...\n",
       "9965  9376. Pract Radiat Oncol. 2014 Nov-Dec;4(6):40...\n",
       "9967  9378. Trans R Soc Trop Med Hyg. 2021 Jan 7;115...\n",
       "9994  9404. Biomech Model Mechanobiol. 2022 Feb;21(1...\n",
       "9998  9408. Cancer Manag Res. 2018 Jul 5;10:1901-190...\n",
       "\n",
       "[877 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create an instance of the TitleReviewFilter class\n",
    "title_review_filter = TitleReviewFilter(title_review_path, abstracts_path)\n",
    "\n",
    "# Filter the abstracts based on the specified column\n",
    "title_review_filter.filter_abstracts(column_name_to_filter)\n",
    "\n",
    "# Save the filtered data to a specified path (Optional)\n",
    "title_review_filter.save_filtered_data(output_path_for_filtered_data)\n",
    "\n",
    "# Get the filtered dataframe for visualization (Optional)\n",
    "filtered_df = title_review_filter.get_filtered_dataframe()\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Evaluate Abstracts That Passed Title Screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time \n",
    "import pandas as pd\n",
    "class AbstractEvaluatorDocumented:\n",
    "    \"\"\"\n",
    "    A class to evaluate abstracts from a CSV using the OpenAI API based on a posed question.\n",
    "\n",
    "    Attributes:\n",
    "    - api_key (str): OpenAI API key.\n",
    "    - df (DataFrame): DataFrame containing the abstracts to be evaluated.\n",
    "\n",
    "    Methods:\n",
    "    - read_api_key: Reads the OpenAI API key from a file.\n",
    "    - evaluate_with_openai: Evaluates an abstract based on the posed question using the OpenAI API.\n",
    "    - evaluate_abstracts: Evaluates all abstracts in the DataFrame based on the posed question.\n",
    "    - to_csv: Saves the updated DataFrame with the evaluation results to a CSV file.\n",
    "    - get_dataframe: Returns the updated DataFrame with the evaluation results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key_path, csv_path, organization_id=None):\n",
    "        \"\"\"\n",
    "        Initializes the AbstractEvaluatorDocumented class with the path to the API key and the CSV containing the abstracts.\n",
    "\n",
    "        Parameters:\n",
    "        - api_key_path (str): Path to the file containing the OpenAI API key.\n",
    "        - csv_path (str): Path to the CSV containing the abstracts.\n",
    "        \"\"\"\n",
    "        self.api_key = self.read_api_key(api_key_path)\n",
    "        openai.api_key = self.api_key\n",
    "        self.organization_id = organization_id\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "    \n",
    "    def read_api_key(self, file_path):\n",
    "        \"\"\"\n",
    "        Reads the OpenAI API key from a file.\n",
    "\n",
    "        Parameters:\n",
    "        - file_path (str): Path to the file containing the OpenAI API key.\n",
    "\n",
    "        Returns:\n",
    "        - str: OpenAI API key.\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.readline().strip()\n",
    "    \n",
    "    def evaluate_with_openai(self, abstract, question):\n",
    "        \"\"\"\n",
    "        Evaluates an abstract based on the posed question using the OpenAI API.\n",
    "\n",
    "        Parameters:\n",
    "        - abstract (str): The abstract to be evaluated.\n",
    "        - question (str): The posed question for evaluation.\n",
    "\n",
    "        Returns:\n",
    "        - int: Binary decision (0 or 1) based on the evaluation.\n",
    "        \"\"\"\n",
    "        headers = {}\n",
    "        if self.organization_id:\n",
    "            headers['OpenAI-Organization'] = self.organization_id\n",
    "            \n",
    "        prompt = f\"Abstract: {abstract}\\n{question}\\n\\nResponse (0 for No, 1 for Yes):\"\n",
    "        \n",
    "        retries = 3\n",
    "        for _ in range(retries):\n",
    "            try:\n",
    "                response = openai.Completion.create(\n",
    "                                                    engine=\"davinci\",\n",
    "                                                    prompt=prompt,\n",
    "                                                    max_tokens=10,\n",
    "                                                    headers=headers\n",
    "                                                )\n",
    "                decision_text = response.choices[0].text.strip()\n",
    "                decision = 1 if \"1\" in decision_text else 0\n",
    "                \n",
    "                return decision\n",
    "            except openai.error.OpenAIError as e:\n",
    "                if \"maximum context length\" in str(e):\n",
    "                    return -1\n",
    "                else:\n",
    "                    raise e\n",
    "            except Exception as e:\n",
    "                if _ < retries - 1:  # i.e. not on the last try yet\n",
    "                    time.sleep(2)  # wait for 2 seconds before trying again\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "\n",
    "    def evaluate_abstracts(self, question):\n",
    "        \"\"\"\n",
    "        Evaluates all abstracts in the DataFrame based on the posed question.\n",
    "\n",
    "        Parameters:\n",
    "        - question (str): The posed question for evaluation.\n",
    "        \"\"\"\n",
    "        tqdm.pandas()\n",
    "        self.df[\"Evaluation_Result\"] = self.df[\"Abstract\"].progress_apply(lambda abstract: self.evaluate_with_openai(abstract, question))\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    def to_csv(self, output_path):\n",
    "        \"\"\"\n",
    "        Saves the updated DataFrame with the evaluation results to a CSV file.\n",
    "\n",
    "        Parameters:\n",
    "        - output_path (str): Path to save the CSV file.\n",
    "        \"\"\"\n",
    "        if not output_path.endswith('.csv'):\n",
    "            output_path += '.csv'\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "    \n",
    "    def get_dataframe(self):\n",
    "        \"\"\"\n",
    "        Returns the updated DataFrame with the evaluation results.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: Updated DataFrame containing the evaluation results.\n",
    "        \"\"\"\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_path = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/lnm_brain_death/systematic_review/sensitive_masked_abstracts.csv'\n",
    "question_to_gpt = \"Do you think this paper has at least one case of a focal lesion causing brain death?\"\n",
    "save_path = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/lnm_brain_death/systematic_review/filtered/sensitive_abstract_results.csv'\n",
    "organization_id = 'org-Y2tKyCPFO6tIjtCtOVZ7c9tr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/877 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 877/877 [09:42<00:00,  1.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Evaluation_Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3. Epilepsia. 2021 Jun;62(6):1306-1317. doi: 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6. Neurol India. 2022 Mar-Apr;70(2):670-675. d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7. Surg Radiol Anat. 2022 Mar;44(3):443-446. d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10. N Engl J Med. 2008 Mar 27;358(13):1327-35....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14. Arthroscopy. 1999 Apr;15(3):333-7. doi: 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>9353. Am Heart J. 1976 Feb;91(2):240-8. doi: 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>9376. Pract Radiat Oncol. 2014 Nov-Dec;4(6):40...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>9378. Trans R Soc Trop Med Hyg. 2021 Jan 7;115...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>9404. Biomech Model Mechanobiol. 2022 Feb;21(1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>9408. Cancer Manag Res. 2018 Jul 5;10:1901-190...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Abstract  Evaluation_Result\n",
       "0    3. Epilepsia. 2021 Jun;62(6):1306-1317. doi: 1...                  0\n",
       "1    6. Neurol India. 2022 Mar-Apr;70(2):670-675. d...                  0\n",
       "2    7. Surg Radiol Anat. 2022 Mar;44(3):443-446. d...                  1\n",
       "3    10. N Engl J Med. 2008 Mar 27;358(13):1327-35....                  0\n",
       "4    14. Arthroscopy. 1999 Apr;15(3):333-7. doi: 10...                  1\n",
       "..                                                 ...                ...\n",
       "872  9353. Am Heart J. 1976 Feb;91(2):240-8. doi: 1...                  0\n",
       "873  9376. Pract Radiat Oncol. 2014 Nov-Dec;4(6):40...                  0\n",
       "874  9378. Trans R Soc Trop Med Hyg. 2021 Jan 7;115...                  0\n",
       "875  9404. Biomech Model Mechanobiol. 2022 Feb;21(1...                  0\n",
       "876  9408. Cancer Manag Res. 2018 Jul 5;10:1901-190...                  1\n",
       "\n",
       "[877 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage (commented out for reference):\n",
    "evaluator = AbstractEvaluatorDocumented(openai_key_path, abstracts_path, organization_id)\n",
    "evaluator.evaluate_abstracts(question_to_gpt)\n",
    "results_df = evaluator.get_dataframe()\n",
    "evaluator.to_csv(save_path)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Positive Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 292 positive abstracts.\n"
     ]
    }
   ],
   "source": [
    "print(f'Found {results_df[\"Evaluation_Result\"].sum()} positive abstracts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.to_csv(\"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/lnm_brain_death/systematic_review/screened_abstracts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
