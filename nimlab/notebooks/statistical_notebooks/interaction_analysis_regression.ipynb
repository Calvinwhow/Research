{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will take your regression or classification problem, the y variables (dependent) and x variables (independent) and determine which have what level of contribution to your dataset.\n",
    "## This will allow you to visualize the information context of Xn to Y, and decide what to keep in future analyses, such as development of lienar regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import glob as glob\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Calculate Correlation\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = 'ols_linear_regression/default_analysis'\n",
    "conn_path = r'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/KiTH_Solutions/Research/Clinical Trial/study_metadata/all_performances.xlsx'\n",
    "#----------------------------------------------------------------DONT TOUCH----------------------------------------------------------------\n",
    "out_dir = os.path.join(conn_path.split('.')[0], f'{analysis}')\n",
    "save = True\n",
    "if os.path.exists(out_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pre-prepared Regression Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Randomization_Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cognitive_Status</th>\n",
       "      <th>Question_2</th>\n",
       "      <th>Question_3</th>\n",
       "      <th>Question_4</th>\n",
       "      <th>Question_5</th>\n",
       "      <th>Question_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Visuospatial.1</th>\n",
       "      <th>Subjective_Complaint</th>\n",
       "      <th>Attention_Complaint</th>\n",
       "      <th>Memory_Complaint</th>\n",
       "      <th>Fluency_Complaint</th>\n",
       "      <th>Language_Complaint</th>\n",
       "      <th>Visuospatial_Complaint</th>\n",
       "      <th>Impaired_on_ACE3</th>\n",
       "      <th>iADL_Impaired</th>\n",
       "      <th>ADL_Impaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>MCI</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>patient_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>patient_26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>patient_30</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patient_33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>patient_38</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>patient_40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45</td>\n",
       "      <td>intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>patient_42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>patient_47</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>patient_108</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>patient_109</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>patient_106</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>Intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>patient_110</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>patient_104</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>patient_111</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>MCI</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>patient_112</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83</td>\n",
       "      <td>Intact</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>patient_102</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>MCI</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>patient_114</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>Intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>patient_107</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>patient_1001</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>patient_1002</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>patient_1012</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>patient_1013</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>patient_1014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>patient_1015</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>patient_1016</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>patient_1017</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>patient_1018</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>patient_1019</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>patient_1020</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>patient_1021</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>patient_1003</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>patient_1004</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>patient_1005</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>patient_1006</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>patient_1007</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>patient_1008</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>patient_1009</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>patient_1010</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>patient_1011</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measurement  Cohort  Randomization_Group  Age Cognitive_Status  \\\n",
       "0     patient_11       1                  2.0   48           intact   \n",
       "1     patient_15       1                  1.0   42              MCI   \n",
       "2     patient_17       1                  1.0   35              MCI   \n",
       "3     patient_19       1                  1.0   70              MCI   \n",
       "4     patient_24       1                  2.0   45           intact   \n",
       "5     patient_25       1                  1.0   53              MCI   \n",
       "6     patient_26       1                  1.0   50              MCI   \n",
       "7     patient_30       1                  2.0   33           intact   \n",
       "8     patient_33       1                  2.0   35              MCI   \n",
       "9     patient_38       1                  2.0   26              MCI   \n",
       "10    patient_40       1                  1.0   45           intact   \n",
       "11    patient_42       1                  1.0   40           intact   \n",
       "12    patient_47       1                  1.0   51              MCI   \n",
       "13   patient_108       2                  1.0   31           intact   \n",
       "14   patient_109       2                  1.0   25              MCI   \n",
       "15   patient_106       2                  NaN   39           Intact   \n",
       "16   patient_110       2                  2.0   30           intact   \n",
       "17   patient_104       2                  NaN   63              MCI   \n",
       "18   patient_111       2                  1.0   61              MCI   \n",
       "19   patient_103       2                  NaN   43              MCI   \n",
       "20   patient_112       2                  2.0   83           Intact   \n",
       "21   patient_102       2                  2.0   39              MCI   \n",
       "22   patient_103       2                  NaN   43              MCI   \n",
       "23   patient_114       2                  NaN   33           Intact   \n",
       "24   patient_107       2                  1.0   54              MCI   \n",
       "25  patient_1001       3                  NaN   28           intact   \n",
       "26  patient_1002       3                  NaN   30           intact   \n",
       "27  patient_1012       3                  NaN   30           intact   \n",
       "28  patient_1013       3                  NaN   35           intact   \n",
       "29  patient_1014       3                  NaN   29           intact   \n",
       "30  patient_1015       3                  NaN   37           intact   \n",
       "31  patient_1016       3                  NaN   24           intact   \n",
       "32  patient_1017       3                  NaN   47           intact   \n",
       "33  patient_1018       3                  NaN   49           intact   \n",
       "34  patient_1019       3                  NaN   45           intact   \n",
       "35  patient_1020       3                  NaN   41           intact   \n",
       "36  patient_1021       3                  NaN   33           intact   \n",
       "37  patient_1003       3                  NaN   65           intact   \n",
       "38  patient_1004       3                  NaN   70           intact   \n",
       "39  patient_1005       3                  NaN   82           intact   \n",
       "40  patient_1006       3                  NaN   80           intact   \n",
       "41  patient_1007       3                  NaN   62           intact   \n",
       "42  patient_1008       3                  NaN   52           intact   \n",
       "43  patient_1009       3                  NaN   49              MCI   \n",
       "44  patient_1010       3                  NaN   66              MCI   \n",
       "45  patient_1011       3                  NaN   71           intact   \n",
       "\n",
       "    Question_2  Question_3  Question_4  Question_5  Question_6  ...  \\\n",
       "0           10           3           5           3          13  ...   \n",
       "1           10           3           1           2           6  ...   \n",
       "2           10           3           2           3           5  ...   \n",
       "3            8           3           5           3           7  ...   \n",
       "4            9           3           5           3          11  ...   \n",
       "5           10           3           1           3           7  ...   \n",
       "6           10           3           5           2          12  ...   \n",
       "7           10           3           5           3          10  ...   \n",
       "8           10           3           5           3           8  ...   \n",
       "9            9           3           4           3          10  ...   \n",
       "10           9           3           5           3          10  ...   \n",
       "11          10           3           5           3          10  ...   \n",
       "12           9           3           4           3          14  ...   \n",
       "13          10           3           5           3           8  ...   \n",
       "14          10           3           5           3           9  ...   \n",
       "15           9           3           0           3          11  ...   \n",
       "16          10           3           3           3           9  ...   \n",
       "17          10           3           0           2           6  ...   \n",
       "18           6           3           0           3           4  ...   \n",
       "19           9           3           3           1           0  ...   \n",
       "20           9           2           5           2           4  ...   \n",
       "21           8           2           5           0           4  ...   \n",
       "22           9           3           4           1           6  ...   \n",
       "23          10           3           5           3          11  ...   \n",
       "24          10           3           3           1           5  ...   \n",
       "25          10           3           5           3          14  ...   \n",
       "26          10           3           5           3          13  ...   \n",
       "27           9           3           5           3          14  ...   \n",
       "28          10           3           5           3          14  ...   \n",
       "29          10           3           5           3          14  ...   \n",
       "30          10           3           5           3          14  ...   \n",
       "31          10           3           5           3          14  ...   \n",
       "32          10           3           5           3          14  ...   \n",
       "33          10           3           5           3          14  ...   \n",
       "34          10           2           4           2          13  ...   \n",
       "35          10           3           5           3          14  ...   \n",
       "36          10           3           5           3          14  ...   \n",
       "37          10           1           1           1          13  ...   \n",
       "38          10           3           3           1          13  ...   \n",
       "39          10           1           5           3          12  ...   \n",
       "40          10           0           5           1          12  ...   \n",
       "41          10           1           5           0          13  ...   \n",
       "42          10           1           3           1          13  ...   \n",
       "43          10           0           1           0           8  ...   \n",
       "44          10           1           5           1           7  ...   \n",
       "45          10           1           4           3          14  ...   \n",
       "\n",
       "    Visuospatial.1  Subjective_Complaint  Attention_Complaint  \\\n",
       "0             14.0                  None                  NaN   \n",
       "1             14.0                  None                  NaN   \n",
       "2             12.0                   Yes                  NaN   \n",
       "3             14.0                   Yes                  NaN   \n",
       "4             16.0                   Yes                  NaN   \n",
       "5             14.0                   Yes                  NaN   \n",
       "6              7.0                   Yes                  NaN   \n",
       "7             16.0                   Yes                  Yes   \n",
       "8             14.0                   Yes                  NaN   \n",
       "9             16.0                   Yes                  NaN   \n",
       "10            16.0                   Yes                  NaN   \n",
       "11            16.0                   Yes                  NaN   \n",
       "12            14.0                    No                  NaN   \n",
       "13            16.0                   NaN                  NaN   \n",
       "14            16.0                   NaN                  NaN   \n",
       "15            16.0                   NaN                  NaN   \n",
       "16            16.0                   NaN                  NaN   \n",
       "17            12.0                   NaN                  NaN   \n",
       "18             8.0                   NaN                  NaN   \n",
       "19            15.0                   NaN                  NaN   \n",
       "20            15.0                   NaN                  NaN   \n",
       "21            14.0                   NaN                  NaN   \n",
       "22            15.0                   NaN                  NaN   \n",
       "23            16.0                   NaN                  NaN   \n",
       "24            15.0                   NaN                  NaN   \n",
       "25             NaN                   NaN                  NaN   \n",
       "26             NaN                   NaN                  NaN   \n",
       "27             NaN                   NaN                  NaN   \n",
       "28             NaN                   NaN                  NaN   \n",
       "29             NaN                   NaN                  NaN   \n",
       "30             NaN                   NaN                  NaN   \n",
       "31             NaN                   NaN                  NaN   \n",
       "32             NaN                   NaN                  NaN   \n",
       "33             NaN                   NaN                  NaN   \n",
       "34             NaN                   NaN                  NaN   \n",
       "35             NaN                   NaN                  NaN   \n",
       "36             NaN                   NaN                  NaN   \n",
       "37             NaN                   NaN                  NaN   \n",
       "38             NaN                   NaN                  NaN   \n",
       "39             NaN                   NaN                  NaN   \n",
       "40             NaN                   NaN                  NaN   \n",
       "41             NaN                   NaN                  NaN   \n",
       "42             NaN                   NaN                  NaN   \n",
       "43             NaN                   NaN                  NaN   \n",
       "44             NaN                   NaN                  NaN   \n",
       "45             NaN                   NaN                  NaN   \n",
       "\n",
       "    Memory_Complaint  Fluency_Complaint  Language_Complaint  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                Yes                NaN                 Yes   \n",
       "3                Yes                NaN                 Yes   \n",
       "4                NaN                NaN                 Yes   \n",
       "5                Yes                NaN                 NaN   \n",
       "6                NaN                NaN                 Yes   \n",
       "7                Yes                NaN                 Yes   \n",
       "8                Yes                NaN                 NaN   \n",
       "9                Yes                NaN                 NaN   \n",
       "10               Yes                NaN                 Yes   \n",
       "11               Yes                NaN                 Yes   \n",
       "12               NaN                NaN                 NaN   \n",
       "13               NaN                NaN                 NaN   \n",
       "14               NaN                NaN                 NaN   \n",
       "15               NaN                NaN                 NaN   \n",
       "16               NaN                NaN                 NaN   \n",
       "17               NaN                NaN                 NaN   \n",
       "18               NaN                NaN                 NaN   \n",
       "19               NaN                NaN                 NaN   \n",
       "20               NaN                NaN                 NaN   \n",
       "21               NaN                NaN                 NaN   \n",
       "22               NaN                NaN                 NaN   \n",
       "23               NaN                NaN                 NaN   \n",
       "24               NaN                NaN                 NaN   \n",
       "25               NaN                NaN                 NaN   \n",
       "26               NaN                NaN                 NaN   \n",
       "27               NaN                NaN                 NaN   \n",
       "28               NaN                NaN                 NaN   \n",
       "29               NaN                NaN                 NaN   \n",
       "30               NaN                NaN                 NaN   \n",
       "31               NaN                NaN                 NaN   \n",
       "32               NaN                NaN                 NaN   \n",
       "33               NaN                NaN                 NaN   \n",
       "34               NaN                NaN                 NaN   \n",
       "35               NaN                NaN                 NaN   \n",
       "36               NaN                NaN                 NaN   \n",
       "37               NaN                NaN                 NaN   \n",
       "38               NaN                NaN                 NaN   \n",
       "39               NaN                NaN                 NaN   \n",
       "40               NaN                NaN                 NaN   \n",
       "41               NaN                NaN                 NaN   \n",
       "42               NaN                NaN                 NaN   \n",
       "43               NaN                NaN                 NaN   \n",
       "44               NaN                NaN                 NaN   \n",
       "45               NaN                NaN                 NaN   \n",
       "\n",
       "    Visuospatial_Complaint  Impaired_on_ACE3  iADL_Impaired  ADL_Impaired  \n",
       "0                      NaN                No           None          None  \n",
       "1                      NaN               Yes           None          None  \n",
       "2                      NaN               Yes           None          None  \n",
       "3                      NaN               Yes           None          None  \n",
       "4                      NaN                No           None          None  \n",
       "5                      NaN               Yes           None          None  \n",
       "6                      NaN               Yes           None          None  \n",
       "7                      NaN                No           None          None  \n",
       "8                      NaN               Yes           None          None  \n",
       "9                      NaN               Yes           None          None  \n",
       "10                     NaN                No           None          None  \n",
       "11                     NaN                No           None          None  \n",
       "12                     NaN                No           None          None  \n",
       "13                     NaN               NaN            NaN           NaN  \n",
       "14                     NaN               NaN            NaN           NaN  \n",
       "15                     NaN               NaN            NaN           NaN  \n",
       "16                     NaN               NaN            NaN           NaN  \n",
       "17                     NaN               NaN            NaN           NaN  \n",
       "18                     NaN               NaN            NaN           NaN  \n",
       "19                     NaN               NaN            NaN           NaN  \n",
       "20                     NaN               NaN            NaN           NaN  \n",
       "21                     NaN               NaN            NaN           NaN  \n",
       "22                     NaN               NaN            NaN           NaN  \n",
       "23                     NaN               NaN            NaN           NaN  \n",
       "24                     NaN               NaN            NaN           NaN  \n",
       "25                     NaN               NaN            NaN           NaN  \n",
       "26                     NaN               NaN            NaN           NaN  \n",
       "27                     NaN               NaN            NaN           NaN  \n",
       "28                     NaN               NaN            NaN           NaN  \n",
       "29                     NaN               NaN            NaN           NaN  \n",
       "30                     NaN               NaN            NaN           NaN  \n",
       "31                     NaN               NaN            NaN           NaN  \n",
       "32                     NaN               NaN            NaN           NaN  \n",
       "33                     NaN               NaN            NaN           NaN  \n",
       "34                     NaN               NaN            NaN           NaN  \n",
       "35                     NaN               NaN            NaN           NaN  \n",
       "36                     NaN               NaN            NaN           NaN  \n",
       "37                     NaN               NaN            NaN           NaN  \n",
       "38                     NaN               NaN            NaN           NaN  \n",
       "39                     NaN               NaN            NaN           NaN  \n",
       "40                     NaN               NaN            NaN           NaN  \n",
       "41                     NaN               NaN            NaN           NaN  \n",
       "42                     NaN               NaN            NaN           NaN  \n",
       "43                     NaN               NaN            NaN           NaN  \n",
       "44                     NaN               NaN            NaN           NaN  \n",
       "45                     NaN               NaN            NaN           NaN  \n",
       "\n",
       "[46 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------------user input above----------------------------------------------------------------\n",
    "from calvin_utils.dataframe_utilities import remove_column_spaces\n",
    "if os.path.basename(conn_path).split('.')[1] == 'csv':\n",
    "    data_df = pd.read_csv(conn_path)\n",
    "else:\n",
    "    data_df = pd.read_excel(conn_path, sheet_name=0)\n",
    "data_df = remove_column_spaces(data_df.reset_index(drop=True))\n",
    "display(data_df)\n",
    "# \n",
    "# display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none to pop\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Randomization_Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cognitive_Status</th>\n",
       "      <th>Question_2</th>\n",
       "      <th>Question_3</th>\n",
       "      <th>Question_4</th>\n",
       "      <th>Question_5</th>\n",
       "      <th>Question_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Visuospatial.1</th>\n",
       "      <th>Subjective_Complaint</th>\n",
       "      <th>Attention_Complaint</th>\n",
       "      <th>Memory_Complaint</th>\n",
       "      <th>Fluency_Complaint</th>\n",
       "      <th>Language_Complaint</th>\n",
       "      <th>Visuospatial_Complaint</th>\n",
       "      <th>Impaired_on_ACE3</th>\n",
       "      <th>iADL_Impaired</th>\n",
       "      <th>ADL_Impaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Measurement  Cohort  Randomization_Group  Age Cognitive_Status  Question_2  \\\n",
       "0  patient_11       1                  2.0   48           intact          10   \n",
       "1  patient_15       1                  1.0   42              MCI          10   \n",
       "\n",
       "   Question_3  Question_4  Question_5  Question_6  ...  Visuospatial.1  \\\n",
       "0           3           5           3          13  ...            14.0   \n",
       "1           3           1           2           6  ...            14.0   \n",
       "\n",
       "   Subjective_Complaint  Attention_Complaint  Memory_Complaint  \\\n",
       "0                  None                  NaN               NaN   \n",
       "1                  None                  NaN               NaN   \n",
       "\n",
       "   Fluency_Complaint  Language_Complaint  Visuospatial_Complaint  \\\n",
       "0                NaN                 NaN                     NaN   \n",
       "1                NaN                 NaN                     NaN   \n",
       "\n",
       "   Impaired_on_ACE3  iADL_Impaired  ADL_Impaired  \n",
       "0                No           None          None  \n",
       "1               Yes           None          None  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select specific subgroup\n",
    "# outlier_index = (data_df['percent_change_adascog11'] <= -50)\n",
    "# data_df = data_df.loc[outlier_index, :]\n",
    "\n",
    "#Remove outlier\n",
    "# outlier_index=[11, 47, 48, 49]\n",
    "# data_df = data_df.drop(index=outlier_index)\n",
    "# data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "try:\n",
    "    data_df.pop('Patient_#_CDR,_ADAS')\n",
    "    data_df.pop('Subiculum_CSF_Z_Score')\n",
    "    data_df.pop('Subiculum')\n",
    "    # data_df.pop('temporal')\n",
    "    # data_df.pop('occipital')\n",
    "    # data_df.pop('cerebellar')\n",
    "    # data_df.pop('sbc_wm_zscores')\n",
    "    # data_df.pop('left_hpc_wm_zscores')\n",
    "    # data_df.pop('left_hpc_z_scores')\t\n",
    "    # data_df.pop('zscore_left_hpc_csf')\t\n",
    "    # data_df.pop('sbc_szcore')\n",
    "    data_df.pop('ID')   \n",
    "    data_df.pop('preOP')\n",
    "    data_df.pop('postOP')\n",
    "    data_df.pop('diff. Mattis')\n",
    "    # data_df.pop('Age')\n",
    "    data_df.pop('perc_change_mattis')\n",
    "    data_df.pop('Unnamed: 0')\n",
    "    # data_df.dropna(inplace=True)\n",
    "    # data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "except:\n",
    "    print('none to pop')\n",
    "\n",
    "#move outcomes to start\n",
    "# first_column = data_df.pop('Patient # CDR, ADAS')  # Remove column and store it in a variable\n",
    "# data_df.insert(0, 'perc_improvement', first_column)  # Insert column at the first position\n",
    "\n",
    "\n",
    "data_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the outcome variable\n",
    "outcome_variable =  data_df.pop('%_Change_from_baseline_(ADAS-Cog11)')\n",
    "data_df['outcome'] = outcome_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encode Specific Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Measurement', 'Cohort', 'Randomization_Group', 'Age',\n",
       "       'Cognitive_Status', 'Question_2', 'Question_3', 'Question_4',\n",
       "       'Question_5', 'Question_6', 'Question_7', 'Question_8', 'Question_9',\n",
       "       'Question_10', 'Question_11', 'Question_12', 'Question_13',\n",
       "       'Question_14', 'Question_15', 'Question_16', 'Question_17',\n",
       "       'Question_18', 'Question_19', 'Question_20', 'Total', 'Attention',\n",
       "       'Memory', 'Fluency', 'Language', 'Visuospatial', 'ACE3_Question_2',\n",
       "       'ACE3_Question_3', 'ACE3_Question_4', 'ACE3_Question_5',\n",
       "       'ACE3_Question_6', 'ACE3_Question_7', 'ACE3_Question_8',\n",
       "       'ACE3_Question_9', 'ACE3_Question_10', 'ACE3_Question_11',\n",
       "       'ACE3_Question_12', 'ACE3_Question_13', 'ACE3_Question_14',\n",
       "       'ACE3_Question_15', 'ACE3_Question_16', 'ACE3_Question_17',\n",
       "       'ACE3_Question_18', 'ACE3_Question_19', 'ACE3_Question_20', 'Total.1',\n",
       "       'Attention.1', 'Memory.1', 'Fluency.1', 'Language.1', 'Visuospatial.1',\n",
       "       'Subjective_Complaint', 'Attention_Complaint', 'Memory_Complaint',\n",
       "       'Fluency_Complaint', 'Language_Complaint', 'Visuospatial_Complaint',\n",
       "       'Impaired_on_ACE3', 'iADL_Impaired', 'ADL_Impaired'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Randomization_Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cognitive_Status</th>\n",
       "      <th>Question_2</th>\n",
       "      <th>Question_3</th>\n",
       "      <th>Question_4</th>\n",
       "      <th>Question_5</th>\n",
       "      <th>Question_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Visuospatial.1</th>\n",
       "      <th>Subjective_Complaint</th>\n",
       "      <th>Attention_Complaint</th>\n",
       "      <th>Memory_Complaint</th>\n",
       "      <th>Fluency_Complaint</th>\n",
       "      <th>Language_Complaint</th>\n",
       "      <th>Visuospatial_Complaint</th>\n",
       "      <th>Impaired_on_ACE3</th>\n",
       "      <th>iADL_Impaired</th>\n",
       "      <th>ADL_Impaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>patient_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>patient_26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>patient_30</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patient_33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>patient_38</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>patient_40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>patient_42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>patient_47</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>patient_108</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>patient_109</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>patient_106</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>patient_110</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>patient_104</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>patient_111</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>patient_112</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>patient_102</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>patient_114</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>patient_107</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>patient_1001</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>patient_1002</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>patient_1012</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>patient_1013</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>patient_1014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>patient_1015</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>patient_1016</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>patient_1017</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>patient_1018</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>patient_1019</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>patient_1020</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>patient_1021</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>patient_1003</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>patient_1004</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>patient_1005</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>patient_1006</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>patient_1007</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>patient_1008</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>patient_1009</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>patient_1010</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>patient_1011</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measurement  Cohort  Randomization_Group  Age  Cognitive_Status  \\\n",
       "0     patient_11       1                  2.0   48                 0   \n",
       "1     patient_15       1                  1.0   42                 1   \n",
       "2     patient_17       1                  1.0   35                 1   \n",
       "3     patient_19       1                  1.0   70                 1   \n",
       "4     patient_24       1                  2.0   45                 0   \n",
       "5     patient_25       1                  1.0   53                 1   \n",
       "6     patient_26       1                  1.0   50                 1   \n",
       "7     patient_30       1                  2.0   33                 0   \n",
       "8     patient_33       1                  2.0   35                 1   \n",
       "9     patient_38       1                  2.0   26                 1   \n",
       "10    patient_40       1                  1.0   45                 0   \n",
       "11    patient_42       1                  1.0   40                 0   \n",
       "12    patient_47       1                  1.0   51                 1   \n",
       "13   patient_108       2                  1.0   31                 0   \n",
       "14   patient_109       2                  1.0   25                 1   \n",
       "15   patient_106       2                  NaN   39                 0   \n",
       "16   patient_110       2                  2.0   30                 0   \n",
       "17   patient_104       2                  NaN   63                 1   \n",
       "18   patient_111       2                  1.0   61                 1   \n",
       "19   patient_103       2                  NaN   43                 1   \n",
       "20   patient_112       2                  2.0   83                 0   \n",
       "21   patient_102       2                  2.0   39                 1   \n",
       "22   patient_103       2                  NaN   43                 1   \n",
       "23   patient_114       2                  NaN   33                 0   \n",
       "24   patient_107       2                  1.0   54                 1   \n",
       "25  patient_1001       3                  NaN   28                 0   \n",
       "26  patient_1002       3                  NaN   30                 0   \n",
       "27  patient_1012       3                  NaN   30                 0   \n",
       "28  patient_1013       3                  NaN   35                 0   \n",
       "29  patient_1014       3                  NaN   29                 0   \n",
       "30  patient_1015       3                  NaN   37                 0   \n",
       "31  patient_1016       3                  NaN   24                 0   \n",
       "32  patient_1017       3                  NaN   47                 0   \n",
       "33  patient_1018       3                  NaN   49                 0   \n",
       "34  patient_1019       3                  NaN   45                 0   \n",
       "35  patient_1020       3                  NaN   41                 0   \n",
       "36  patient_1021       3                  NaN   33                 0   \n",
       "37  patient_1003       3                  NaN   65                 0   \n",
       "38  patient_1004       3                  NaN   70                 0   \n",
       "39  patient_1005       3                  NaN   82                 0   \n",
       "40  patient_1006       3                  NaN   80                 0   \n",
       "41  patient_1007       3                  NaN   62                 0   \n",
       "42  patient_1008       3                  NaN   52                 0   \n",
       "43  patient_1009       3                  NaN   49                 1   \n",
       "44  patient_1010       3                  NaN   66                 1   \n",
       "45  patient_1011       3                  NaN   71                 0   \n",
       "\n",
       "    Question_2  Question_3  Question_4  Question_5  Question_6  ...  \\\n",
       "0           10           3           5           3          13  ...   \n",
       "1           10           3           1           2           6  ...   \n",
       "2           10           3           2           3           5  ...   \n",
       "3            8           3           5           3           7  ...   \n",
       "4            9           3           5           3          11  ...   \n",
       "5           10           3           1           3           7  ...   \n",
       "6           10           3           5           2          12  ...   \n",
       "7           10           3           5           3          10  ...   \n",
       "8           10           3           5           3           8  ...   \n",
       "9            9           3           4           3          10  ...   \n",
       "10           9           3           5           3          10  ...   \n",
       "11          10           3           5           3          10  ...   \n",
       "12           9           3           4           3          14  ...   \n",
       "13          10           3           5           3           8  ...   \n",
       "14          10           3           5           3           9  ...   \n",
       "15           9           3           0           3          11  ...   \n",
       "16          10           3           3           3           9  ...   \n",
       "17          10           3           0           2           6  ...   \n",
       "18           6           3           0           3           4  ...   \n",
       "19           9           3           3           1           0  ...   \n",
       "20           9           2           5           2           4  ...   \n",
       "21           8           2           5           0           4  ...   \n",
       "22           9           3           4           1           6  ...   \n",
       "23          10           3           5           3          11  ...   \n",
       "24          10           3           3           1           5  ...   \n",
       "25          10           3           5           3          14  ...   \n",
       "26          10           3           5           3          13  ...   \n",
       "27           9           3           5           3          14  ...   \n",
       "28          10           3           5           3          14  ...   \n",
       "29          10           3           5           3          14  ...   \n",
       "30          10           3           5           3          14  ...   \n",
       "31          10           3           5           3          14  ...   \n",
       "32          10           3           5           3          14  ...   \n",
       "33          10           3           5           3          14  ...   \n",
       "34          10           2           4           2          13  ...   \n",
       "35          10           3           5           3          14  ...   \n",
       "36          10           3           5           3          14  ...   \n",
       "37          10           1           1           1          13  ...   \n",
       "38          10           3           3           1          13  ...   \n",
       "39          10           1           5           3          12  ...   \n",
       "40          10           0           5           1          12  ...   \n",
       "41          10           1           5           0          13  ...   \n",
       "42          10           1           3           1          13  ...   \n",
       "43          10           0           1           0           8  ...   \n",
       "44          10           1           5           1           7  ...   \n",
       "45          10           1           4           3          14  ...   \n",
       "\n",
       "    Visuospatial.1  Subjective_Complaint  Attention_Complaint  \\\n",
       "0             14.0                  None                  NaN   \n",
       "1             14.0                  None                  NaN   \n",
       "2             12.0                   Yes                  NaN   \n",
       "3             14.0                   Yes                  NaN   \n",
       "4             16.0                   Yes                  NaN   \n",
       "5             14.0                   Yes                  NaN   \n",
       "6              7.0                   Yes                  NaN   \n",
       "7             16.0                   Yes                  Yes   \n",
       "8             14.0                   Yes                  NaN   \n",
       "9             16.0                   Yes                  NaN   \n",
       "10            16.0                   Yes                  NaN   \n",
       "11            16.0                   Yes                  NaN   \n",
       "12            14.0                    No                  NaN   \n",
       "13            16.0                   NaN                  NaN   \n",
       "14            16.0                   NaN                  NaN   \n",
       "15            16.0                   NaN                  NaN   \n",
       "16            16.0                   NaN                  NaN   \n",
       "17            12.0                   NaN                  NaN   \n",
       "18             8.0                   NaN                  NaN   \n",
       "19            15.0                   NaN                  NaN   \n",
       "20            15.0                   NaN                  NaN   \n",
       "21            14.0                   NaN                  NaN   \n",
       "22            15.0                   NaN                  NaN   \n",
       "23            16.0                   NaN                  NaN   \n",
       "24            15.0                   NaN                  NaN   \n",
       "25             NaN                   NaN                  NaN   \n",
       "26             NaN                   NaN                  NaN   \n",
       "27             NaN                   NaN                  NaN   \n",
       "28             NaN                   NaN                  NaN   \n",
       "29             NaN                   NaN                  NaN   \n",
       "30             NaN                   NaN                  NaN   \n",
       "31             NaN                   NaN                  NaN   \n",
       "32             NaN                   NaN                  NaN   \n",
       "33             NaN                   NaN                  NaN   \n",
       "34             NaN                   NaN                  NaN   \n",
       "35             NaN                   NaN                  NaN   \n",
       "36             NaN                   NaN                  NaN   \n",
       "37             NaN                   NaN                  NaN   \n",
       "38             NaN                   NaN                  NaN   \n",
       "39             NaN                   NaN                  NaN   \n",
       "40             NaN                   NaN                  NaN   \n",
       "41             NaN                   NaN                  NaN   \n",
       "42             NaN                   NaN                  NaN   \n",
       "43             NaN                   NaN                  NaN   \n",
       "44             NaN                   NaN                  NaN   \n",
       "45             NaN                   NaN                  NaN   \n",
       "\n",
       "    Memory_Complaint  Fluency_Complaint  Language_Complaint  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                Yes                NaN                 Yes   \n",
       "3                Yes                NaN                 Yes   \n",
       "4                NaN                NaN                 Yes   \n",
       "5                Yes                NaN                 NaN   \n",
       "6                NaN                NaN                 Yes   \n",
       "7                Yes                NaN                 Yes   \n",
       "8                Yes                NaN                 NaN   \n",
       "9                Yes                NaN                 NaN   \n",
       "10               Yes                NaN                 Yes   \n",
       "11               Yes                NaN                 Yes   \n",
       "12               NaN                NaN                 NaN   \n",
       "13               NaN                NaN                 NaN   \n",
       "14               NaN                NaN                 NaN   \n",
       "15               NaN                NaN                 NaN   \n",
       "16               NaN                NaN                 NaN   \n",
       "17               NaN                NaN                 NaN   \n",
       "18               NaN                NaN                 NaN   \n",
       "19               NaN                NaN                 NaN   \n",
       "20               NaN                NaN                 NaN   \n",
       "21               NaN                NaN                 NaN   \n",
       "22               NaN                NaN                 NaN   \n",
       "23               NaN                NaN                 NaN   \n",
       "24               NaN                NaN                 NaN   \n",
       "25               NaN                NaN                 NaN   \n",
       "26               NaN                NaN                 NaN   \n",
       "27               NaN                NaN                 NaN   \n",
       "28               NaN                NaN                 NaN   \n",
       "29               NaN                NaN                 NaN   \n",
       "30               NaN                NaN                 NaN   \n",
       "31               NaN                NaN                 NaN   \n",
       "32               NaN                NaN                 NaN   \n",
       "33               NaN                NaN                 NaN   \n",
       "34               NaN                NaN                 NaN   \n",
       "35               NaN                NaN                 NaN   \n",
       "36               NaN                NaN                 NaN   \n",
       "37               NaN                NaN                 NaN   \n",
       "38               NaN                NaN                 NaN   \n",
       "39               NaN                NaN                 NaN   \n",
       "40               NaN                NaN                 NaN   \n",
       "41               NaN                NaN                 NaN   \n",
       "42               NaN                NaN                 NaN   \n",
       "43               NaN                NaN                 NaN   \n",
       "44               NaN                NaN                 NaN   \n",
       "45               NaN                NaN                 NaN   \n",
       "\n",
       "    Visuospatial_Complaint  Impaired_on_ACE3  iADL_Impaired  ADL_Impaired  \n",
       "0                      NaN                No           None          None  \n",
       "1                      NaN               Yes           None          None  \n",
       "2                      NaN               Yes           None          None  \n",
       "3                      NaN               Yes           None          None  \n",
       "4                      NaN                No           None          None  \n",
       "5                      NaN               Yes           None          None  \n",
       "6                      NaN               Yes           None          None  \n",
       "7                      NaN                No           None          None  \n",
       "8                      NaN               Yes           None          None  \n",
       "9                      NaN               Yes           None          None  \n",
       "10                     NaN                No           None          None  \n",
       "11                     NaN                No           None          None  \n",
       "12                     NaN                No           None          None  \n",
       "13                     NaN               NaN            NaN           NaN  \n",
       "14                     NaN               NaN            NaN           NaN  \n",
       "15                     NaN               NaN            NaN           NaN  \n",
       "16                     NaN               NaN            NaN           NaN  \n",
       "17                     NaN               NaN            NaN           NaN  \n",
       "18                     NaN               NaN            NaN           NaN  \n",
       "19                     NaN               NaN            NaN           NaN  \n",
       "20                     NaN               NaN            NaN           NaN  \n",
       "21                     NaN               NaN            NaN           NaN  \n",
       "22                     NaN               NaN            NaN           NaN  \n",
       "23                     NaN               NaN            NaN           NaN  \n",
       "24                     NaN               NaN            NaN           NaN  \n",
       "25                     NaN               NaN            NaN           NaN  \n",
       "26                     NaN               NaN            NaN           NaN  \n",
       "27                     NaN               NaN            NaN           NaN  \n",
       "28                     NaN               NaN            NaN           NaN  \n",
       "29                     NaN               NaN            NaN           NaN  \n",
       "30                     NaN               NaN            NaN           NaN  \n",
       "31                     NaN               NaN            NaN           NaN  \n",
       "32                     NaN               NaN            NaN           NaN  \n",
       "33                     NaN               NaN            NaN           NaN  \n",
       "34                     NaN               NaN            NaN           NaN  \n",
       "35                     NaN               NaN            NaN           NaN  \n",
       "36                     NaN               NaN            NaN           NaN  \n",
       "37                     NaN               NaN            NaN           NaN  \n",
       "38                     NaN               NaN            NaN           NaN  \n",
       "39                     NaN               NaN            NaN           NaN  \n",
       "40                     NaN               NaN            NaN           NaN  \n",
       "41                     NaN               NaN            NaN           NaN  \n",
       "42                     NaN               NaN            NaN           NaN  \n",
       "43                     NaN               NaN            NaN           NaN  \n",
       "44                     NaN               NaN            NaN           NaN  \n",
       "45                     NaN               NaN            NaN           NaN  \n",
       "\n",
       "[46 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode as needed\n",
    "# data_df['interaction'] = data_df['Subiculum_Grey_Matter']*data_df['Subiculum_Connectivity']\n",
    "data_df['Cognitive_Status'] = np.where(data_df['Cognitive_Status'] == 'MCI', 1, 0)\n",
    "# data_df['Age'] = np.where(data_df['Age'] <= 65, 0, 1)\n",
    "\n",
    "data_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Measurement', 'Cohort', 'Randomization_Group', 'Age',\n",
       "       'Cognitive_Status', 'Question_2', 'Question_3', 'Question_4',\n",
       "       'Question_5', 'Question_6', 'Question_7', 'Question_8', 'Question_9',\n",
       "       'Question_10', 'Question_11', 'Question_12', 'Question_13',\n",
       "       'Question_14', 'Question_15', 'Question_16', 'Question_17',\n",
       "       'Question_18', 'Question_19', 'Question_20', 'Total', 'Attention',\n",
       "       'Memory', 'Fluency', 'Language', 'Visuospatial', 'ACE3_Question_2',\n",
       "       'ACE3_Question_3', 'ACE3_Question_4', 'ACE3_Question_5',\n",
       "       'ACE3_Question_6', 'ACE3_Question_7', 'ACE3_Question_8',\n",
       "       'ACE3_Question_9', 'ACE3_Question_10', 'ACE3_Question_11',\n",
       "       'ACE3_Question_12', 'ACE3_Question_13', 'ACE3_Question_14',\n",
       "       'ACE3_Question_15', 'ACE3_Question_16', 'ACE3_Question_17',\n",
       "       'ACE3_Question_18', 'ACE3_Question_19', 'ACE3_Question_20', 'Total.1',\n",
       "       'Attention.1', 'Memory.1', 'Fluency.1', 'Language.1', 'Visuospatial.1',\n",
       "       'Subjective_Complaint', 'Attention_Complaint', 'Memory_Complaint',\n",
       "       'Fluency_Complaint', 'Language_Complaint', 'Visuospatial_Complaint',\n",
       "       'Impaired_on_ACE3', 'iADL_Impaired', 'ADL_Impaired'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Randomization_Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cognitive_Status</th>\n",
       "      <th>Question_2</th>\n",
       "      <th>Question_3</th>\n",
       "      <th>Question_4</th>\n",
       "      <th>Question_5</th>\n",
       "      <th>Question_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Visuospatial.1</th>\n",
       "      <th>Subjective_Complaint</th>\n",
       "      <th>Attention_Complaint</th>\n",
       "      <th>Memory_Complaint</th>\n",
       "      <th>Fluency_Complaint</th>\n",
       "      <th>Language_Complaint</th>\n",
       "      <th>Visuospatial_Complaint</th>\n",
       "      <th>Impaired_on_ACE3</th>\n",
       "      <th>iADL_Impaired</th>\n",
       "      <th>ADL_Impaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_11</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0.091120</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_15</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.289926</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-1.810980</td>\n",
       "      <td>-0.353899</td>\n",
       "      <td>-1.159954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_17</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.734479</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-1.193905</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.981010</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_19</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.488286</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>-2.139367</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.886324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_24</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.099403</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>0.208197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>patient_25</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.408657</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-1.810980</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.886324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>patient_26</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.218135</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>-0.353899</td>\n",
       "      <td>0.481827</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.132349</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>patient_30</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.861494</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.065433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patient_33</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.734479</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.612694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>patient_38</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.306047</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.040244</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.065433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>patient_40</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.099403</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.065433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>patient_42</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.416941</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.065433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>patient_47</td>\n",
       "      <td>-1.394274</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.281642</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.040244</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>patient_108</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.988509</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.612694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>patient_109</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-1.369554</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.339064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>patient_106</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.480449</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-2.428054</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>0.208197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>patient_110</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.052017</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-0.576831</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-0.339064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>patient_104</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.043733</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-2.428054</td>\n",
       "      <td>-0.353899</td>\n",
       "      <td>-1.159954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.981010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>patient_111</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.916718</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>-4.763658</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-2.428054</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>-1.707215</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.702081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.226418</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-0.576831</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>-2.801736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>patient_112</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>2.313884</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>-0.619412</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>-0.353899</td>\n",
       "      <td>-1.707215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>patient_102</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.480449</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>-2.139367</td>\n",
       "      <td>-0.619412</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>-2.388819</td>\n",
       "      <td>-1.707215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.226418</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.040244</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>-1.159954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>patient_114</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.861494</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>0.208197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>patient_107</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.472165</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-0.576831</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>patient_1001</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.179032</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>patient_1002</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.052017</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>patient_1012</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.052017</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>-0.827222</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>patient_1013</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.734479</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>patient_1014</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.115524</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>patient_1015</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.607464</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>patient_1016</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.433062</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>patient_1017</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027612</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>patient_1018</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154627</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>patient_1019</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.099403</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-0.619412</td>\n",
       "      <td>0.040244</td>\n",
       "      <td>-0.353899</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>patient_1020</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.353433</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>patient_1021</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.861494</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>patient_1003</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.170748</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-1.759129</td>\n",
       "      <td>-1.810980</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>patient_1004</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.488286</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>-0.576831</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>patient_1005</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.250377</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-1.759129</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>0.481827</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>patient_1006</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.123362</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-2.898847</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>0.481827</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>patient_1007</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.980225</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-1.759129</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>-2.388819</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>patient_1008</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345150</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-1.759129</td>\n",
       "      <td>-0.576831</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>patient_1009</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154627</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-2.898847</td>\n",
       "      <td>-1.810980</td>\n",
       "      <td>-2.388819</td>\n",
       "      <td>-0.612694</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>patient_1010</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.234256</td>\n",
       "      <td>1.306094</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-1.759129</td>\n",
       "      <td>0.657319</td>\n",
       "      <td>-1.371359</td>\n",
       "      <td>-0.886324</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>patient_1011</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.551794</td>\n",
       "      <td>-0.765641</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>-1.759129</td>\n",
       "      <td>0.040244</td>\n",
       "      <td>0.663561</td>\n",
       "      <td>1.029088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measurement    Cohort  Randomization_Group       Age  Cognitive_Status  \\\n",
       "0     patient_11 -1.394274             1.224745  0.091120         -0.765641   \n",
       "1     patient_15 -1.394274            -0.816497 -0.289926          1.306094   \n",
       "2     patient_17 -1.394274            -0.816497 -0.734479          1.306094   \n",
       "3     patient_19 -1.394274            -0.816497  1.488286          1.306094   \n",
       "4     patient_24 -1.394274             1.224745 -0.099403         -0.765641   \n",
       "5     patient_25 -1.394274            -0.816497  0.408657          1.306094   \n",
       "6     patient_26 -1.394274            -0.816497  0.218135          1.306094   \n",
       "7     patient_30 -1.394274             1.224745 -0.861494         -0.765641   \n",
       "8     patient_33 -1.394274             1.224745 -0.734479          1.306094   \n",
       "9     patient_38 -1.394274             1.224745 -1.306047          1.306094   \n",
       "10    patient_40 -1.394274            -0.816497 -0.099403         -0.765641   \n",
       "11    patient_42 -1.394274            -0.816497 -0.416941         -0.765641   \n",
       "12    patient_47 -1.394274            -0.816497  0.281642          1.306094   \n",
       "13   patient_108 -0.206559            -0.816497 -0.988509         -0.765641   \n",
       "14   patient_109 -0.206559            -0.816497 -1.369554          1.306094   \n",
       "15   patient_106 -0.206559                  NaN -0.480449         -0.765641   \n",
       "16   patient_110 -0.206559             1.224745 -1.052017         -0.765641   \n",
       "17   patient_104 -0.206559                  NaN  1.043733          1.306094   \n",
       "18   patient_111 -0.206559            -0.816497  0.916718          1.306094   \n",
       "19   patient_103 -0.206559                  NaN -0.226418          1.306094   \n",
       "20   patient_112 -0.206559             1.224745  2.313884         -0.765641   \n",
       "21   patient_102 -0.206559             1.224745 -0.480449          1.306094   \n",
       "22   patient_103 -0.206559                  NaN -0.226418          1.306094   \n",
       "23   patient_114 -0.206559                  NaN -0.861494         -0.765641   \n",
       "24   patient_107 -0.206559            -0.816497  0.472165          1.306094   \n",
       "25  patient_1001  0.981156                  NaN -1.179032         -0.765641   \n",
       "26  patient_1002  0.981156                  NaN -1.052017         -0.765641   \n",
       "27  patient_1012  0.981156                  NaN -1.052017         -0.765641   \n",
       "28  patient_1013  0.981156                  NaN -0.734479         -0.765641   \n",
       "29  patient_1014  0.981156                  NaN -1.115524         -0.765641   \n",
       "30  patient_1015  0.981156                  NaN -0.607464         -0.765641   \n",
       "31  patient_1016  0.981156                  NaN -1.433062         -0.765641   \n",
       "32  patient_1017  0.981156                  NaN  0.027612         -0.765641   \n",
       "33  patient_1018  0.981156                  NaN  0.154627         -0.765641   \n",
       "34  patient_1019  0.981156                  NaN -0.099403         -0.765641   \n",
       "35  patient_1020  0.981156                  NaN -0.353433         -0.765641   \n",
       "36  patient_1021  0.981156                  NaN -0.861494         -0.765641   \n",
       "37  patient_1003  0.981156                  NaN  1.170748         -0.765641   \n",
       "38  patient_1004  0.981156                  NaN  1.488286         -0.765641   \n",
       "39  patient_1005  0.981156                  NaN  2.250377         -0.765641   \n",
       "40  patient_1006  0.981156                  NaN  2.123362         -0.765641   \n",
       "41  patient_1007  0.981156                  NaN  0.980225         -0.765641   \n",
       "42  patient_1008  0.981156                  NaN  0.345150         -0.765641   \n",
       "43  patient_1009  0.981156                  NaN  0.154627          1.306094   \n",
       "44  patient_1010  0.981156                  NaN  1.234256          1.306094   \n",
       "45  patient_1011  0.981156                  NaN  1.551794         -0.765641   \n",
       "\n",
       "    Question_2  Question_3  Question_4  Question_5  Question_6  ...  \\\n",
       "0     0.484923    0.520306    0.657319    0.663561    0.755457  ...   \n",
       "1     0.484923    0.520306   -1.810980   -0.353899   -1.159954  ...   \n",
       "2     0.484923    0.520306   -1.193905    0.663561   -1.433584  ...   \n",
       "3    -2.139367    0.520306    0.657319    0.663561   -0.886324  ...   \n",
       "4    -0.827222    0.520306    0.657319    0.663561    0.208197  ...   \n",
       "5     0.484923    0.520306   -1.810980    0.663561   -0.886324  ...   \n",
       "6     0.484923    0.520306    0.657319   -0.353899    0.481827  ...   \n",
       "7     0.484923    0.520306    0.657319    0.663561   -0.065433  ...   \n",
       "8     0.484923    0.520306    0.657319    0.663561   -0.612694  ...   \n",
       "9    -0.827222    0.520306    0.040244    0.663561   -0.065433  ...   \n",
       "10   -0.827222    0.520306    0.657319    0.663561   -0.065433  ...   \n",
       "11    0.484923    0.520306    0.657319    0.663561   -0.065433  ...   \n",
       "12   -0.827222    0.520306    0.040244    0.663561    1.029088  ...   \n",
       "13    0.484923    0.520306    0.657319    0.663561   -0.612694  ...   \n",
       "14    0.484923    0.520306    0.657319    0.663561   -0.339064  ...   \n",
       "15   -0.827222    0.520306   -2.428054    0.663561    0.208197  ...   \n",
       "16    0.484923    0.520306   -0.576831    0.663561   -0.339064  ...   \n",
       "17    0.484923    0.520306   -2.428054   -0.353899   -1.159954  ...   \n",
       "18   -4.763658    0.520306   -2.428054    0.663561   -1.707215  ...   \n",
       "19   -0.827222    0.520306   -0.576831   -1.371359   -2.801736  ...   \n",
       "20   -0.827222   -0.619412    0.657319   -0.353899   -1.707215  ...   \n",
       "21   -2.139367   -0.619412    0.657319   -2.388819   -1.707215  ...   \n",
       "22   -0.827222    0.520306    0.040244   -1.371359   -1.159954  ...   \n",
       "23    0.484923    0.520306    0.657319    0.663561    0.208197  ...   \n",
       "24    0.484923    0.520306   -0.576831   -1.371359   -1.433584  ...   \n",
       "25    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "26    0.484923    0.520306    0.657319    0.663561    0.755457  ...   \n",
       "27   -0.827222    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "28    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "29    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "30    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "31    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "32    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "33    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "34    0.484923   -0.619412    0.040244   -0.353899    0.755457  ...   \n",
       "35    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "36    0.484923    0.520306    0.657319    0.663561    1.029088  ...   \n",
       "37    0.484923   -1.759129   -1.810980   -1.371359    0.755457  ...   \n",
       "38    0.484923    0.520306   -0.576831   -1.371359    0.755457  ...   \n",
       "39    0.484923   -1.759129    0.657319    0.663561    0.481827  ...   \n",
       "40    0.484923   -2.898847    0.657319   -1.371359    0.481827  ...   \n",
       "41    0.484923   -1.759129    0.657319   -2.388819    0.755457  ...   \n",
       "42    0.484923   -1.759129   -0.576831   -1.371359    0.755457  ...   \n",
       "43    0.484923   -2.898847   -1.810980   -2.388819   -0.612694  ...   \n",
       "44    0.484923   -1.759129    0.657319   -1.371359   -0.886324  ...   \n",
       "45    0.484923   -1.759129    0.040244    0.663561    1.029088  ...   \n",
       "\n",
       "    Visuospatial.1  Subjective_Complaint  Attention_Complaint  \\\n",
       "0        -0.120475                  None                  NaN   \n",
       "1        -0.120475                  None                  NaN   \n",
       "2        -0.981010                   Yes                  NaN   \n",
       "3        -0.120475                   Yes                  NaN   \n",
       "4         0.740061                   Yes                  NaN   \n",
       "5        -0.120475                   Yes                  NaN   \n",
       "6        -3.132349                   Yes                  NaN   \n",
       "7         0.740061                   Yes                  Yes   \n",
       "8        -0.120475                   Yes                  NaN   \n",
       "9         0.740061                   Yes                  NaN   \n",
       "10        0.740061                   Yes                  NaN   \n",
       "11        0.740061                   Yes                  NaN   \n",
       "12       -0.120475                    No                  NaN   \n",
       "13        0.740061                   NaN                  NaN   \n",
       "14        0.740061                   NaN                  NaN   \n",
       "15        0.740061                   NaN                  NaN   \n",
       "16        0.740061                   NaN                  NaN   \n",
       "17       -0.981010                   NaN                  NaN   \n",
       "18       -2.702081                   NaN                  NaN   \n",
       "19        0.309793                   NaN                  NaN   \n",
       "20        0.309793                   NaN                  NaN   \n",
       "21       -0.120475                   NaN                  NaN   \n",
       "22        0.309793                   NaN                  NaN   \n",
       "23        0.740061                   NaN                  NaN   \n",
       "24        0.309793                   NaN                  NaN   \n",
       "25             NaN                   NaN                  NaN   \n",
       "26             NaN                   NaN                  NaN   \n",
       "27             NaN                   NaN                  NaN   \n",
       "28             NaN                   NaN                  NaN   \n",
       "29             NaN                   NaN                  NaN   \n",
       "30             NaN                   NaN                  NaN   \n",
       "31             NaN                   NaN                  NaN   \n",
       "32             NaN                   NaN                  NaN   \n",
       "33             NaN                   NaN                  NaN   \n",
       "34             NaN                   NaN                  NaN   \n",
       "35             NaN                   NaN                  NaN   \n",
       "36             NaN                   NaN                  NaN   \n",
       "37             NaN                   NaN                  NaN   \n",
       "38             NaN                   NaN                  NaN   \n",
       "39             NaN                   NaN                  NaN   \n",
       "40             NaN                   NaN                  NaN   \n",
       "41             NaN                   NaN                  NaN   \n",
       "42             NaN                   NaN                  NaN   \n",
       "43             NaN                   NaN                  NaN   \n",
       "44             NaN                   NaN                  NaN   \n",
       "45             NaN                   NaN                  NaN   \n",
       "\n",
       "    Memory_Complaint  Fluency_Complaint  Language_Complaint  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                Yes                NaN                 Yes   \n",
       "3                Yes                NaN                 Yes   \n",
       "4                NaN                NaN                 Yes   \n",
       "5                Yes                NaN                 NaN   \n",
       "6                NaN                NaN                 Yes   \n",
       "7                Yes                NaN                 Yes   \n",
       "8                Yes                NaN                 NaN   \n",
       "9                Yes                NaN                 NaN   \n",
       "10               Yes                NaN                 Yes   \n",
       "11               Yes                NaN                 Yes   \n",
       "12               NaN                NaN                 NaN   \n",
       "13               NaN                NaN                 NaN   \n",
       "14               NaN                NaN                 NaN   \n",
       "15               NaN                NaN                 NaN   \n",
       "16               NaN                NaN                 NaN   \n",
       "17               NaN                NaN                 NaN   \n",
       "18               NaN                NaN                 NaN   \n",
       "19               NaN                NaN                 NaN   \n",
       "20               NaN                NaN                 NaN   \n",
       "21               NaN                NaN                 NaN   \n",
       "22               NaN                NaN                 NaN   \n",
       "23               NaN                NaN                 NaN   \n",
       "24               NaN                NaN                 NaN   \n",
       "25               NaN                NaN                 NaN   \n",
       "26               NaN                NaN                 NaN   \n",
       "27               NaN                NaN                 NaN   \n",
       "28               NaN                NaN                 NaN   \n",
       "29               NaN                NaN                 NaN   \n",
       "30               NaN                NaN                 NaN   \n",
       "31               NaN                NaN                 NaN   \n",
       "32               NaN                NaN                 NaN   \n",
       "33               NaN                NaN                 NaN   \n",
       "34               NaN                NaN                 NaN   \n",
       "35               NaN                NaN                 NaN   \n",
       "36               NaN                NaN                 NaN   \n",
       "37               NaN                NaN                 NaN   \n",
       "38               NaN                NaN                 NaN   \n",
       "39               NaN                NaN                 NaN   \n",
       "40               NaN                NaN                 NaN   \n",
       "41               NaN                NaN                 NaN   \n",
       "42               NaN                NaN                 NaN   \n",
       "43               NaN                NaN                 NaN   \n",
       "44               NaN                NaN                 NaN   \n",
       "45               NaN                NaN                 NaN   \n",
       "\n",
       "    Visuospatial_Complaint  Impaired_on_ACE3  iADL_Impaired  ADL_Impaired  \n",
       "0                      NaN                No           None          None  \n",
       "1                      NaN               Yes           None          None  \n",
       "2                      NaN               Yes           None          None  \n",
       "3                      NaN               Yes           None          None  \n",
       "4                      NaN                No           None          None  \n",
       "5                      NaN               Yes           None          None  \n",
       "6                      NaN               Yes           None          None  \n",
       "7                      NaN                No           None          None  \n",
       "8                      NaN               Yes           None          None  \n",
       "9                      NaN               Yes           None          None  \n",
       "10                     NaN                No           None          None  \n",
       "11                     NaN                No           None          None  \n",
       "12                     NaN                No           None          None  \n",
       "13                     NaN               NaN            NaN           NaN  \n",
       "14                     NaN               NaN            NaN           NaN  \n",
       "15                     NaN               NaN            NaN           NaN  \n",
       "16                     NaN               NaN            NaN           NaN  \n",
       "17                     NaN               NaN            NaN           NaN  \n",
       "18                     NaN               NaN            NaN           NaN  \n",
       "19                     NaN               NaN            NaN           NaN  \n",
       "20                     NaN               NaN            NaN           NaN  \n",
       "21                     NaN               NaN            NaN           NaN  \n",
       "22                     NaN               NaN            NaN           NaN  \n",
       "23                     NaN               NaN            NaN           NaN  \n",
       "24                     NaN               NaN            NaN           NaN  \n",
       "25                     NaN               NaN            NaN           NaN  \n",
       "26                     NaN               NaN            NaN           NaN  \n",
       "27                     NaN               NaN            NaN           NaN  \n",
       "28                     NaN               NaN            NaN           NaN  \n",
       "29                     NaN               NaN            NaN           NaN  \n",
       "30                     NaN               NaN            NaN           NaN  \n",
       "31                     NaN               NaN            NaN           NaN  \n",
       "32                     NaN               NaN            NaN           NaN  \n",
       "33                     NaN               NaN            NaN           NaN  \n",
       "34                     NaN               NaN            NaN           NaN  \n",
       "35                     NaN               NaN            NaN           NaN  \n",
       "36                     NaN               NaN            NaN           NaN  \n",
       "37                     NaN               NaN            NaN           NaN  \n",
       "38                     NaN               NaN            NaN           NaN  \n",
       "39                     NaN               NaN            NaN           NaN  \n",
       "40                     NaN               NaN            NaN           NaN  \n",
       "41                     NaN               NaN            NaN           NaN  \n",
       "42                     NaN               NaN            NaN           NaN  \n",
       "43                     NaN               NaN            NaN           NaN  \n",
       "44                     NaN               NaN            NaN           NaN  \n",
       "45                     NaN               NaN            NaN           NaN  \n",
       "\n",
       "[46 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardize the data\n",
    "preserved_df = data_df.copy()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Measurement', 'Subjective_Complaint', 'Attention_Complaint', 'Memory_Complaint',\n",
    "       'Fluency_Complaint', 'Language_Complaint', 'Visuospatial_Complaint',\n",
    "       'Impaired_on_ACE3', 'iADL_Impaired', 'ADL_Impaired']\n",
    "# Select the columns to be standardized\n",
    "try:\n",
    "    cols_to_standardize = [col for col in data_df.columns if col not in cols_not_to_standardize]\n",
    "except:\n",
    "    print('No columns to standardize')\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "data_df[cols_to_standardize] = scaler.fit_transform(data_df[cols_to_standardize])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Drop NAN\n",
    "# data_df = data_df.dropna()\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate DF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop a specific set of rows\n",
    "# data_df = data_df[data_df['Disease'] == 1]\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tailor the Dataframe\n",
    "data_df = data_df.loc[:, ['Age','Mesial_Temporal_Grade','Subiculum_Connectivity', 'outcome']]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over = data_df['basline'] >= np.mean(data_df['basline'])\n",
    "# under = data_df['basline'] < np.mean(data_df['basline'])\n",
    "# data_df['basline'][over] = 1\n",
    "# data_df['basline'][under] = 0\n",
    "\n",
    "# display(data_df)\n",
    "# print(np.max(data_df.age))\n",
    "mc_test = data_df.copy()\n",
    "mc_test.pop('outcome')\n",
    "# mc_test = mc_test.loc[:, ['Ventral_Attention', 'Limbic']]\n",
    "# mc_test['interaction'] = mc_test['Limbic']*mc_test['Ventral_Attention']\n",
    "from calvin_utils.statistical_measurements import calculate_vif\n",
    "calculate_vif(mc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## GET INFORMATION ABOUT THE DATA\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[39m.\u001b[39;49mpairplot(data_df)\n\u001b[1;32m      3\u001b[0m data_df\u001b[39m.\u001b[39mdescribe()\u001b[39m.\u001b[39mtranspose()\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/seaborn/axisgrid.py:2114\u001b[0m, in \u001b[0;36mpairplot\u001b[0;34m(data, hue, hue_order, palette, vars, x_vars, y_vars, kind, diag_kind, markers, height, aspect, corner, dropna, plot_kws, diag_kws, grid_kws, size)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[39m# Set up the PairGrid\u001b[39;00m\n\u001b[1;32m   2113\u001b[0m grid_kws\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mdiag_sharey\u001b[39m\u001b[39m\"\u001b[39m, diag_kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2114\u001b[0m grid \u001b[39m=\u001b[39m PairGrid(data, \u001b[39mvars\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mvars\u001b[39;49m, x_vars\u001b[39m=\u001b[39;49mx_vars, y_vars\u001b[39m=\u001b[39;49my_vars, hue\u001b[39m=\u001b[39;49mhue,\n\u001b[1;32m   2115\u001b[0m                 hue_order\u001b[39m=\u001b[39;49mhue_order, palette\u001b[39m=\u001b[39;49mpalette, corner\u001b[39m=\u001b[39;49mcorner,\n\u001b[1;32m   2116\u001b[0m                 height\u001b[39m=\u001b[39;49mheight, aspect\u001b[39m=\u001b[39;49maspect, dropna\u001b[39m=\u001b[39;49mdropna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgrid_kws)\n\u001b[1;32m   2118\u001b[0m \u001b[39m# Add the markers here as PairGrid has figured out how many levels of the\u001b[39;00m\n\u001b[1;32m   2119\u001b[0m \u001b[39m# hue variable are needed and we don't want to duplicate that process\u001b[39;00m\n\u001b[1;32m   2120\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/seaborn/axisgrid.py:1348\u001b[0m, in \u001b[0;36mPairGrid.__init__\u001b[0;34m(self, data, hue, vars, x_vars, y_vars, hue_order, palette, hue_kws, corner, diag_sharey, height, aspect, layout_pad, despine, dropna)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 1348\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m ax\u001b[39m.\u001b[39;49mget_yticklabels():\n\u001b[1;32m   1349\u001b[0m     label\u001b[39m.\u001b[39mset_visible(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1350\u001b[0m ax\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39moffsetText\u001b[39m.\u001b[39mset_visible(\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axes/_base.py:73\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m get_method(\u001b[39mself\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axis.py:1388\u001b[0m, in \u001b[0;36mAxis.get_ticklabels\u001b[0;34m(self, minor, which)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mif\u001b[39;00m minor:\n\u001b[1;32m   1387\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_minorticklabels()\n\u001b[0;32m-> 1388\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_majorticklabels()\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axis.py:1345\u001b[0m, in \u001b[0;36mAxis.get_majorticklabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_majorticklabels\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1344\u001b[0m     \u001b[39m\"\"\"Return this Axis' major tick labels, as a list of `~.text.Text`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_ticks()\n\u001b[1;32m   1346\u001b[0m     ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_major_ticks()\n\u001b[1;32m   1347\u001b[0m     labels1 \u001b[39m=\u001b[39m [tick\u001b[39m.\u001b[39mlabel1 \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()]\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axis.py:1198\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     tick\u001b[39m.\u001b[39mset_label1(label)\n\u001b[1;32m   1197\u001b[0m     tick\u001b[39m.\u001b[39mset_label2(label)\n\u001b[0;32m-> 1198\u001b[0m minor_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_minorticklocs()\n\u001b[1;32m   1199\u001b[0m minor_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminor\u001b[39m.\u001b[39mformatter\u001b[39m.\u001b[39mformat_ticks(minor_locs)\n\u001b[1;32m   1200\u001b[0m minor_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_minor_ticks(\u001b[39mlen\u001b[39m(minor_locs))\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axis.py:1423\u001b[0m, in \u001b[0;36mAxis.get_minorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m minor_locs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminor\u001b[39m.\u001b[39mlocator())\n\u001b[1;32m   1422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_overlapping_locs:\n\u001b[0;32m-> 1423\u001b[0m     major_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmajor\u001b[39m.\u001b[39;49mlocator()\n\u001b[1;32m   1424\u001b[0m     transform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scale\u001b[39m.\u001b[39mget_transform()\n\u001b[1;32m   1425\u001b[0m     tr_minor_locs \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(minor_locs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/ticker.py:2142\u001b[0m, in \u001b[0;36mMaxNLocator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 2142\u001b[0m     vmin, vmax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis\u001b[39m.\u001b[39;49mget_view_interval()\n\u001b[1;32m   2143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick_values(vmin, vmax)\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axis.py:2162\u001b[0m, in \u001b[0;36m_make_getset_interval.<locals>.getter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2161\u001b[0m     \u001b[39m# docstring inherited.\u001b[39;00m\n\u001b[0;32m-> 2162\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes, lim_name), attr_name)\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axes/_base.py:815\u001b[0m, in \u001b[0;36m_AxesBase.viewLim\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    814\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mviewLim\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unstale_viewLim()\n\u001b[1;32m    816\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_viewLim\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axes/_base.py:802\u001b[0m, in \u001b[0;36m_AxesBase._unstale_viewLim\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unstale_viewLim\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    800\u001b[0m     \u001b[39m# We should arrange to store this information once per share-group\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39m# instead of on every axis.\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m     need_scale \u001b[39m=\u001b[39m {\n\u001b[1;32m    803\u001b[0m         name: \u001b[39many\u001b[39m(ax\u001b[39m.\u001b[39m_stale_viewlims[name]\n\u001b[1;32m    804\u001b[0m                   \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shared_axes[name]\u001b[39m.\u001b[39mget_siblings(\u001b[39mself\u001b[39m))\n\u001b[1;32m    805\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_axis_names}\n\u001b[1;32m    806\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(need_scale\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    807\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m need_scale:\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/axes/_base.py:804\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unstale_viewLim\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    800\u001b[0m     \u001b[39m# We should arrange to store this information once per share-group\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39m# instead of on every axis.\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     need_scale \u001b[39m=\u001b[39m {\n\u001b[1;32m    803\u001b[0m         name: \u001b[39many\u001b[39m(ax\u001b[39m.\u001b[39m_stale_viewlims[name]\n\u001b[0;32m--> 804\u001b[0m                   \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shared_axes[name]\u001b[39m.\u001b[39;49mget_siblings(\u001b[39mself\u001b[39;49m))\n\u001b[1;32m    805\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_axis_names}\n\u001b[1;32m    806\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(need_scale\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    807\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m need_scale:\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:916\u001b[0m, in \u001b[0;36mGrouper.get_siblings\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_siblings\u001b[39m(\u001b[39mself\u001b[39m, a):\n\u001b[1;32m    915\u001b[0m     \u001b[39m\"\"\"Return all of the items joined with *a*, including itself.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclean()\n\u001b[1;32m    917\u001b[0m     siblings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping\u001b[39m.\u001b[39mget(weakref\u001b[39m.\u001b[39mref(a), [weakref\u001b[39m.\u001b[39mref(a)])\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m [x() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m siblings]\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:868\u001b[0m, in \u001b[0;36mGrouper.clean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[39m\"\"\"Clean dead weak references from the dictionary.\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m mapping \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping\n\u001b[0;32m--> 868\u001b[0m to_drop \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m mapping \u001b[39mif\u001b[39;00m key() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    869\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m to_drop:\n\u001b[1;32m    870\u001b[0m     val \u001b[39m=\u001b[39m mapping\u001b[39m.\u001b[39mpop(key)\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:868\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[39m\"\"\"Clean dead weak references from the dictionary.\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m mapping \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping\n\u001b[0;32m--> 868\u001b[0m to_drop \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m mapping \u001b[39mif\u001b[39;00m key() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    869\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m to_drop:\n\u001b[1;32m    870\u001b[0m     val \u001b[39m=\u001b[39m mapping\u001b[39m.\u001b[39mpop(key)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## GET INFORMATION ABOUT THE DATA\n",
    "# sns.pairplot(data_df)\n",
    "data_df.describe().transpose()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Statsmodel Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Measurement', 'Cohort', 'Randomization_Group', 'Age',\n",
      "       'Cognitive_Status', 'Question_2', 'Question_3', 'Question_4',\n",
      "       'Question_5', 'Question_6', 'Question_7', 'Question_8', 'Question_9',\n",
      "       'Question_10', 'Question_11', 'Question_12', 'Question_13',\n",
      "       'Question_14', 'Question_15', 'Question_16', 'Question_17',\n",
      "       'Question_18', 'Question_19', 'Question_20', 'Total', 'Attention',\n",
      "       'Memory', 'Fluency', 'Language', 'Visuospatial', 'ACE3_Question_2',\n",
      "       'ACE3_Question_3', 'ACE3_Question_4', 'ACE3_Question_5',\n",
      "       'ACE3_Question_6', 'ACE3_Question_7', 'ACE3_Question_8',\n",
      "       'ACE3_Question_9', 'ACE3_Question_10', 'ACE3_Question_11',\n",
      "       'ACE3_Question_12', 'ACE3_Question_13', 'ACE3_Question_14',\n",
      "       'ACE3_Question_15', 'ACE3_Question_16', 'ACE3_Question_17',\n",
      "       'ACE3_Question_18', 'ACE3_Question_19', 'ACE3_Question_20', 'Total.1',\n",
      "       'Attention.1', 'Memory.1', 'Fluency.1', 'Language.1', 'Visuospatial.1',\n",
      "       'Subjective_Complaint', 'Attention_Complaint', 'Memory_Complaint',\n",
      "       'Fluency_Complaint', 'Language_Complaint', 'Visuospatial_Complaint',\n",
      "       'Impaired_on_ACE3', 'iADL_Impaired', 'ADL_Impaired'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Results: Ordinary least squares\n",
      "=================================================================\n",
      "Model:              OLS              Adj. R-squared:     -0.011  \n",
      "Dependent Variable: Question_16      AIC:                134.0040\n",
      "Date:               2023-07-15 22:16 BIC:                137.6613\n",
      "No. Observations:   46               Log-Likelihood:     -65.002 \n",
      "Df Model:           1                F-statistic:        0.5180  \n",
      "Df Residuals:       44               Prob (F-statistic): 0.476   \n",
      "R-squared:          0.012            Scale:              1.0333  \n",
      "------------------------------------------------------------------\n",
      "                Coef.   Std.Err.     t     P>|t|    [0.025  0.975]\n",
      "------------------------------------------------------------------\n",
      "Intercept      -0.0000    0.1499  -0.0000  1.0000  -0.3021  0.3021\n",
      "Age             0.1079    0.1499   0.7197  0.4755  -0.1942  0.4099\n",
      "-----------------------------------------------------------------\n",
      "Omnibus:               5.014        Durbin-Watson:          1.268\n",
      "Prob(Omnibus):         0.082        Jarque-Bera (JB):       2.218\n",
      "Skew:                  -0.203       Prob(JB):               0.330\n",
      "Kurtosis:              2.004        Condition No.:          1    \n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = 'Question_16~Age'\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "results = smf.ols(formula, data=data_df).fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#-----------------------------------------------------------------------------DO NOT TOUCH THIS!----------------------------------------------------------------\n",
    "# Assuming data_df is already defined\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(data_df)\n",
    "\n",
    "models = []\n",
    "squared_error_list = []\n",
    "predictions = []\n",
    "actual_values = []\n",
    "\n",
    "for train_index, test_index in loo.split(data_df):\n",
    "    train_data, test_data = data_df.iloc[train_index], data_df.iloc[test_index]\n",
    "\n",
    "    model = smf.ols(f'{formula.split(\" ~ \")[0]}'' ~ 'f'{formula.split(\" ~ \")[1]}', data=train_data).fit()\n",
    "    models.append(model)\n",
    "\n",
    "    test_x = test_data.drop(columns=[f'{formula.split(\" ~ \")[0]}'])\n",
    "    test_y = test_data[f'{formula.split(\" ~ \")[0]}']\n",
    "    pred_y = model.predict(test_x)\n",
    "\n",
    "    squared_error = np.square(pred_y - test_y)\n",
    "    squared_error_list.extend(squared_error)\n",
    "\n",
    "    predictions.extend(pred_y)\n",
    "    actual_values.extend(test_y)\n",
    "\n",
    "average_squared_error = np.mean(squared_error_list)\n",
    "average_rmse = np.sqrt(average_squared_error)\n",
    "correlation, _ = pearsonr(predictions, actual_values)\n",
    "\n",
    "print(f\"LOOCV - Average Root Mean Squared Error: {average_rmse}\")\n",
    "print(f\"Pearson Correlation Coefficient: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "def structural_coefficients(model: statsmodels.regression.linear_model.RegressionResultsWrapper, \n",
    "                            data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the structural coefficients of a linear regression model, along with their \n",
    "    associated model coefficients (beta weights). It also computes a 'suppressor index' which indicates \n",
    "    the likelihood of a variable being a suppressor variable (high beta weight, near-zero structural coefficient).\n",
    "    A suppressor index over 10 is a good heuristic for identifying a suppressor variable\n",
    "    \n",
    "    Parameters:\n",
    "    model (statsmodels.regression.linear_model.RegressionResultsWrapper): The fitted linear regression model.\n",
    "    data (pd.DataFrame): The dataset used in the model.\n",
    "    \n",
    "    Returns:\n",
    "    structural_coefs_df (pd.DataFrame): A dataframe containing the predictors, their structural coefficients,\n",
    "                                        model coefficients (beta weights), and suppressor index.\n",
    "                                        \n",
    "                                        If the sum of the structure coefficients is higher than 1, they are correlated (multicollinear)\n",
    "    \"\"\"\n",
    "    # Calculating the predicted values\n",
    "    y_predicted = model.predict(data)\n",
    "\n",
    "    # Creating a temporary dataframe to store interaction terms\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    # Calculating the structural coefficients\n",
    "    structural_coefs = {}\n",
    "    for pred in model.params.index:\n",
    "        if pred == 'Intercept':\n",
    "            continue\n",
    "\n",
    "        # Check if the predictor is an interaction term\n",
    "        if ':' in pred:\n",
    "            # Split the interaction term into its components\n",
    "            components = pred.split(':')\n",
    "            # Multiply the components and store the result in the temporary dataframe\n",
    "            temp_product = data[components[0]]\n",
    "            for component in components[1:]:\n",
    "                temp_product *= data[component]\n",
    "            temp_df[pred] = temp_product\n",
    "        else:\n",
    "            temp_df[pred] = data[pred]\n",
    "        \n",
    "        coef, _ = pearsonr(temp_df[pred], y_predicted)\n",
    "        structural_coefs[pred] = np.square(coef)\n",
    "\n",
    "    # Calculating the model coefficients\n",
    "    model_coefs = model.params.drop('Intercept')\n",
    "\n",
    "    # Creating a dataframe to store the results\n",
    "    structural_coefs_df = pd.DataFrame(list(zip(structural_coefs.keys(), structural_coefs.values(), model_coefs.values)), \n",
    "                                       columns=['predictor', 'structural_coefficient', 'model_coefficient'])\n",
    "\n",
    "    # Adding suppressor index column\n",
    "    structural_coefs_df['suppressor_index'] = structural_coefs_df['model_coefficient'].abs() / structural_coefs_df['structural_coefficient']\n",
    "\n",
    "    # Sorting the dataframe by the structural coefficients in descending order\n",
    "    structural_coefs_df.sort_values(by='structural_coefficient', ascending=False, inplace=True)\n",
    "    structural_coefs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return structural_coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_structural_coefs_df = structural_coefficients(results, data_df.copy())\n",
    "squared_structural_coefs_df.to_csv(os.path.join(out_dir, 'structural_coefficient_analysis.csv'))\n",
    "print('saved to: ', os.path.join(out_dir, 'structural_coefficient_analysis.csv'))\n",
    "display(squared_structural_coefs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sqrt, mean\n",
    "\n",
    "# Calculate the squared errors\n",
    "squared_errors = (data_df['percent_change_adascog11'] - results.fittedvalues) ** 2\n",
    "\n",
    "# Calculate the mean of the squared errors\n",
    "mse = mean(squared_errors)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_measurements import model_diagnostics\n",
    "model_diagnostics(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Two Lienar Regressions Using F-Test (ANOVA_LM In Statsmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.api import anova_lm\n",
    "smaller_formula = 'outcome ~ Subiculum_Connectivity'\n",
    "\n",
    "larger_formula = 'outcome ~ Age*Subiculum_Connectivity'\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH!----------------------------------------------------------------\n",
    "table1 = anova_lm(smf.ols(smaller_formula, data=data_df).fit(), smf.ols(larger_formula, data=data_df).fit())\n",
    "print(table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_groups = data_df.groupby([\"Age\", \"Subiculum_Connectivity\"])\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------do not touch\n",
    "infl = results.get_influence()\n",
    "resid = infl.resid_studentized_internal\n",
    "plt.figure(figsize=(6, 6))\n",
    "for values, group in factor_groups:\n",
    "    i, j = values\n",
    "    idx = group.index\n",
    "    plt.scatter(\n",
    "        data_df['Age'][idx],\n",
    "        resid[idx],\n",
    "        # marker=symbols[j],\n",
    "        # color=colors[i - 1],\n",
    "        s=144,\n",
    "        edgecolors=\"black\",\n",
    "    )\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"standardized resids\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 2D Interaction Plot to Visualize Interactions\n",
    "\n",
    "\n",
    "This code is designed to create an interaction plot to visualize the effects of two factors and their interaction on the outcome variable.\n",
    "\n",
    "The interaction_plot function takes as input a dataframe, two factors (x_one and x_two), two corresponding labels for the conditions when the values of these factors are under the mean (x_one_under_mean and x_two_under_mean) and over the mean (x_one_over_mean and x_two_over_mean), and the response variable (outcome). If binarize is set to True, it converts the two factors into binary variables based on whether their values are above or below the mean. The function then creates a mapping for the x_two variable to numerical values for the purpose of plotting.\n",
    "\n",
    "It uses the interaction_plot function from the statsmodels package to create the plot. In the plot, x_two is represented on the x-axis, x_one is used to color the lines, and the outcome variable is plotted on the y-axis. The function also sets the labels for the x and y axes and the tick labels on the x-axis according to the inputs provided.\n",
    "\n",
    "The function also allows for saving the plot to an output directory specified by the user. If save is set to True, it saves the plot in both PNG and SVG formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.api import interaction_plot\n",
    "\n",
    "def two_dimensional_interaction_plot(data_df, \n",
    "                    x_one, x_one_under_mean, x_one_over_mean,\n",
    "                    x_two, x_two_under_mean, x_two_over_mean, \n",
    "                    response, \n",
    "                    binarize=True,\n",
    "                    x_label='Subiculum Connectivity', y_label='Percent Improvement (MDRS)',\n",
    "                    save=False, out_dir=None):\n",
    "    \"\"\"\n",
    "    Function to create an interaction plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pandas.DataFrame\n",
    "        The dataframe containing the data.\n",
    "    x_one, x_two : str\n",
    "        Column names of the two factors.\n",
    "    x_one_under_mean, x_two_under_mean : str\n",
    "        Labels to be used when the values of x_one and x_two are under the mean, respectively.\n",
    "    x_one_over_mean, x_two_over_mean : str\n",
    "        Labels to be used when the values of x_one and x_two are over the mean, respectively.\n",
    "    response : str\n",
    "        Column name of the outcome variable.\n",
    "    binarize : bool, optional\n",
    "        Whether to convert x_one and x_two into binary variables.\n",
    "    x_label, y_label : str, optional\n",
    "        Labels for the x-axis and y-axis.\n",
    "    save : bool, optional\n",
    "        Whether to save the plot.\n",
    "    out_dir : str, optional\n",
    "        Directory where the plot will be saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The original dataframe with modified x_one and x_two if binarize is True.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Binarize x_two variable\n",
    "    if binarize:\n",
    "        data_df[x_two] = np.where(data_df[x_two] <= data_df[x_two].mean(), f'{x_two_under_mean}', f'{x_two_over_mean}')\n",
    "\n",
    "    # Binarize x_one variable\n",
    "    if binarize:\n",
    "        data_df[x_one] = np.where(data_df[x_one] <= data_df[x_one].mean(), f'{x_one_under_mean}', f'{x_one_over_mean}')\n",
    "    \n",
    "    # Map the x_two categories to numbers for plotting\n",
    "    mapping = {x_two_under_mean: 0, x_two_over_mean: 1}\n",
    "    data_df[x_two] = data_df[x_two].map(mapping)\n",
    "    \n",
    "    # Create an interaction plot with the specified factors and response\n",
    "    fig, ax = plt.subplots()\n",
    "    interaction_plot(x=data_df[x_two].values, trace=data_df[x_one].values, response=data_df[response].values, colors=['Red', 'Blue'], xlabel=x_label, ylabel=y_label, ax=ax)\n",
    "\n",
    "    # Set the labels for the x-axis and y-axis, and the tick labels on the x-axis\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([x_two_under_mean, x_two_over_mean])\n",
    "    ax.set_ylabel(f'{y_label}')\n",
    "    ax.set_xlabel(f'{x_label}')\n",
    "\n",
    "    # Save the plot if save is True\n",
    "    if save:\n",
    "        if out_dir is not None:\n",
    "            fig.savefig(out_dir + '2D_interaction.png')\n",
    "            fig.savefig(out_dir + '2D_interaction.svg')\n",
    "            print(f'saved to: {out_dir}')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dimensional_interaction_plot(data_df.copy(), \n",
    "                 x_one='Age', x_one_under_mean='Young', x_one_over_mean='Old', \n",
    "                 x_two='Subiculum_Connectivity', x_two_under_mean='Low Connectivity', x_two_over_mean='High Connectivity', \n",
    "                 response='outcome', \n",
    "                 x_label='Subiculum Connectivity', \n",
    "                 y_label='Percent Improvement (MDRS)',\n",
    "                 save=True, out_dir='./')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use response plane to visualize interaction effect\n",
    "- This models the marginal distribution of variables\n",
    "- If the model has 2 predictors and 1 response, then choose option A\n",
    "- If the model has more than 2 predictors, then choose option B. You will need to manually vary across the additional predictors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 variable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_plot(data_df: pd.DataFrame,\n",
    "                            x_one: str,\n",
    "                            x_two: str,\n",
    "                            outcome: str,\n",
    "                            results: GLMResults,\n",
    "                            num_slices: int = 100,\n",
    "                            out_dir: str = './',\n",
    "                            labels: dict = None) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a 3D plot visualizing the interaction of two predictor variables on the outcome.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : str\n",
    "        Column name of the first predictor variable in the dataframe.\n",
    "    x_two : str\n",
    "        Column name of the second predictor variable in the dataframe.\n",
    "    outcome : str\n",
    "        Column name of the outcome variable in the dataframe.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    num_slices : int, optional\n",
    "        Number of slices to create in the 3D grid, default is 100.\n",
    "    out_dir : str, optional\n",
    "        Directory to save the output PNG and SVG files, default is the current directory.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        The created figure.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create grid of predictor variable values\n",
    "    x1 = np.linspace(min(data_df[x_one]), max(data_df[x_one]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[x_two]), max(data_df[x_two]), num_slices)\n",
    "    x1v, x2v = np.meshgrid(x1, x2)\n",
    "\n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    # Flattening the matrices to create a DataFrame for prediction\n",
    "    X_grid = pd.DataFrame({\n",
    "        x_one: x1v.ravel(),\n",
    "        x_two: x2v.ravel(),\n",
    "    })\n",
    "\n",
    "    # Generate response values for grid\n",
    "    y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices)\n",
    "\n",
    "    # Create a new figure for plotting\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot the surface\n",
    "    ax.plot_surface(x1v, x2v, y_pred, cmap='bwr', alpha=0.8)\n",
    "\n",
    "    # Set the axes labels\n",
    "    format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "    # Set the axes labels\n",
    "    if labels is not None:\n",
    "        ax.set_xlabel(labels.get('x', format_label(x_one)))\n",
    "        ax.set_ylabel(labels.get('y', format_label(x_two)))\n",
    "        ax.set_zlabel(labels.get('z', format_label(outcome)))\n",
    "    else:\n",
    "        ax.set_xlabel(format_label(x_one))\n",
    "        ax.set_ylabel(format_label(x_two))\n",
    "        ax.set_zlabel(format_label(outcome))\n",
    "\n",
    "\n",
    "    # Save the plot as PNG and SVG files\n",
    "    fig.savefig(out_dir + '2_variable.png', dpi=300)\n",
    "    fig.savefig(out_dir + '2_variable.svg', format='svg')\n",
    "    print('Saved to file', out_dir)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one = 'Subiculum_Connectivity'\n",
    "x_two = 'Age'\n",
    "outcome = 'outcome'\n",
    "#----------------------------------------------------------------DO NOT TOUCH THIS!----------------------------------------------------------------\n",
    "create_interaction_plot(data_df, \n",
    "                        x_one=x_one, \n",
    "                        x_two=x_two, \n",
    "                        outcome=outcome, \n",
    "                        results=results, \n",
    "                        out_dir=out_dir, \n",
    "                        labels={'x': 'Subiculum Connectivity', 'y': 'Age', 'z': 'Percent Improvement (MDRS)'});"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Variable Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def create_interaction_gifs(data_df: pd.DataFrame, \n",
    "                            x_one: str, \n",
    "                            x_two: str, \n",
    "                            x_three: str, \n",
    "                            outcome: str, \n",
    "                            results: GLMResults, \n",
    "                            num_slices: int = 100,\n",
    "                            gif_duration: float = 0.3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Creates gifs visualizing the interaction of predictor variables on the outcome.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : str\n",
    "        Column name of the first predictor variable in the dataframe.\n",
    "    x_two : str\n",
    "        Column name of the second predictor variable in the dataframe.\n",
    "    x_three : str\n",
    "        Column name of the third predictor variable in the dataframe.\n",
    "    outcome : str\n",
    "        Column name of the outcome variable in the dataframe.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    num_slices : int, optional\n",
    "        Number of slices to create in the gifs, default is 100.\n",
    "    gif_duration : float, optional\n",
    "        Duration of each frame in the gif in seconds, default is 0.3.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        List of file paths to the created gif files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if x_three is binary\n",
    "    unique_values = data_df[x_three].unique()\n",
    "    is_binary = len(unique_values) == 2\n",
    "\n",
    "    # Create grid of predictor variable values\n",
    "    x1 = np.linspace(min(data_df[x_one]), max(data_df[x_one]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[x_two]), max(data_df[x_two]), num_slices)\n",
    "    \n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    gif_paths = []\n",
    "\n",
    "    if is_binary:\n",
    "        for x_three_value in unique_values:\n",
    "            # Flattening the matrices to create a DataFrame for prediction\n",
    "            X_grid = pd.DataFrame({\n",
    "                x_one: np.tile(x1, len(x2)),\n",
    "                x_two: np.repeat(x2, len(x1)),\n",
    "                x_three: np.ones_like(np.tile(x1, len(x2))) * x_three_value\n",
    "            })\n",
    "\n",
    "            # Generate response values for grid\n",
    "            y_pred = results.predict(X_grid).values.reshape(len(x2), len(x1))\n",
    "\n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Plot the surface\n",
    "            ax.plot_surface(np.tile(x1, (len(x2), 1)), np.repeat(x2[:, np.newaxis], len(x1), axis=1), y_pred, cmap='bwr', alpha=0.8)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "\n",
    "            # Set the title with the actual value of x_three\n",
    "            title = f'{x_three} = {x_three_value}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_{x_three}_{x_three_value}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            gif_paths.append(image_path)\n",
    "            plt.close()\n",
    "    else:\n",
    "        # Flattening the matrices to create a DataFrame for prediction\n",
    "        x3 = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)\n",
    "        x1v, x2v, x3v = np.meshgrid(x1, x2, x3)\n",
    "\n",
    "        X_grid = pd.DataFrame({\n",
    "            x_one: x1v.ravel(),\n",
    "            x_two: x2v.ravel(),\n",
    "            x_three: x3v.ravel(),\n",
    "        })\n",
    "\n",
    "        # Generate response values for grid\n",
    "        y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices, num_slices)\n",
    "\n",
    "        # Collect the file paths of images\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterating over x3 (third predictor variable) and saving each plot as an image\n",
    "        for i in range(num_slices):\n",
    "            x3_slice = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)[i]\n",
    "\n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Plot the surface\n",
    "            ax.plot_surface(x1v[:, :, i], x2v[:, :, i], y_pred[:, :, i], cmap='bwr', alpha=0.8)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "\n",
    "            # Set the title with the actual value of x_three\n",
    "            title = f'{x_three} = {x3_slice:.2f}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_slice_{i+1}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            image_paths.append(image_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Create a gif from the image files\n",
    "        gif_path = f'plots.gif'\n",
    "        images = [imageio.imread(image_path) for image_path in image_paths]\n",
    "        imageio.mimsave(gif_path, images, duration=gif_duration)\n",
    "        gif_paths.append(gif_path)\n",
    "\n",
    "        # Remove the individual image files\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "\n",
    "    return gif_paths\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# gifs = create_interaction_gifs(data_df, 'x_one', 'x_two', 'x_three', 'outcome', results)\n",
    "# print(\"GIFs created:\", gifs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one = 'Subiculum_Connectivity'\n",
    "x_two = 'Subiculum_Grey_Matter' \n",
    "x_three = 'Age'\n",
    "outcome = 'cognitive_improvement'\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "gifs = create_interaction_gifs(data_df, \n",
    "                               x_one, \n",
    "                               x_two, \n",
    "                               x_three, \n",
    "                               outcome, \n",
    "                               results)\n",
    "print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Variable Method\n",
    "- 4th variable is expected to be 1-hot encoded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def create_interaction_gifs(data_df: pd.DataFrame, \n",
    "                            x_one: str, \n",
    "                            x_two: str, \n",
    "                            x_three: str, \n",
    "                            x_four: str, \n",
    "                            x_four_dict: dict,\n",
    "                            outcome: str, \n",
    "                            results: GLMResults, \n",
    "                            num_slices: int = 100,\n",
    "                            gif_duration: float = 0.3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Creates gifs visualizing the interaction of predictor variables on the outcome,\n",
    "    and the effect of a one-hot encoded variable (x_four).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : str\n",
    "        Column name of the first predictor variable in the dataframe.\n",
    "    x_two : str\n",
    "        Column name of the second predictor variable in the dataframe.\n",
    "    x_three : str\n",
    "        Column name of the third predictor variable in the dataframe.\n",
    "    x_four : str\n",
    "        Column name of the one-hot encoded predictor variable (values should be 0 or 1) in the dataframe.\n",
    "    x_four_list : list\n",
    "        List of the x_four variables corresponding to their one hot encoded outcomes.\n",
    "    outcome : str\n",
    "        Column name of the outcome variable in the dataframe.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    num_slices : int, optional\n",
    "        Number of slices to create in the gifs, default is 100.\n",
    "    gif_duration : float, optional\n",
    "        Duration of each frame in the gif in seconds, default is 0.3.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        List of file paths to the created gif files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    gif_paths = []\n",
    "\n",
    "    # Iterate over x_four values 0 and 1\n",
    "    for x_four_value in [0, 1]:\n",
    "        distribution_df = data_df.copy()\n",
    "        distribution_df = distribution_df[distribution_df['Disease'] == x_four_value]\n",
    "        # Create grid of predictor variable values\n",
    "        x1 = np.linspace(min(distribution_df[x_one]), max(distribution_df[x_one]), num_slices)\n",
    "        x2 = np.linspace(min(distribution_df[x_two]), max(distribution_df[x_two]), num_slices)\n",
    "        x3 = np.linspace(min(distribution_df[x_three]), max(distribution_df[x_three]), num_slices)\n",
    "        x1v, x2v, x3v = np.meshgrid(x1, x2, x3)\n",
    "        \n",
    "        # Flattening the matrices to create a DataFrame for prediction\n",
    "        X_grid = pd.DataFrame({\n",
    "            x_one: x1v.ravel(),\n",
    "            x_two: x2v.ravel(),\n",
    "            x_three: x3v.ravel(),\n",
    "            x_four: np.ones_like(x1v).ravel() * x_four_value\n",
    "        })\n",
    "\n",
    "        # Generate response values for grid\n",
    "        y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices, num_slices)\n",
    "\n",
    "        # Collect the file paths of images\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterating over x3 (third predictor variable) and saving each plot as an image\n",
    "        for i in range(num_slices):\n",
    "            x3_slice = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)[i]\n",
    "            \n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Plot the surface\n",
    "            ax.plot_surface(x1v[:, :, i], x2v[:, :, i], y_pred[:, :, i], cmap='bwr', alpha=0.8)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "            \n",
    "            # Set the title with the actual value of x_three and x_four\n",
    "            title = f'{x_four_dict[x_four_value]}, {x_three} = {x3_slice:.2f}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_{x_four}_{x_four_dict[x_four_value]}_slice_{i+1}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            image_paths.append(image_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Create a gif from the image files\n",
    "        gif_path = f'{x_four}_{x_four_dict[x_four_value]}_plots.gif'\n",
    "        images = [imageio.imread(image_path) for image_path in image_paths]\n",
    "        imageio.mimsave(gif_path, images, duration=gif_duration)\n",
    "        gif_paths.append(gif_path)\n",
    "\n",
    "        # Remove the individual image files\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "\n",
    "    return gif_paths\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# gifs = create_interaction_gifs(data_df, 'Subiculum_Connectivity', 'Subiculum_Grey_Matter', 'Age', 'Disease', 'outcome', results)\n",
    "# print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/946tskyj68b6htgvndtppmz80000gp/T/ipykernel_25492/3155527796.py:114: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images = [imageio.imread(image_path) for image_path in image_paths]\n",
      "/var/folders/82/946tskyj68b6htgvndtppmz80000gp/T/ipykernel_25492/3155527796.py:114: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images = [imageio.imread(image_path) for image_path in image_paths]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIFs created: [\"Disease_Parkinson's_plots.gif\", \"Disease_Alzheimer's_plots.gif\"]\n"
     ]
    }
   ],
   "source": [
    "x_one = 'Subiculum_Connectivity'\n",
    "x_two = 'Subiculum_Grey_Matter' \n",
    "x_three = 'Age'\n",
    "x_four = 'Disease'\n",
    "x_four_dict = {1: \"Alzheimer's\", 0: \"Parkinson's\"}\n",
    "outcome = 'cognitive_improvement'\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "gifs = create_interaction_gifs(data_df, \n",
    "                               x_one, \n",
    "                               x_two, \n",
    "                               x_three, \n",
    "                               x_four,\n",
    "                               x_four_dict,\n",
    "                               outcome, \n",
    "                               results)\n",
    "print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Variable Method\n",
    "- This is identical to the 4 variable method, but takes the 5th variable \n",
    "and calculates is at -2 and +2 standard deviations, then plots a response plane for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def create_interaction_gifs_with_5_variables(data_df: pd.DataFrame, \n",
    "                                             x_one: str, \n",
    "                                             x_two: str, \n",
    "                                             x_three: str, \n",
    "                                             x_four: str, \n",
    "                                             x_four_dict: dict,\n",
    "                                             x_five: str,\n",
    "                                             x_five_factor_levels: int,\n",
    "                                             outcome: str, \n",
    "                                             results: GLMResults, \n",
    "                                             num_slices: int = 100,\n",
    "                                             gif_duration: float = 0.3) -> List[str]:\n",
    "    \n",
    "    # Create grid of predictor variable values\n",
    "    x1 = np.linspace(min(data_df[x_one]), max(data_df[x_one]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[x_two]), max(data_df[x_two]), num_slices)\n",
    "    x3 = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)\n",
    "    x1v, x2v, x3v = np.meshgrid(x1, x2, x3)\n",
    "\n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    gif_paths = []\n",
    "\n",
    "    # Iterate over x_four values 0 and 1\n",
    "    for x_four_value in [0, 1]:\n",
    "        \n",
    "        # Collect the file paths of images\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterating over x3 (third predictor variable) and saving each plot as an image\n",
    "        for i in range(num_slices):\n",
    "            x3_slice = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)[i]\n",
    "            \n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Choose to use x_five mean\n",
    "            x_five_mean = data_df[x_five].mean()\n",
    "            x_five_std = data_df[x_five].std()\n",
    "            if x_five_factor_levels == 1:\n",
    "                x_five_level = [x_five_mean]\n",
    "            # Choose to use x_five +/- 2 standard deviations\n",
    "            else:\n",
    "                x_five_level = [x_five_mean-(2*x_five_std), x_five_mean+(2*x_five_std)]\n",
    "            for level in range(0, len(x_five_level)):\n",
    "                \n",
    "                # Flattening the matrices to create a DataFrame for prediction\n",
    "                X_grid = pd.DataFrame({\n",
    "                    x_one: x1v.ravel(),\n",
    "                    x_two: x2v.ravel(),\n",
    "                    x_three: x3v.ravel(),\n",
    "                    x_four: np.ones_like(x1v).ravel() * x_four_value,\n",
    "                    x_five: np.ones_like(x1v).ravel() * x_five_level[level]\n",
    "                })\n",
    "\n",
    "                # Generate response values for grid\n",
    "                y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices, num_slices)\n",
    "                \n",
    "                # Plot the surface\n",
    "                cmap = 'viridis' if x_five_level[level] == data_df[x_five].mean() else ('cool' if x_five_level[level] < 0 else 'magma')\n",
    "                ax.plot_surface(x1v[:, :, i], x2v[:, :, i], y_pred[:, :, i], cmap=cmap, alpha=0.5)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "            \n",
    "            # Set the title with the actual value of x_three and x_four\n",
    "            title = f'{x_four_dict[x_four_value]}, {x_three} = {x3_slice:.2f}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_{x_four}_{x_four_dict[x_four_value]}_slice_{i+1}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            image_paths.append(image_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Create a gif from the image files\n",
    "        gif_path = f'{x_four}_{x_four_dict[x_four_value]}_plots.gif'\n",
    "        images = [imageio.imread(image_path) for image_path in image_paths]\n",
    "        imageio.mimsave(gif_path, images, duration=gif_duration)\n",
    "        gif_paths.append(gif_path)\n",
    "\n",
    "        # Remove the individual image files\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "\n",
    "    return gif_paths\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one = 'Subiculum_Connectivity'\n",
    "x_two = 'Subiculum_Grey_Matter' \n",
    "x_three = 'Age'\n",
    "x_four = 'Disease'\n",
    "x_four_dict = {1: \"Alzheimer's\", 0: \"Parkinson's\"}\n",
    "x_five = 'Subiculum_CSF'\n",
    "x_five_factor_levels = 1\n",
    "outcome = 'cognitive_improvement'\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "gifs = create_interaction_gifs_with_5_variables(data_df, \n",
    "                               x_one, \n",
    "                               x_two, \n",
    "                               x_three, \n",
    "                               x_four,\n",
    "                               x_four_dict,\n",
    "                               x_five,\n",
    "                               x_five_factor_levels,\n",
    "                               outcome, \n",
    "                               results)\n",
    "print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Within Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, test_type, test_tails='two_tailed'):\n",
    "    \"\"\"\n",
    "    Compute p-value and confidence interval and organize them in a DataFrame.\n",
    "    \n",
    "    :param resampled_metrics: List of metrics computed from the resampled or permuted data\n",
    "    :param observed_metric: Observed metric computed from the original data\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param test_type: Type of test performed ('resampling' or 'permutation')\n",
    "    :param test_tails: Type of tail for p-value testing ('two_tailed', 'right_tailed', or 'left_tailed')\n",
    "    :return: DataFrame with p-value and confidence interval\n",
    "    \"\"\"\n",
    "    # Calculate p-value and confidence interval for low and high values\n",
    "    if test_type =='permutation':\n",
    "        if test_tails == 'two_tailed':\n",
    "            print('Two-tailed p-value testing')\n",
    "            p_value_low = np.mean(np.abs([x[0] for x in resampled_metrics]) >= np.abs(observed_metric[0]))\n",
    "            p_value_high = np.mean(np.abs([x[1] for x in resampled_metrics]) >= np.abs(observed_metric[1]))\n",
    "        elif test_tails == 'right_tailed':\n",
    "            print('Right-tailed p-value testing')\n",
    "            p_value_low = np.mean([x[0] for x in resampled_metrics] >= observed_metric[0])\n",
    "            p_value_high = np.mean([x[1] for x in resampled_metrics] >= observed_metric[1])\n",
    "        elif test_tails == 'left_tailed':\n",
    "            print('Left-tailed p-value testing.')\n",
    "            p_value_low = np.mean([x[0] for x in resampled_metrics] <= observed_metric[0])\n",
    "            p_value_high = np.mean([x[1] for x in resampled_metrics] <= observed_metric[1])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for test_tails. Must be one of 'two_tailed', 'right_tailed', or 'left_tailed'.\")\n",
    "    elif test_type == 'resampling':\n",
    "        p_value_low = np.mean(np.sign(np.mean([x[0] for x in resampled_metrics])) != np.sign(observed_metric[0]))\n",
    "        p_value_high = np.mean(np.sign(np.mean([x[1] for x in resampled_metrics])) != np.sign(observed_metric[1]))\n",
    "    else:\n",
    "        raise ValueError(f\"Test type is not supported: {test_type}\")\n",
    "    \n",
    "    conf_int_low = np.percentile([x[0] for x in resampled_metrics], [2.5, 97.5])\n",
    "    conf_int_high = np.percentile([x[1] for x in resampled_metrics], [2.5, 97.5])\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'Observed Metric': [observed_metric[0], observed_metric[1]],\n",
    "        'P-value': [p_value_low, p_value_high],\n",
    "        '95% CI Lower': [conf_int_low[0], conf_int_high[0]],\n",
    "        '95% CI Upper': [conf_int_low[1], conf_int_high[1]]\n",
    "    }\n",
    "    index = ['Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at -2stdev', \n",
    "                'Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at +2stdev']\n",
    "\n",
    "    return pd.DataFrame(data, index=[index])\n",
    "\n",
    "\n",
    "def compare_responses(df, dependent_var, independent_var1, independent_var2, interaction=True):\n",
    "    \"\"\"\n",
    "    Compare responses of a dataset using point testing method.\n",
    "    \n",
    "    :param df: DataFrame containing the dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :return: Comparison metric (absolute differences between low and high points)\n",
    "    \"\"\"\n",
    "    if interaction:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} * {independent_var2}'\n",
    "    else:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} + {independent_var2}'\n",
    "\n",
    "    # Fit the model\n",
    "    model = smf.ols(formula=formula, data=df).fit()\n",
    "\n",
    "    # Evaluate at specific points\n",
    "    diff_low, diff_high = evaluate_at_specific_points(df, independent_var1, independent_var2, model)\n",
    "\n",
    "    # Return the absolute differences\n",
    "    return abs(diff_low), abs(diff_high)\n",
    "\n",
    "def evaluate_at_specific_points(df, independent_var1, independent_var2, model):\n",
    "    \"\"\"\n",
    "    Evaluate the model at specific points.\n",
    "    \n",
    "    :param df: DataFrame containing the dataset\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param model: Fitted model\n",
    "    :return: Differences between low and high points\n",
    "    \"\"\"\n",
    "    # Determine the low and high values of the independent variables\n",
    "    iv1_sd = data_df[independent_var1].std()\n",
    "    iv2_sd = data_df[independent_var2].std()\n",
    "    iv1_mean = data_df[independent_var1].mean()\n",
    "    iv2_mean = data_df[independent_var2].mean()\n",
    "\n",
    "    # Create the dataframes for low_1 and high_1 predictions\n",
    "    low_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean - 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    high_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean + 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    # Perform the predictions on the dataframes\n",
    "    low_1_predictions = model.predict(low_1_df)\n",
    "    high_1_predictions = model.predict(high_1_df)\n",
    "\n",
    "    # Calculate the differences between the predictions\n",
    "    difference_low = low_1_predictions[1] - low_1_predictions[0]\n",
    "    difference_high = high_1_predictions[1] - high_1_predictions[0]\n",
    "\n",
    "    return difference_low, difference_high\n",
    "\n",
    "def resample_or_permutation_test(df, dependent_var, independent_var1, independent_var2, interaction=True, num_resamples=1000, test_type='permutation'):\n",
    "    \"\"\"\n",
    "    Perform resampling or permutation test to compare responses of two datasets and return results in a DataFrame.\n",
    "    \n",
    "    :param df: DataFrame containing the dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param num_slices: Number of values to take for each variable to form the grid (used in correlation)\n",
    "    :param num_resamples: Number of resamples to perform\n",
    "    :param test_type: Type of test to perform ('resampling' or 'permutation')\n",
    "    :return: p-value and confidence interval\n",
    "    \"\"\"\n",
    "    # Calculate observed metric\n",
    "    observed_metric = compare_responses(df, dependent_var, independent_var1, independent_var2, interaction)\n",
    "    \n",
    "    # Initialize results\n",
    "    resampled_metrics = []\n",
    "\n",
    "    for i in tqdm(range(num_resamples)):\n",
    "        # Perform resampling or permutation\n",
    "        if test_type == 'resampling':\n",
    "            sample_df = df.sample(frac=1, replace=True)\n",
    "        elif test_type == 'permutation':\n",
    "            sample_df = df.copy()\n",
    "            sample_df[dependent_var] = np.random.permutation(sample_df[dependent_var].values)\n",
    "        else:\n",
    "            raise ValueError(\"test_type must be either 'resampling' or 'permutation'.\")\n",
    "        \n",
    "        # Calculate resampled metric\n",
    "        resampled_metric = compare_responses(sample_df, dependent_var, independent_var1, independent_var2, interaction)\n",
    "        resampled_metrics.append(resampled_metric)\n",
    "    \n",
    "    # Calculate statistics and create DataFrame\n",
    "    results_dataframe = compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, test_type)\n",
    "    \n",
    "    return results_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataframe 1 and dataframe 2 for comaprison by permutation test\n",
    "df_1 = data_df[data_df['Disease'] == 1]\n",
    "df_2 = data_df[data_df['Disease'] == 0]\n",
    "dependent_var = 'outcome'\n",
    "independent_var1 = 'Age'\n",
    "independent_var2 = 'Subiculum_Connectivity'\n",
    "enable_interaction = True\n",
    "num_iterations = 10000\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "permutation_results = resample_or_permutation_test(df = df_2,\n",
    "                                                    dependent_var = dependent_var,\n",
    "                                                    independent_var1 = independent_var1,\n",
    "                                                    independent_var2 = independent_var2,\n",
    "                                                    interaction = enable_interaction,\n",
    "                                                    num_resamples=num_iterations, \n",
    "                                                    test_type='permutation')\n",
    "permutation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "bootstrap_results = resample_or_permutation_test(df = df_2,\n",
    "                                                    dependent_var = dependent_var,\n",
    "                                                    independent_var1 = independent_var1,\n",
    "                                                    independent_var2 = independent_var2,\n",
    "                                                    interaction = enable_interaction,\n",
    "                                                    num_resamples=num_iterations, \n",
    "                                                    test_type='resampling')\n",
    "bootstrap_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Between Joint Distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of 2 Joint Distributions**\n",
    "1) Joint Distributions and Multiple Regression:\n",
    "\n",
    "The concept of \"joint distributions\" refers to the combined distribution of multiple variables, taking into account their mutual relationships. In the context of multiple regression analysis, we utilize a statistical model to examine the joint distribution of the independent variables and their relationship with the dependent variable. By fitting a regression model, such as the one used in this code, we can investigate how the independent variables collectively influence the dependent variable.\n",
    "\n",
    "In the provided code, we compare the responses of two datasets based on their joint distributions. This means that we analyze the relationship between the independent variables (independent_var1 and independent_var2) as a pair and their collective influence on the dependent variable. We fit separate regression models for each dataset, considering both independent variables as predictors and the dependent variable as the response.\n",
    "\n",
    "Analyzing the joint distributions allows us to gain insights into how the independent variables interact with each other and jointly impact the dependent variable. By considering the joint relationship between the variables, we can understand how changes in one independent variable may affect the response when the other independent variable is also taken into account.\n",
    "\n",
    "2) Permutation vs Bootstrap:\n",
    "\n",
    "The code employs two different approaches for hypothesis testing: permutation testing and bootstrap resampling. Both methods aim to assess the significance of the observed metrics by generating alternative datasets.\n",
    "\n",
    "Permutation testing involves randomly permuting the values of the dependent variable while keeping the independent variables unchanged. This process breaks the relationship between the dependent and independent variables, creating new datasets under the assumption of no association. By comparing the observed metric with metrics obtained from the permuted datasets, we can estimate p-values and confidence intervals, providing a measure of the statistical significance of our results. A permuted dataset is one wherein the independent variables are unrelated to the dependent variable. They are the null distribution. \n",
    "\n",
    "Bootstrap resampling, on the other hand, involves randomly sampling data points from the original datasets with replacement. This resampling process allows us to create multiple datasets of the same size as the original datasets. By generating new datasets through resampling, we can examine the distribution of the metrics of interest and estimate their variability. This information can be used to estimate confidence intervals and assess the statistical significance of our findings. A bootstrap resampling process creates alternative datasets wherein the independent variables are still related to the dependent variable. These define significance by demonstrating the confidence intervals of the dataset do not cross a threshold, which is typically 0.\n",
    "\n",
    "3) Correlation vs Point-test:\n",
    "\n",
    "The code provides two different methods for comparing responses based on the joint distributions: correlation and point testing.\n",
    "\n",
    "The correlation analysis aims to assess the spatial correlation between the joint distributions of the two datasets. This analysis examines the overall patterns and similarities in the responses across the range of the joint distributions. By calculating the correlation coefficient between the predicted responses, we can determine if there is a consistent relationship between the joint distributions of the independent variables and the dependent variable across the datasets. Then, we compare this to bootstrapped or permuted datasets to derive significance estimates.\n",
    "\n",
    "In contrast, point testing focuses on evaluating the differences in the predicted responses at specific points of the joint distributions. Specifically, we examine the differences at +/- 2 standard deviations of the independent variables. This analysis allows us to determine if the differences between the responses at these specific points significantly vary between the two datasets. By comparing the differences in response values at these critical points, we can identify regions of the joint distributions where the relationship between the independent variables and the dependent variable differs significantly. The purpose of this is to condense a 3-dimensional joint distribution into 2-dimensions at set values which is good for generating figures. Then, we compare this to bootstrapped or permuted datasets to derive significance estimates.\n",
    "\n",
    "In summary, comparing the joint distributions enables us to analyze the combined effects of the independent variables on the dependent variable. The correlation and point testing methods offer different perspectives on the relationship between the variables, while permutation testing and bootstrap resampling provide means to assess the statistical significance of our findings.\n",
    "\n",
    "**Instructions**\n",
    "Testing: 'correlation' or 'point_testing'\n",
    "Significance Testing: 'permutation' or 'resampling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, comparison_method, test_type, test_tails='two_tailed'):\n",
    "    \"\"\"\n",
    "    Compute p-value and confidence interval and organize them in a DataFrame.\n",
    "    \n",
    "    :param resampled_metrics: List of metrics computed from the resampled or permuted data\n",
    "    :param observed_metric: Observed metric computed from the original data\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :return: DataFrame with p-value and confidence interval\n",
    "    \"\"\"\n",
    "    if comparison_method == 'correlation':\n",
    "        # Calculate p-value and confidence interval\n",
    "        p_value = np.mean(np.abs(resampled_metrics) >= np.abs(observed_metric))\n",
    "        conf_int = np.percentile(resampled_metrics, [2.5, 97.5])\n",
    "\n",
    "        # Create DataFrame\n",
    "        data = {\n",
    "            'Observed Metric': [observed_metric],\n",
    "            'P-value': [p_value],\n",
    "            '95% CI Lower': [conf_int[0]],\n",
    "            '95% CI Upper': [conf_int[1]]\n",
    "        }\n",
    "        index = 'Spatial correlation of the joint distributions'\n",
    "    \n",
    "    elif comparison_method == 'point_testing':\n",
    "        # Calculate p-value and confidence interval for low and high values\n",
    "        if test_type =='permutation':\n",
    "            if test_tails == 'two_tailed':\n",
    "                print('Two-tailed p-value testing')\n",
    "                p_value_low = np.mean(np.abs([x[0] for x in resampled_metrics]) >= np.abs(observed_metric[0]))\n",
    "                p_value_high = np.mean(np.abs([x[1] for x in resampled_metrics]) >= np.abs(observed_metric[1]))\n",
    "            elif test_tails == 'right_tailed':\n",
    "                print('Right-tailed p-value testing')\n",
    "                p_value_low = np.mean([x[0] for x in resampled_metrics] >= observed_metric[0])\n",
    "                p_value_high = np.mean([x[1] for x in resampled_metrics] >= observed_metric[1])\n",
    "            elif test_tails == 'left_tailed':\n",
    "                print('Left-tailed p-value testing.')\n",
    "                p_value_low = np.mean([x[0] for x in resampled_metrics] <= observed_metric[0])\n",
    "                p_value_high = np.mean([x[1] for x in resampled_metrics] <= observed_metric[1])\n",
    "            else:\n",
    "                raise ValueError(\"Invalid value for test_tails. Must be one of 'two_tailed', 'right_tailed', or 'left_tailed'.\")\n",
    "        elif test_type == 'resampling':\n",
    "            p_value_low = np.mean(np.sign(np.mean([x[0] for x in resampled_metrics])) != (np.sign(np.mean([x[0] for x in resampled_metrics]))))\n",
    "            p_value_high = np.mean(np.sign(np.mean([x[1] for x in resampled_metrics])) != (np.sign(np.mean([x[1] for x in resampled_metrics]))))\n",
    "        else:\n",
    "            raise ValueError (f'Test type is not supported {test_type}')\n",
    "        conf_int_low = np.percentile(resampled_metrics[0], [2.5, 97.5])\n",
    "        conf_int_high = np.percentile(resampled_metrics[1], [2.5, 97.5])\n",
    "\n",
    "        # Create DataFrame\n",
    "        data = {\n",
    "            'Observed Metric': [observed_metric[0], observed_metric[1]],\n",
    "            'P-value': [p_value_low, p_value_high],\n",
    "            '95% CI Lower': [conf_int_low[0], conf_int_high[0]],\n",
    "            '95% CI Upper': [conf_int_low[1], conf_int_high[1]]\n",
    "        }\n",
    "        index = ['Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at -2stdev', \n",
    "                 'Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at +2stdev']\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"comparison_method must be either 'correlation' or 'point_testing'.\")\n",
    "\n",
    "    return pd.DataFrame(data, index=[index])\n",
    "\n",
    "\n",
    "def calculate_predicted_response(data_df, independent_var1, independent_var2, model, num_slices=100):\n",
    "    \"\"\"\n",
    "    Calculate predicted response values for a grid of values of two independent variables.\n",
    "    \n",
    "    :param data_df: DataFrame containing data\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param model: Fitted model\n",
    "    :param num_slices: Number of values to take for each variable to form the grid\n",
    "    :return: Flattened array of predicted responses\n",
    "    \"\"\"\n",
    "    x1 = np.linspace(min(data_df[independent_var1]), max(data_df[independent_var1]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[independent_var2]), max(data_df[independent_var2]), num_slices)\n",
    "    x1v, x2v = np.meshgrid(x1, x2)\n",
    "\n",
    "    X_grid = pd.DataFrame({\n",
    "        independent_var1: x1v.ravel(),\n",
    "        independent_var2: x2v.ravel(),\n",
    "    })\n",
    "\n",
    "    y_pred = model.predict(X_grid).values.reshape(num_slices, num_slices)\n",
    "\n",
    "    return y_pred.ravel()\n",
    "\n",
    "def evaluate_at_specific_points(data_df, independent_var1, independent_var2, model):\n",
    "    \"\"\"\n",
    "    Evaluate the model at specific points: +/- 2 standard deviations of the independent variables.\n",
    "\n",
    "    :param data_df: DataFrame containing data\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param model: Fitted model\n",
    "    :return: Differences between the predictions at specific points\n",
    "    \"\"\"\n",
    "    iv1_sd = data_df[independent_var1].std()\n",
    "    iv2_sd = data_df[independent_var2].std()\n",
    "    iv1_mean = data_df[independent_var1].mean()\n",
    "    iv2_mean = data_df[independent_var2].mean()\n",
    "\n",
    "    # Create the dataframes for low_1 and high_1 predictions\n",
    "    low_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean - 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    high_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean + 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    # Perform the predictions on the dataframes\n",
    "    low_1_predictions = model.predict(low_1_df)\n",
    "    high_1_predictions = model.predict(high_1_df)\n",
    "\n",
    "    # Calculate the differences between the predictions\n",
    "    difference_low = low_1_predictions[1] - low_1_predictions[0]\n",
    "    difference_high = high_1_predictions[1] - high_1_predictions[0]\n",
    "\n",
    "    return difference_low, difference_high\n",
    "\n",
    "def compare_responses(df1, df2, dependent_var, independent_var1, independent_var2, interaction=True, comparison_method='correlation', num_slices=100):\n",
    "    \"\"\"\n",
    "    Compare responses of two datasets using correlation or point testing method.\n",
    "    \n",
    "    :param df1: DataFrame containing first dataset\n",
    "    :param df2: DataFrame containing second dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param num_slices: Number of values to take for each variable to form the grid (used in correlation)\n",
    "    :return: Comparison metric\n",
    "    \"\"\"\n",
    "    if interaction:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} * {independent_var2}'\n",
    "    else:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} + {independent_var2}'\n",
    "\n",
    "    # Fit the models\n",
    "    model1 = smf.ols(formula=formula, data=df1).fit()\n",
    "    model2 = smf.ols(formula=formula, data=df2).fit()\n",
    "\n",
    "    if comparison_method == 'correlation':\n",
    "        # Calculate predicted responses\n",
    "        response_1 = calculate_predicted_response(df1, independent_var1, independent_var2, model1, num_slices)\n",
    "        response_2 = calculate_predicted_response(df2, independent_var1, independent_var2, model2, num_slices)\n",
    "\n",
    "        # Calculate correlation between the predicted responses\n",
    "        return stats.pearsonr(response_1, response_2)[0]\n",
    "\n",
    "    elif comparison_method == 'point_testing':\n",
    "        # Evaluate at specific points\n",
    "        diff_low_1, diff_high_1 = evaluate_at_specific_points(df1, independent_var1, independent_var2, model1)\n",
    "        diff_low_2, diff_high_2 = evaluate_at_specific_points(df2, independent_var1, independent_var2, model2)\n",
    "        \n",
    "        # Return the absolute differences\n",
    "        return abs(diff_low_1 - diff_low_2), abs(diff_high_1 - diff_high_2)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"comparison_method must be either 'correlation' or 'point_testing'.\")\n",
    "\n",
    "# Update the resample_or_permutation_test function\n",
    "def resample_or_permutation_test(df1, df2, dependent_var, independent_var1, independent_var2, interaction=True, comparison_method='correlation', num_slices=100, num_resamples=1000, test_type='permutation'):\n",
    "    \"\"\"\n",
    "    Perform resampling or permutation test to compare responses of two datasets and return results in a DataFrame.\n",
    "    \n",
    "    :param df1: DataFrame containing first dataset\n",
    "    :param df2: DataFrame containing second dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param num_slices: Number of values to take for each variable to form the grid (used in correlation)\n",
    "    :param num_resamples: Number of resamples to perform\n",
    "    :param test_type: Type of test to perform ('resampling' or 'permutation')\n",
    "    :return: p-value and confidence interval\n",
    "    \"\"\"\n",
    "    # Calculate observed metric\n",
    "    observed_metric = compare_responses(df1, df2, dependent_var, independent_var1, independent_var2, interaction, comparison_method, num_slices)\n",
    "    \n",
    "    # Initialize results\n",
    "    resampled_metrics = []\n",
    "\n",
    "    for i in tqdm(range(num_resamples)):\n",
    "        # Perform resampling or permutation\n",
    "        if test_type == 'resampling':\n",
    "            sample_df1 = df1.sample(frac=1, replace=True)\n",
    "            sample_df2 = df2.sample(frac=1, replace=True)\n",
    "        elif test_type == 'permutation':\n",
    "            sample_df1 = df1.copy()\n",
    "            sample_df2 = df2.copy()\n",
    "            sample_df1[dependent_var] = np.random.permutation(sample_df1[dependent_var].values)\n",
    "            sample_df2[dependent_var] = np.random.permutation(sample_df2[dependent_var].values)\n",
    "        else:\n",
    "            raise ValueError(\"test_type must be either 'resampling' or 'permutation'.\")\n",
    "        \n",
    "        # Calculate resampled metric\n",
    "        resampled_metric = compare_responses(sample_df1, sample_df2, dependent_var, independent_var1, independent_var2, interaction, comparison_method, num_slices)\n",
    "        resampled_metrics.append(resampled_metric)\n",
    "    \n",
    "    # Calculate statistics and create DataFrame\n",
    "    results_dataframe = compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, comparison_method, test_type)\n",
    "    \n",
    "    return results_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataframe 1 and dataframe 2 for comaprison by permutation test\n",
    "df_1 = data_df[data_df['Disease'] == 1]\n",
    "df_2 = data_df[data_df['Disease'] == 0]\n",
    "dependent_var = 'outcome'\n",
    "independent_var1 = 'Age'\n",
    "independent_var2 = 'Subiculum_Connectivity'\n",
    "enable_interaction = True\n",
    "num_iterations = 10000\n",
    "comparison_method = 'correlation' \n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "permutation_results = resample_or_permutation_test(df1 = df_1,\n",
    "                                                    df2 = df_2,\n",
    "                                                    dependent_var = dependent_var,\n",
    "                                                    independent_var1 = independent_var1,\n",
    "                                                    independent_var2 = independent_var2,\n",
    "                                                    interaction = enable_interaction,\n",
    "                                                    test_type = 'permutation',\n",
    "                                                    comparison_method = comparison_method,\n",
    "                                                    num_resamples = num_iterations)\n",
    "permutation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "bootstrap_results = resample_or_permutation_test(df1 = df_1,\n",
    "                                                    df2 = df_2,\n",
    "                                                    dependent_var = dependent_var,\n",
    "                                                    independent_var1 = independent_var1,\n",
    "                                                    independent_var2 = independent_var2,\n",
    "                                                    interaction = enable_interaction,\n",
    "                                                    test_type = 'resampling',\n",
    "                                                    comparison_method = comparison_method,\n",
    "                                                    num_resamples = num_iterations)\n",
    "bootstrap_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Fancy Response Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.import_matrices import import_matrices_from_folder\n",
    "from calvin_utils.generate_nifti import nifti_from_matrix\n",
    "from nimlab import datasets as nimds\n",
    "import numpy as np\n",
    "from nilearn import image, plotting, maskers\n",
    "\n",
    "#Name variables to plot\n",
    "var_one = 'Limbic'\n",
    "var_two = 'Ventral_Attention'\n",
    "val_var_two = 65.4\n",
    "\n",
    "#get conectivity values of interest\n",
    "matrix_path = '/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/seed_generated_networks/yeo_networks_from_thick_yeo_seeds/all_05_limbic_T.nii'\n",
    "matrix = import_matrices_from_folder(matrix_path, file_pattern='')\n",
    "\n",
    "#get conectivity values of interest\n",
    "matrix_path_2 = '/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/seed_generated_networks/yeo_networks_from_thick_yeo_seeds/all_04_ventral_attention_T.nii'\n",
    "matrix_2 = import_matrices_from_folder(matrix_path, file_pattern='')\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------DO NOT MODIFY!------------------------------------------------------------------------------------------------\n",
    "#Set reression input values into a dataframe\n",
    "input_df = pd.DataFrame()\n",
    "input_df[var_one] = matrix.iloc[:,0]\n",
    "input_df[var_two] = matrix_2.iloc[:,0]\n",
    "\n",
    "from nimlab import datasets as nimds\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "input_df = input_df.iloc[brain_indices, :]\n",
    "\n",
    "#Standardize matrix via z score\n",
    "from calvin_utils.z_score_matrix import z_score_matrix\n",
    "for col in input_df.columns:\n",
    "    input_df.loc[:, col] = z_score_matrix(input_df.loc[:, col])\n",
    "\n",
    "#Display results\n",
    "display(input_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "#Generate a new matrix from the input dataframe\n",
    "responses = []\n",
    "\n",
    "#Work on a voxel-wise basis by iterating over index\n",
    "for i in tqdm.tqdm(range(0, len(input_df))):\n",
    "    #Do not calculate on zero values as intercept will be applied in the regressoin\n",
    "    if np.sum(input_df.iloc[i,0]) != 0:\n",
    "        #Assign a temporary dataframe with values that the statsmodels model is expecting\n",
    "        temp_df = pd.DataFrame({var_one: input_df.iloc[i,0], var_two: input_df.iloc[i,1]}, index=['temp_vals'])\n",
    "        #Calculate the voxelwise predicted outcome at a given voxel\n",
    "        responses.append(results.predict(temp_df)[0])\n",
    "    else:\n",
    "        #If voxel is zero-connectivity, assign zero so as to avoid application of intercept\n",
    "        responses.append(0)\n",
    "        \n",
    "#Store responses in a dataframe\n",
    "response_df = pd.DataFrame()\n",
    "response_df['response_topology'] = responses\n",
    "display(response_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Place back in brain mask\n",
    "mask_data[brain_indices] = response_df.loc[:, 'response_topology']\n",
    "response_toplogy = mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "matrix_img = view_and_save_nifti(response_toplogy, out_dir)\n",
    "matrix_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Driven Search for Most Relevant Regressors\n",
    "Combines:\n",
    "- All possible subsets regression combined with leave-one-out cross validation\n",
    "- Identifies formula with lowest RMSE and highest Pearson Correlation of predictor to observed outcome values\n",
    "- Presents the optimal formulas and allows selection of which formula to interpret with structural analysis and coefficient analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_interaction_terms(df, predictors, max_interaction_level=3):\n",
    "    interaction_df = df[predictors].copy()\n",
    "\n",
    "    def add_interaction_terms(df, columns, interaction_level):\n",
    "        if interaction_level == 1:\n",
    "            return df\n",
    "\n",
    "        for col_combination in itertools.combinations(columns, interaction_level):\n",
    "            interaction_term = ':'.join(col_combination)\n",
    "            interaction_values = np.prod(df[list(col_combination)], axis=1)\n",
    "            df[interaction_term] = interaction_values\n",
    "\n",
    "        return add_interaction_terms(df, columns, interaction_level - 1)\n",
    "\n",
    "    return add_interaction_terms(interaction_df, predictors, max_interaction_level)\n",
    "\n",
    "def loocv_regression(df, interaction_df, formula, outcome_var):\n",
    "    full_df = interaction_df.copy()\n",
    "    full_df[outcome_var] = df[outcome_var]\n",
    "    model = sm.formula.ols(formula, data=full_df).fit()\n",
    "    y_actual, y_predicted = [], []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_test = interaction_df.iloc[[i]]\n",
    "        x_train = interaction_df.drop(i)\n",
    "        y_train = df[outcome_var].drop(i)\n",
    "        \n",
    "        model_train_df = x_train.join(y_train)\n",
    "        model_train = sm.formula.ols(formula, data=model_train_df).fit()\n",
    "        y_actual.append(df[outcome_var].iloc[i])\n",
    "        y_predicted.append(model_train.predict(x_test).values[0])\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "    corr, _ = pearsonr(y_actual, y_predicted)\n",
    "    return rmse, corr\n",
    "\n",
    "def all_subsets_regression(df, outcome_var):\n",
    "    predictor_columns = [col for col in df.columns if col != outcome_var]\n",
    "    interaction_df = generate_interaction_terms(df, predictor_columns, max_interaction_level=3)\n",
    "\n",
    "    results = []\n",
    "    for n_predictors in tqdm(range(1, len(predictor_columns) + 1)):\n",
    "        for predictor_combination in itertools.combinations(predictor_columns, n_predictors):\n",
    "            formula = f\"{outcome_var} ~ {' + '.join(predictor_combination)}\"\n",
    "            loocv_rmse, loocv_corr = loocv_regression(df, interaction_df, formula, outcome_var)\n",
    "\n",
    "            results.append({\n",
    "                'formula': formula,\n",
    "                'rmse': loocv_rmse,\n",
    "                'correlation': loocv_corr\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.sort_values(by='correlation', ascending=False, inplace=True)\n",
    "    results_df.reset_index(drop=True, inplace=True)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def all_subsets_regression_no_loocv(df, outcome_var):\n",
    "    predictor_columns = [col for col in df.columns if col != outcome_var]\n",
    "\n",
    "    results = []\n",
    "    for n_predictors in tqdm(range(1, len(predictor_columns) + 1)):\n",
    "        for predictor_combination in itertools.combinations(predictor_columns, n_predictors):\n",
    "            formula = f\"{outcome_var} ~ {' + '.join(predictor_combination)}\"\n",
    "            model = sm.formula.ols(formula, data=df).fit()\n",
    "\n",
    "            y_actual = df[outcome_var].values\n",
    "            y_predicted = model.predict(df[predictor_columns])\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "            corr, _ = pearsonr(y_actual, y_predicted)\n",
    "\n",
    "            results.append({\n",
    "                'formula': formula,\n",
    "                'rmse': rmse,\n",
    "                'correlation': corr\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.sort_values(by='correlation', ascending=False, inplace=True)\n",
    "    results_df.reset_index(drop=True, inplace=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def all_subsets_regression(df, outcome_var, limit_to_two_way_interactions=False):\n",
    "    predictor_columns = [col for col in df.columns if col != outcome_var]\n",
    "\n",
    "    results = []\n",
    "    for n_predictors in tqdm(range(1, len(predictor_columns) + 1)):\n",
    "        for predictor_combination in itertools.combinations(predictor_columns, n_predictors):\n",
    "            # Check whether to limit interactions to two-way\n",
    "            if limit_to_two_way_interactions and n_predictors > 1:\n",
    "                # Generate combinations for two-way interactions\n",
    "                interaction_combinations = itertools.combinations(predictor_combination, 2)\n",
    "                interaction_terms = [' : '.join(interaction) for interaction in interaction_combinations]\n",
    "                # Include both individual predictors and interaction terms\n",
    "                formula = f\"{outcome_var} ~ {' + '.join(predictor_combination)} + {' + '.join(interaction_terms)}\"\n",
    "            else:\n",
    "                # Original formula generation with all possible interactions\n",
    "                formula = f\"{outcome_var} ~ {' * '.join(predictor_combination)}\"\n",
    "            \n",
    "            print(formula)\n",
    "            loocv_rmse, loocv_corr = loocv_regression(df, formula, outcome_var)\n",
    "\n",
    "            results.append({\n",
    "                'formula': formula,\n",
    "                'rmse': loocv_rmse,\n",
    "                'correlation': loocv_corr\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.sort_values(by='correlation', ascending=False, inplace=True)\n",
    "    results_df.reset_index(drop=True, inplace=True)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def loocv_regression(df, formula, outcome_var):\n",
    "    model = sm.formula.ols(formula, data=df).fit()\n",
    "    y_actual, y_predicted = [], []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        index_label = df.index[i]\n",
    "        x_test = df.iloc[[i]].drop(outcome_var, axis=1)\n",
    "        x_train = df.drop(index_label).drop(outcome_var, axis=1)\n",
    "        y_train = df[outcome_var].drop(index_label)\n",
    "\n",
    "        model_train_df = x_train.join(y_train)\n",
    "        model_train = sm.formula.ols(formula, data=model_train_df).fit()\n",
    "        y_actual.append(df[outcome_var].iloc[i])\n",
    "        y_predicted.append(model_train.predict(x_test).values[0])\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "    corr, _ = pearsonr(y_actual, y_predicted)\n",
    "    return rmse, corr\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# outcome_var = 'your_outcome_variable'\n",
    "# results_df = all_subsets_regression(df, outcome_var)\n",
    "# print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = 'outcome'\n",
    "limit_to_two_way_interactions = False\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "df = data_df.copy()\n",
    "results_df = all_subsets_regression(df, outcome_var, limit_to_two_way_interactions=limit_to_two_way_interactions)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 20 formulas by Correlation of y-hat to y')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 20 formulas by RMSE of y-hat to y')\n",
    "# Sort DataFrame by 'rmse' in ascending order\n",
    "rmse_df = results_df.copy().sort_values(by='rmse', ascending=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "rmse_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing top 5 formulas\n",
    "\n",
    "top_five_formulas = results_df.head(5)['formula']\n",
    "print(\"Top 5 Formulas:\")\n",
    "print(top_five_formulas)\n",
    "\n",
    "\n",
    "print('---Lowest RMSE Information---')\n",
    "index_of_min_rmse = results_df['rmse'].idxmin()\n",
    "print(results_df.loc[index_of_min_rmse, 'formula'])\n",
    "print('RMSE: ',results_df.loc[index_of_min_rmse, 'rmse'])\n",
    "print('Pearson R: ', results_df.loc[index_of_min_rmse, 'correlation'])\n",
    "print('Formula index: ', index_of_min_rmse)\n",
    "\n",
    "print('\\n---Highest Correlation Information---')\n",
    "index_of_max_corr = results_df['correlation'].idxmax()\n",
    "print(results_df.loc[index_of_max_corr, 'formula'])\n",
    "print('RMSE: ',results_df.loc[index_of_max_corr, 'rmse'])\n",
    "print('Pearson R: ', results_df.loc[index_of_max_corr, 'correlation'])\n",
    "print('Formula index: ', index_of_max_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "formula_to_test = 0\n",
    "#----------------------------------------------------------------\n",
    "results = smf.ols(results_df.loc[formula_to_test, 'formula'], data=df).fit()\n",
    "# results = smf.ols('percent_change_adascog11 ~ Subiculum*Age*total_hippocampal_csf*frontal', data=data_df).fit()\n",
    "\n",
    "\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_measurements import model_diagnostics\n",
    "model_diagnostics(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Optimal Interaction Subset of Optimal Model by Backward Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import itertools\n",
    "\n",
    "\n",
    "def backward_subsets_loocv_regression(df, formula):\n",
    "    # Extract outcome_var from the formula\n",
    "    outcome_var = formula.split(' ~ ')[0].strip()\n",
    "    \n",
    "    y_actual, y_predicted = [], []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        index_label = df.index[i]\n",
    "        x_test = df.iloc[[i]].drop(outcome_var, axis=1)\n",
    "        x_train = df.drop(index_label).drop(outcome_var, axis=1)\n",
    "        y_train = df[outcome_var].drop(index_label)\n",
    "\n",
    "        model_train_df = x_train.join(y_train)\n",
    "        model_train = smf.ols(formula, data=model_train_df).fit()\n",
    "        y_actual.append(df[outcome_var].iloc[i])\n",
    "        y_predicted.append(model_train.predict(x_test).values[0])\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "    corr, _ = pearsonr(y_actual, y_predicted)\n",
    "    return rmse, corr\n",
    "\n",
    "\n",
    "def serial_interaction_removal_loocv(df, formula):\n",
    "    # Split the formula into the left and right side\n",
    "    left, right = formula.split(\"~\")\n",
    "    \n",
    "    # Get all the terms from the right side of the formula\n",
    "    terms = right.strip().split(\"*\")\n",
    "    terms = [term.strip() for term in terms]\n",
    "    \n",
    "    # Generate all combinations of + and *\n",
    "    operators_combinations = itertools.product([\"+\", \"*\"], repeat=len(terms)-1)\n",
    "    \n",
    "    # Generate the formulas\n",
    "    formulas = []\n",
    "    for operators in operators_combinations:\n",
    "        combined_formula = left + \" ~ \" + terms[0]\n",
    "        for op, term in zip(operators, terms[1:]):\n",
    "            combined_formula += \" \" + op + \" \" + term\n",
    "        formulas.append(combined_formula.strip())\n",
    "\n",
    "    # Run LOOCV on each formula\n",
    "    loocv_results = []\n",
    "    for sub_formula in formulas:\n",
    "        loocv_rmse, loocv_corr = backward_subsets_loocv_regression(df, sub_formula)\n",
    "        loocv_results.append({\n",
    "            'formula': sub_formula,\n",
    "            'rmse': loocv_rmse,\n",
    "            'correlation': loocv_corr\n",
    "        })\n",
    "    \n",
    "    # Convert results to DataFrame, sort by correlation and reset index\n",
    "    loocv_results_df = pd.DataFrame(loocv_results)\n",
    "    loocv_results_df.sort_values(by='correlation', ascending=False, inplace=True)\n",
    "    loocv_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return loocv_results_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `df` is your DataFrame, and `formula` is a string like \"y ~ a * b * c\"\n",
    "# best_formula = \"y ~ a * b * c\"\n",
    "# serial_loocv_df = serial_interaction_removal_loocv(df, best_formula)\n",
    "# print(serial_loocv_df)\n",
    "\n",
    "best_formula = results_df.loc[formula_to_test, 'formula']\n",
    "optimal_interaction_loocv_df = serial_interaction_removal_loocv(df, best_formula)\n",
    "optimal_interaction_loocv_df.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Coefficient Analysis of Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "def structural_coefficients(model, data):\n",
    "    # Extracting the predictor names\n",
    "    predictor_names = model.model.exog_names\n",
    "    if 'Intercept' in predictor_names:\n",
    "        predictor_names.remove('Intercept')\n",
    "\n",
    "    # Calculating the predicted values\n",
    "    y_predicted = model.predict(data)\n",
    "\n",
    "    # Creating a temporary dataframe to store interaction terms\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    for pred in predictor_names:\n",
    "        # Check if the predictor is an interaction term\n",
    "        if ':' in pred:\n",
    "            # Split the interaction term into its components\n",
    "            components = pred.split(':')\n",
    "            # Multiply the components and store the result in the temporary dataframe\n",
    "            temp_product = data[components[0]]\n",
    "            for component in components[1:]:\n",
    "                temp_product *= data[component]\n",
    "            temp_df[pred] = temp_product\n",
    "        else:\n",
    "            temp_df[pred] = data[pred]\n",
    "\n",
    "    # Calculating the structural coefficients\n",
    "    structural_coefs = {}\n",
    "    for pred in predictor_names:\n",
    "        coef, _ = pearsonr(temp_df[pred], y_predicted)\n",
    "        structural_coefs[pred] = np.square(coef)\n",
    "\n",
    "    # Creating a dataframe to store the results\n",
    "    structural_coefs_df = pd.DataFrame(structural_coefs.items(), columns=['predictor', 'structural_coefficient'])\n",
    "\n",
    "    # Sorting the dataframe by the structural coefficients in descending order\n",
    "    structural_coefs_df.sort_values(by='structural_coefficient', ascending=False, inplace=True)\n",
    "    structural_coefs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return structural_coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "def structural_coefficients(model: statsmodels.regression.linear_model.RegressionResultsWrapper, \n",
    "                            data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the structural coefficients of a linear regression model, along with their \n",
    "    associated model coefficients (beta weights). It also computes a 'suppressor index' which indicates \n",
    "    the likelihood of a variable being a suppressor variable (high beta weight, near-zero structural coefficient).\n",
    "    A suppressor index over 10 is a good heuristic for identifying a suppressor variable\n",
    "    \n",
    "    Parameters:\n",
    "    model (statsmodels.regression.linear_model.RegressionResultsWrapper): The fitted linear regression model.\n",
    "    data (pd.DataFrame): The dataset used in the model.\n",
    "    \n",
    "    Returns:\n",
    "    structural_coefs_df (pd.DataFrame): A dataframe containing the predictors, their structural coefficients,\n",
    "                                        model coefficients (beta weights), and suppressor index.\n",
    "                                        \n",
    "                                        If the sum of the structure coefficients is higher than 1, they are correlated (multicollinear)\n",
    "    \"\"\"\n",
    "    # Calculating the predicted values\n",
    "    y_predicted = model.predict(data)\n",
    "\n",
    "    # Creating a temporary dataframe to store interaction terms\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    # Calculating the structural coefficients\n",
    "    structural_coefs = {}\n",
    "    for pred in model.params.index:\n",
    "        if pred == 'Intercept':\n",
    "            continue\n",
    "\n",
    "        # Check if the predictor is an interaction term\n",
    "        if ':' in pred:\n",
    "            # Split the interaction term into its components\n",
    "            components = pred.split(':')\n",
    "            # Multiply the components and store the result in the temporary dataframe\n",
    "            temp_product = data[components[0]]\n",
    "            for component in components[1:]:\n",
    "                temp_product *= data[component]\n",
    "            temp_df[pred] = temp_product\n",
    "        else:\n",
    "            temp_df[pred] = data[pred]\n",
    "        \n",
    "        coef, _ = pearsonr(temp_df[pred], y_predicted)\n",
    "        structural_coefs[pred] = np.square(coef)\n",
    "\n",
    "    # Calculating the model coefficients\n",
    "    model_coefs = model.params.drop('Intercept')\n",
    "\n",
    "    # Creating a dataframe to store the results\n",
    "    structural_coefs_df = pd.DataFrame(list(zip(structural_coefs.keys(), structural_coefs.values(), model_coefs.values)), \n",
    "                                       columns=['predictor', 'structural_coefficient', 'model_coefficient'])\n",
    "\n",
    "    # Adding suppressor index column\n",
    "    structural_coefs_df['suppressor_index'] = structural_coefs_df['model_coefficient'].abs() / structural_coefs_df['structural_coefficient']\n",
    "\n",
    "    # Sorting the dataframe by the structural coefficients in descending order\n",
    "    structural_coefs_df.sort_values(by='structural_coefficient', ascending=False, inplace=True)\n",
    "    structural_coefs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return structural_coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_structural_coefs_df = structural_coefficients(results, df.copy())\n",
    "squared_structural_coefs_df.to_csv(os.path.join(out_dir, 'structural_coefficient_analysis.csv'))\n",
    "print('saved to: ', os.path.join(out_dir, 'structural_coefficient_analysis.csv'))\n",
    "display(squared_structural_coefs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the sum of the structure coefficients is higher than 1, they are correlated\n",
    "print(squared_structural_coefs_df.loc[:, 'structural_coefficient'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary2())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check optimal model without LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "no_loocv_results_df = all_subsets_regression_no_loocv(df, outcome_var)\n",
    "no_loocv_results_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing top 5 formulas\n",
    "no_loocv_top_five_formulas = no_loocv_results_df.head(10)['formula']\n",
    "print(\"Top 5 Formulas:\")\n",
    "print(no_loocv_top_five_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "formula_to_test = 0\n",
    "#----------------------------------------------------------------\n",
    "results = smf.ols(no_loocv_results_df.loc[formula_to_test, 'formula'], data=df).fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (nimlab)",
   "language": "python",
   "name": "nimlab_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62880161f19d28ddb8a8f59c63374d84ace356c39e36cc839cb3fb3bb03fb010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
