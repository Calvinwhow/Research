{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Convert PDFs to Text\n",
    "\n",
    "Define pdf_dir - this is the absolute path to the directory with all PDF files you want evaluated\n",
    "\n",
    "Define output_dir - this is the absolute path to the directory to output all the preprocessed PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = r'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/writes/test'\n",
    "output_dir = r\"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/ocr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess Using Text Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textract\n",
    "\n",
    "class PDFTextExtractor:\n",
    "    \"\"\"\n",
    "    A class to handle PDF text extraction and saving it to a file.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    extract_text_from_pdf(file_path: str) -> str:\n",
    "        Extracts text from a given PDF file and returns it as a string.\n",
    "    save_text_to_file(text: str, output_file_path: str) -> None:\n",
    "        Saves a given text string to a specified file path.\n",
    "    extract_text_from_pdf_dir(pdf_dir: str, output_dir: str) -> None:\n",
    "        Iterates through a directory of PDF files, extracts text, and saves it to text files in an output directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf(file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extracts text from a given PDF file and returns it as a string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            The path of the PDF file to extract text from.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The extracted text as a string.\n",
    "        \"\"\"\n",
    "        text = textract.process(file_path)\n",
    "        return text.decode(\"utf-8\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_text_to_file(text: str, output_file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Saves a given text string to a specified file path.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The text string to save.\n",
    "        output_file_path : str\n",
    "            The path where the text file will be saved.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(text)\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf_dir(pdf_dir: str, output_dir: str) -> None:\n",
    "        \"\"\"\n",
    "        Iterates through a directory of PDF files, extracts text, and saves it to text files in an output directory.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdf_dir : str\n",
    "            The directory containing the PDF files.\n",
    "        output_dir : str\n",
    "            The directory where text files will be saved.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        for file_name in os.listdir(pdf_dir):\n",
    "            if file_name.endswith(\".pdf\"):\n",
    "                input_file_path = os.path.join(pdf_dir, file_name)\n",
    "                output_file_path = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}.txt\")\n",
    "                text = PDFTextExtractor.extract_text_from_pdf(input_file_path)\n",
    "                PDFTextExtractor.save_text_to_file(text, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the PDFTextExtractor class\n",
    "pdf_extractor = PDFTextExtractor()\n",
    "# Call the extract_text_from_pdf_dir method\n",
    "pdf_extractor.extract_text_from_pdf_dir(pdf_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract Tezt Using OCR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class OCROperator:\n",
    "    \"\"\"\n",
    "    A class to handle OCR text extraction from PDFs in a directory.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    extract_text_from_pdf(file_path: str) -> str:\n",
    "        Extracts text from a given PDF file using OCR and returns it as a string.\n",
    "    save_text_to_file(text: str, output_file_path: str) -> None:\n",
    "        Saves the extracted text to a specified file path.\n",
    "    extract_text_from_pdf_dir(pdf_dir: str, output_dir: str) -> None:\n",
    "        Iterates through a directory of PDF files and extracts text using OCR.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_image(image):\n",
    "        \"\"\"\n",
    "        Preprocesses the image for OCR.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : PIL.Image.Image\n",
    "            The image to preprocess.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        PIL.Image.Image\n",
    "            The preprocessed image.\n",
    "        \"\"\"\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        # Convert the image to binary (black and white)\n",
    "        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        return binary\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf(file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extracts text from a PDF using OCR and returns it as a string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            The path of the PDF file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The OCR-extracted text.\n",
    "        \"\"\"\n",
    "        images = convert_from_path(file_path)\n",
    "        text = \"\"\n",
    "\n",
    "        for image in images:\n",
    "            text += pytesseract.image_to_string(image)\n",
    "\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def save_text_to_file(text: str, output_file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Saves the extracted text to a specified file path.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The text to save.\n",
    "        output_file_path : str\n",
    "            The file path to save the text to.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf_dir(pdf_dir: str, output_dir: str) -> None:\n",
    "        \"\"\"\n",
    "        Iterates through a directory of PDF files and extracts text using OCR.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdf_dir : str\n",
    "            The directory containing the PDF files.\n",
    "        output_dir : str\n",
    "            The directory to save the extracted text to.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        for file_name in tqdm(os.listdir(pdf_dir)):\n",
    "            if file_name.endswith('.pdf'):\n",
    "                input_file_path = os.path.join(pdf_dir, file_name)\n",
    "                output_file_path = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}_OCR.txt\")\n",
    "\n",
    "                text = OCROperator.extract_text_from_pdf(input_file_path)\n",
    "                OCROperator.save_text_to_file(text, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCROperator.extract_text_from_pdf_dir(pdf_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 - Preprocess the Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Updated TextPreprocessor class without removing newlines\n",
    "class TextPreprocessor:\n",
    "    \"\"\"\n",
    "    A class to preprocess text files in a directory.\n",
    "\n",
    "    Attributes:\n",
    "    - input_dir (str): The directory containing the text files to be preprocessed.\n",
    "    - output_dir (str): The directory where the preprocessed text files will be saved.\n",
    "\n",
    "    Methods:\n",
    "    - preprocess_text: Applies various preprocessing steps to a given text.\n",
    "    - remove_non_ascii: Removes non-ASCII characters from the text.\n",
    "    - process_files: Reads each text file from the input directory, applies preprocessing, and saves it to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dir, output_dir):\n",
    "        \"\"\"\n",
    "        Initializes the TextPreprocessor class with input and output directories.\n",
    "\n",
    "        Parameters:\n",
    "        - input_dir (str): Path to the directory containing the text files to be preprocessed.\n",
    "        - output_dir (str): Path to the directory where the preprocessed text files will be saved.\n",
    "        \"\"\"\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_text(text):\n",
    "        \"\"\"\n",
    "        Applies various preprocessing steps to a given text.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The text to be preprocessed.\n",
    "\n",
    "        Returns:\n",
    "        - str: The preprocessed text.\n",
    "        \"\"\"\n",
    "        text = re.sub(r'([,.:;])', r'\\1 ', text)\n",
    "        text = re.sub(r'([(])', r' \\1', text)\n",
    "        text = re.sub(r'([)])', r'\\1 ', text)\n",
    "        text = re.sub(r'(?<![a-zA-Z0-9-])-(?![a-zA-Z0-9-])', r' - ', text)\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_non_ascii(text):\n",
    "        \"\"\"\n",
    "        Removes non-ASCII characters from the text.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The text from which non-ASCII characters will be removed.\n",
    "\n",
    "        Returns:\n",
    "        - str: The text with non-ASCII characters removed.\n",
    "        \"\"\"\n",
    "        return re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    def process_files(self):\n",
    "        \"\"\"\n",
    "        Reads each text file from the input directory, applies preprocessing, and saves it to the output directory.\n",
    "        \"\"\"\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "        \n",
    "        # Loop through each file in the input directory\n",
    "        for filename in os.listdir(self.input_dir):\n",
    "            if filename.endswith('.txt'):\n",
    "                input_filepath = os.path.join(self.input_dir, filename)\n",
    "                output_filepath = os.path.join(self.output_dir, filename)\n",
    "                \n",
    "                # Read the original text\n",
    "                with open(input_filepath, 'r', encoding='utf-8') as input_file:\n",
    "                    original_text = input_file.read()\n",
    "                \n",
    "                # Apply preprocessing\n",
    "                preprocessed_text = self.preprocess_text(original_text)\n",
    "                cleaned_text = self.remove_non_ascii(preprocessed_text)\n",
    "                \n",
    "                # Save the preprocessed text\n",
    "                with open(output_filepath, 'w', encoding='utf-8') as output_file:\n",
    "                    output_file.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/ocr\"\n",
    "output_dir = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/ocr/preprocessed\"\n",
    "# Initialize the TextPreprocessor class and preprocess the files\n",
    "preprocessor = TextPreprocessor(input_dir, output_dir)\n",
    "preprocessor.process_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03 - Label Text Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Text Chunking Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "class TextChunker:\n",
    "    \"\"\"\n",
    "    A class to chunk a given text into smaller segments based on a token limit.\n",
    "    \n",
    "    Attributes:\n",
    "    - text (str): The text to be chunked.\n",
    "    - token_limit (int): The maximum number of tokens allowed in each chunk.\n",
    "    - chunks (list): List to store the generated text chunks.\n",
    "    \n",
    "    Methods:\n",
    "    - chunk_text: Splits the text into smaller segments based on the token limit.\n",
    "    - get_chunks: Returns the list of generated text chunks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text, token_limit):\n",
    "        \"\"\"\n",
    "        Initializes the TextChunker class with the text and token limit.\n",
    "        \n",
    "        Parameters:\n",
    "        - text (str): The text to be chunked.\n",
    "        - token_limit (int): The maximum number of tokens allowed in each chunk.\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.token_limit = token_limit\n",
    "        self.chunks = []\n",
    "    \n",
    "    def chunk_text(self):\n",
    "        \"\"\"\n",
    "        Splits the text into smaller segments based on the token limit.\n",
    "        \"\"\"\n",
    "        words = self.text.split()\n",
    "        current_chunk = []\n",
    "        current_chunk_tokens = 0\n",
    "        \n",
    "        for word in words:\n",
    "            # Considering each word as a token and adding 1 for the space\n",
    "            tokens_in_word = len(word.split()) + 1\n",
    "            \n",
    "            if current_chunk_tokens + tokens_in_word <= self.token_limit:\n",
    "                current_chunk.append(word)\n",
    "                current_chunk_tokens += tokens_in_word\n",
    "            else:\n",
    "                self.chunks.append(' '.join(current_chunk))\n",
    "                current_chunk = [word]\n",
    "                current_chunk_tokens = tokens_in_word\n",
    "        \n",
    "        # Adding the last chunk if any words are left\n",
    "        if current_chunk:\n",
    "            self.chunks.append(' '.join(current_chunk))\n",
    "    \n",
    "    def get_chunks(self):\n",
    "        \"\"\"\n",
    "        Returns the list of generated text chunks.\n",
    "        \n",
    "        Returns:\n",
    "        - list: List containing the generated text chunks.\n",
    "        \"\"\"\n",
    "        return self.chunks\n",
    "    \n",
    "# > Example Usage:\n",
    "# # Setting the token limit to 75% of GPT-3's maximum token limit (4096)\n",
    "# token_limit = int(0.75 * 4096)  # About 3072 tokens\n",
    "\n",
    "# # Reading the text file\n",
    "# file_path = '/mnt/data/Horn 2017PD Fxconn_OCR.txt'\n",
    "# with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Creating an instance of the TextChunker class\n",
    "# text_chunker = TextChunker(text, token_limit)\n",
    "\n",
    "# # Chunking the text\n",
    "# text_chunker.chunk_text()\n",
    "\n",
    "# # Getting the list of chunks\n",
    "# chunks = text_chunker.get_chunks()\n",
    "\n",
    "# # Displaying the first chunk as a sample\n",
    "# chunks[0][:500]  # Displaying the first 500 characters of the first chunk as a sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Natural Language Processing Software\n",
    "\n",
    "Latent Dirichlet Allocation approach employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the JSON serialization issue by converting NumPy int64 to native Python int\n",
    "\n",
    "class SectionLabeler:\n",
    "    \"\"\"\n",
    "    A class to label sections of a given text based on chunking and topic modeling.\n",
    "    \n",
    "    Attributes:\n",
    "    - folder_path (str): The path to the folder containing the text files.\n",
    "    - article_type (str): The type of article (e.g., 'research', 'case_report').\n",
    "    - lda (LatentDirichletAllocation): The Latent Dirichlet Allocation model for topic modeling.\n",
    "    \n",
    "    Methods:\n",
    "    - label_sections: Labels the sections of each text file in the folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, folder_path, article_type):\n",
    "        \"\"\"\n",
    "        Initializes the SectionLabeler class with the folder path and article type.\n",
    "        \n",
    "        Parameters:\n",
    "        - folder_path (str): The path to the folder containing the text files.\n",
    "        - article_type (str): The type of article (e.g., 'research', 'case_report').\n",
    "        \"\"\"\n",
    "        self.folder_path = folder_path\n",
    "        self.article_type = article_type\n",
    "        self.lda = LatentDirichletAllocation(n_components=7, random_state=42) # Number of topics can be adjusted\n",
    "    \n",
    "    def label_sections(self):\n",
    "        \"\"\"\n",
    "        Labels the sections of each text file in the folder.\n",
    "        \"\"\"\n",
    "        for filename in os.listdir(self.folder_path):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                file_path = os.path.join(self.folder_path, filename)\n",
    "                \n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "                \n",
    "                # Chunk the text using TextChunker\n",
    "                chunker = TextChunker(text, int(4096 * 0.75))  # 75% of the maximum token limit of 4096\n",
    "                chunker.chunk_text()\n",
    "                chunks = chunker.get_chunks()\n",
    "                \n",
    "                # Vectorize the text chunks for topic modeling\n",
    "                vectorizer = CountVectorizer()\n",
    "                dtm = vectorizer.fit_transform(chunks)\n",
    "                \n",
    "                # Fit LDA model to the document-term matrix\n",
    "                self.lda.fit(dtm)\n",
    "                \n",
    "                # Get the topic for each chunk\n",
    "                topic_results = self.lda.transform(dtm)\n",
    "                chunk_labels = topic_results.argmax(axis=1)\n",
    "                \n",
    "                # Store chunk and its label in a dictionary\n",
    "                labeled_chunks = {}\n",
    "                for i, label in enumerate(chunk_labels):\n",
    "                    labeled_chunks[f\"Chunk_{i+1}\"] = {\"text\": chunks[i], \"topic\": int(label)}  # Convert to native int\n",
    "                \n",
    "                # Save the labeled chunks to a JSON file\n",
    "                json_filename = filename.replace('.txt', '_labeled.json')\n",
    "                json_file_path = os.path.join(self.folder_path, json_filename)\n",
    "                \n",
    "                with open(json_file_path, 'w', encoding='utf-8') as json_f:\n",
    "                    json.dump(labeled_chunks, json_f, ensure_ascii=False, indent=4)\n",
    "# > Example Usage:\n",
    "# # Initialize and run the SectionLabeler\n",
    "# labeler = SectionLabeler(\"/mnt/data\", \"research\")\n",
    "# labeler.label_sections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define OpenAI Labelling Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # Make sure to install the OpenAI package\n",
    "\n",
    "class OpenAIEvaluator:\n",
    "    \"\"\"\n",
    "    A class to evaluate text chunks using the OpenAI API based on the type of article.\n",
    "\n",
    "    Attributes:\n",
    "    - api_key (str): OpenAI API key.\n",
    "    - article_type (str): The type of article (e.g., 'research', 'case').\n",
    "    - questions (dict): Dictionary mapping article types to evaluation questions.\n",
    "\n",
    "    Methods:\n",
    "    - __init__: Initializes the OpenAIEvaluator class with the API key path and article type.\n",
    "    - read_api_key: Reads the OpenAI API key from a file.\n",
    "    - evaluate_with_openai: Evaluates a text chunk based on the question corresponding to the article type.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key_path):\n",
    "        \"\"\"\n",
    "        Initializes the OpenAIEvaluator class.\n",
    "\n",
    "        Parameters:\n",
    "        - api_key_path (str): Path to the file containing the OpenAI API key.\n",
    "        - article_type (str): The type of article (e.g., 'research', 'case').\n",
    "        \"\"\"\n",
    "        self.api_key = self.read_api_key(api_key_path)\n",
    "        openai.api_key = self.api_key\n",
    "\n",
    "    def read_api_key(self, file_path):\n",
    "        \"\"\"\n",
    "        Reads the OpenAI API key from a file.\n",
    "\n",
    "        Parameters:\n",
    "        - file_path (str): Path to the file containing the OpenAI API key.\n",
    "\n",
    "        Returns:\n",
    "        - str: OpenAI API key.\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.readline().strip()\n",
    "\n",
    "    def evaluate_with_openai(self, chunk, questions):\n",
    "        \"\"\"\n",
    "        Evaluates a chunk based on multiple posed questions using OpenAI API.\n",
    "\n",
    "        Parameters:\n",
    "        - chunk (str): The text chunk to be evaluated.\n",
    "        - questions (list): A list of questions for evaluation.\n",
    "\n",
    "        Returns:\n",
    "        - dict: A dictionary where keys are questions and values are binary decisions (0 or 1).\n",
    "        \"\"\"\n",
    "        question_list = list(questions.keys())\n",
    "        question_prompt = \"\\n\".join([f\"{q}\" for q in question_list])\n",
    "        prompt = f\"Text Chunk: {chunk}\\n{question_prompt}\"\n",
    "\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"gpt-3.5-turbo-16k-0613\",\n",
    "                prompt=prompt,\n",
    "                max_tokens=10  # Adjust as needed\n",
    "            )\n",
    "            decision_text = response.choices[0].text.strip()\n",
    "            decisions = decision_text.split(\"\\n\")\n",
    "            \n",
    "            if len(decisions) != len(questions):\n",
    "                print(\"Warning: The number of decisions does not match the number of questions.\")\n",
    "                valid_decisions = [line.strip() for line in decisions if line.strip()]\n",
    "                if len(valid_decisions) != len(questions):\n",
    "                    decisions = valid_decisions\n",
    "                    print(\"Solved warning.\")\n",
    "                else:\n",
    "                    print('Decisions here, returning None: ', decisions)\n",
    "                    return None\n",
    "\n",
    "            return {q: 1 if \"Y\" in d else 0 for q, d in zip(questions, decisions)}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return \"Unidentified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "class SectionLabeler:\n",
    "    \"\"\"\n",
    "    A class to label sections of a text document using LDA and OpenAI's GPT-3.\n",
    "\n",
    "    Attributes:\n",
    "    - folder_path (str): The path to the folder containing text files.\n",
    "    - article_type (str): The type of article (e.g., 'research', 'case').\n",
    "    - lda_model (object): The trained LDA model for topic modeling.\n",
    "    - vectorizer (object): The CountVectorizer object for text vectorization.\n",
    "    - chunker (object): The TextChunker object for text chunking.\n",
    "    - api_key (str): The OpenAI API key. [Replace with actual API key later]\n",
    "\n",
    "    Methods:\n",
    "    - train_lda: Trains the LDA model based on the text chunks.\n",
    "    - dominant_topic: Finds the dominant topic for a given text chunk.\n",
    "    - label_with_openai: Labels a section based on the dominant topic using OpenAI's GPT-3.\n",
    "    - process_files: Processes all text files in the specified folder.\n",
    "    - save_to_json: Saves the labeled sections to a JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder_path, article_type, api_key_path=None, label_method='LDA'):\n",
    "        \"\"\"\n",
    "        Initializes the SectionLabeler class with the folder path and article type.\n",
    "\n",
    "        Parameters:\n",
    "        - api_key_path (str): Path to the file containing the OpenAI API key.\n",
    "        - article_type (str): The type of article (e.g., 'research' or 'case').\n",
    "        - folder_path (str): The path to the folder containing text files.\n",
    "        - article_type (str): The type of article (e.g., 'research', 'case').\n",
    "        \"\"\"\n",
    "        self.folder_path = folder_path\n",
    "        self.article_type = article_type\n",
    "        self.api_key_path = api_key_path\n",
    "        self.lda_model = None\n",
    "        self.vectorizer = None\n",
    "        self.chunker = None\n",
    "        self.label_method = label_method\n",
    "        self.token_max = 4098\n",
    "        self.token_safety = 0.4\n",
    "\n",
    "\n",
    "    def select_labels(self):\n",
    "        # Define section labels for each article type\n",
    "        if self.article_type == \"research\":\n",
    "            self.section_headers = {\n",
    "            \"Abstract\": [\"Abstract\"],\n",
    "            \"Introduction\": [\"Background\", \"Introduction\", \"Intro\"],\n",
    "            \"Methods\": [\"Methods\", \"Materials\", \"Material and Methods\", \"Materials & Methods\", \"Methodology\", \"Subjects and Methods\"],\n",
    "            \"Results\": [\"Results\", \"Findings\"],\n",
    "            \"Discussion\": [\"Discussion\", \"Interpretation\"],\n",
    "            \"Conclusion\": [\"Conclusion\", \"Summary\"],\n",
    "            \"References\": [\"References\", \"Bibliography\", \"Citations\"]\n",
    "            }\n",
    "        if self.article_type == \"case\":\n",
    "            self.section_headers = {\n",
    "            \"Abstract\": [\"Abstract\"],\n",
    "            \"Introduction\": [\"Background\", \"Introduction\", \"Intro\"],\n",
    "            \"Methods\": [\"Methods\", \"Materials\", \"Material and Methods\", \"Materials & Methods\", \"Methodology\", \"Subjects and Methods\"],\n",
    "            \"Results\": [\"Results\", \"Findings\"],\n",
    "            \"Discussion\": [\"Discussion\", \"Interpretation\"],\n",
    "            \"Conclusion\": [\"Conclusion\", \"Summary\"],\n",
    "            \"References\": [\"References\", \"Bibliography\", \"Citations\"]\n",
    "            }\n",
    "        else:\n",
    "            self.section_headers = {\n",
    "            \"Abstract\": [\"Abstract\"],\n",
    "            \"Introduction\": [\"Background\", \"Introduction\", \"Intro\"],\n",
    "            \"Methods\": [\"Methods\", \"Materials\", \"Material and Methods\", \"Materials & Methods\", \"Methodology\", \"Subjects and Methods\"],\n",
    "            \"Results\": [\"Results\", \"Findings\"],\n",
    "            \"Discussion\": [\"Discussion\", \"Interpretation\"],\n",
    "            \"Conclusion\": [\"Conclusion\", \"Summary\"],\n",
    "            \"References\": [\"References\", \"Bibliography\", \"Citations\"]\n",
    "            }\n",
    "            \n",
    "    def get_questions(self):\n",
    "        if self.article_type == \"research\":\n",
    "            return None\n",
    "        elif self.article_type == \"case\":\n",
    "            questions = {'Does this contain a neurological case report? (Y/N)': 'case_report'}\n",
    "            return questions\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def train_lda(self, text_chunks):\n",
    "        \"\"\"\n",
    "        Trains the LDA model based on the text chunks.\n",
    "\n",
    "        Parameters:\n",
    "        - text_chunks (list): List of text chunks.\n",
    "\n",
    "        Returns:\n",
    "        - object: Trained LDA model.\n",
    "        \"\"\"\n",
    "        self.vectorizer = CountVectorizer(min_df=5, max_df=0.9, stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "        data_vectorized = self.vectorizer.fit_transform(text_chunks)\n",
    "        lda_model = LatentDirichletAllocation(n_components=len(self.topic_labels), max_iter=10, learning_method='online')\n",
    "        lda_Z = lda_model.fit_transform(data_vectorized)\n",
    "        self.lda_model = lda_model\n",
    "        return lda_model      \n",
    "    \n",
    "    def train_lda_on_all_files(self):\n",
    "        \"\"\"\n",
    "        Trains the LDA model on text from all files in the specified folder.\n",
    "\n",
    "        Returns:\n",
    "        - object: Trained LDA model.\n",
    "        \"\"\"\n",
    "        all_text_chunks = []\n",
    "\n",
    "        for filename in tqdm(os.listdir(self.folder_path)):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(self.folder_path, filename), 'r') as f:\n",
    "                    text = f.read()\n",
    "\n",
    "                self.chunker = TextChunker(text, np.round(4096*0.75)) # Set to 75% max token limit\n",
    "                self.chunker.chunk_text()\n",
    "                chunks = self.chunker.get_chunks()\n",
    "\n",
    "                all_text_chunks.extend(chunks)\n",
    "\n",
    "        # Train LDA model on all text chunks\n",
    "        return self.train_lda(all_text_chunks)  \n",
    "        \n",
    "    def dominant_topic(self, text_chunk):\n",
    "        \"\"\"\n",
    "        Finds the dominant topic for a given text chunk.\n",
    "\n",
    "        Parameters:\n",
    "        - text_chunk (str): The text chunk to be labeled.\n",
    "\n",
    "        Returns:\n",
    "        - int: Index of the dominant topic.\n",
    "        \"\"\"\n",
    "        text_vectorized = self.vectorizer.transform([text_chunk])\n",
    "        topic_probability_scores = self.lda_model.transform(text_vectorized)\n",
    "        dominant_topic_index = topic_probability_scores.argmax()\n",
    "        return dominant_topic_index\n",
    "    \n",
    "    def label_with_lda(self, text_chunk):\n",
    "        # Get the list of section labels based on the article type\n",
    "        return self.topic_labels[self.dominant_topic(text_chunk)]\n",
    "    \n",
    "    def extract_topic_significant_words(self, dominant_topic_index):\n",
    "        \"\"\"\n",
    "        Extracts significant words for a specific topic in the LDA model.\n",
    "\n",
    "        Parameters:\n",
    "        - dominant_topic_index (int): The index of the dominant topic.\n",
    "\n",
    "        Returns:\n",
    "        - list: Significant words for the dominant topic.\n",
    "        \"\"\"\n",
    "        # Initialize an empty list to store the significant words for the dominant topic\n",
    "        significant_words = []\n",
    "\n",
    "        # Get the topic-word distribution for the dominant topic\n",
    "        topic_word_distribution = self.lda_model.components_[dominant_topic_index]\n",
    "\n",
    "        # Get the indices of the top N significant words\n",
    "        N = 10  # Adjust as needed\n",
    "        top_word_indices = topic_word_distribution.argsort()[-N:][::-1]\n",
    "\n",
    "        # Get the actual words from the vectorizer\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        significant_words = [feature_names[i] for i in top_word_indices]\n",
    "\n",
    "        return significant_words\n",
    "\n",
    "    def label_with_exact_matching(self, text):\n",
    "        labeled_sections = {}\n",
    "        current_section = None\n",
    "        current_text = \"\"\n",
    "\n",
    "        # Adding newline to section labels for exact matching\n",
    "        section_labels_with_newline = []\n",
    "        for labels in self.section_headers.values():\n",
    "            section_labels_with_newline.extend([f\"\\n{label}\\n\" for label in labels])\n",
    "\n",
    "        for line in text.split('\\n'):\n",
    "            if f\"\\n{line}\\n\" in section_labels_with_newline:\n",
    "                if current_section:\n",
    "                    labeled_sections[current_section] = current_text.strip()\n",
    "                current_section = line\n",
    "                current_text = \"\"\n",
    "            else:\n",
    "                current_text += line + \"\\n\"\n",
    "\n",
    "        # Adding the last section\n",
    "        if current_section:\n",
    "            labeled_sections[current_section] = current_text.strip()\n",
    "\n",
    "        return labeled_sections\n",
    "\n",
    "    def label_with_fuzzy_matching(self, text, labeled_sections):\n",
    "        current_section = None\n",
    "        current_text = \"\"\n",
    "\n",
    "        for line in text.split('\\n'):\n",
    "            for section, labels in self.section_headers.items():\n",
    "                if any(fuzz.partial_ratio(line, label) > 80 for label in labels):\n",
    "                    if current_section:\n",
    "                        if current_section not in labeled_sections:\n",
    "                            labeled_sections[current_section] = current_text.strip()\n",
    "                        else:\n",
    "                            labeled_sections[current_section] += \"\\n\" + current_text.strip()\n",
    "                    current_section = section\n",
    "                    current_text = \"\"\n",
    "                    break\n",
    "            else:\n",
    "                current_text += line + \"\\n\"\n",
    "\n",
    "        # Adding the last section\n",
    "        if current_section:\n",
    "            if current_section not in labeled_sections:\n",
    "                labeled_sections[current_section] = current_text.strip()\n",
    "            else:\n",
    "                labeled_sections[current_section] += \"\\n\" + current_text.strip()\n",
    "\n",
    "        return labeled_sections\n",
    "\n",
    "    def label_with_loose_matching(self, text, labeled_sections):\n",
    "        current_section = None\n",
    "        current_text = \"\"\n",
    "\n",
    "        for line in text.split('\\n'):\n",
    "            for section, labels in self.section_headers.items():\n",
    "                if any(re.search(f\"\\\\b{label}\\\\b\", line, re.IGNORECASE) for label in labels):\n",
    "                    if current_section:\n",
    "                        if current_section not in labeled_sections:\n",
    "                            labeled_sections[current_section] = current_text.strip()\n",
    "                        else:\n",
    "                            labeled_sections[current_section] += \"\\n\" + current_text.strip()\n",
    "                    current_section = section\n",
    "                    current_text = \"\"\n",
    "                    break\n",
    "            else:\n",
    "                current_text += line + \"\\n\"\n",
    "\n",
    "        # Adding the last section\n",
    "        if current_section:\n",
    "            if current_section not in labeled_sections:\n",
    "                labeled_sections[current_section] = current_text.strip()\n",
    "            else:\n",
    "                labeled_sections[current_section] += \"\\n\" + current_text.strip()\n",
    "\n",
    "        return labeled_sections\n",
    "\n",
    "    def label_text(self, text, show_residuals=True):\n",
    "        labeled_sections = self.label_with_exact_matching(text)\n",
    "        labeled_sections = self.label_with_fuzzy_matching(text, labeled_sections)\n",
    "        labeled_sections = self.label_with_loose_matching(text, labeled_sections)\n",
    "        \n",
    "        # Check for residual text\n",
    "        labeled_text = \"\".join(list(labeled_sections.values()))\n",
    "        residual_text = set(text) - set(labeled_text)\n",
    "        \n",
    "        if self.label_method=='openai':\n",
    "            # Extract only the \"References\" section from labeled_sections\n",
    "            references_section = {key: value for key, value in labeled_sections.items() if key == \"References\"}\n",
    "            \n",
    "            # Remove each labeled section from residual_text\n",
    "            residual_text = text\n",
    "            for section_text in labeled_sections.values():\n",
    "                residual_text = residual_text.replace(section_text, \"\")\n",
    "            return references_section, residual_text\n",
    "        else:\n",
    "            if len(residual_text) > 100:\n",
    "                print(f\"Warning: High number of characters missed ({len(residual_text)}), please investigate manually.\")\n",
    "                if show_residuals:\n",
    "                    print(residual_text)\n",
    "            return labeled_sections, residual_text\n",
    "        \n",
    "    def process_files(self):\n",
    "        \"\"\"\n",
    "        Processes all text files in the specified folder.\n",
    "        \"\"\"\n",
    "        output_dict = {}\n",
    "\n",
    "        self.select_labels()\n",
    "\n",
    "        for filename in tqdm(os.listdir(self.folder_path)):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(self.folder_path, filename), 'r') as f:\n",
    "                    text = f.read()\n",
    "\n",
    "                # Initialize labeled_sections\n",
    "                labeled_sections = {}\n",
    "\n",
    "                # Use Keyword matching to find sections first\n",
    "                if self.label_method == 'keyword_matching' or self.label_method == 'openai':\n",
    "                    labeled_sections, text = self.label_text(text)\n",
    "\n",
    "                if self.label_method != 'keyword_matching':\n",
    "                    # Split the text into sections\n",
    "                    self.chunker = TextChunker(text, np.round(self.token_max * self.token_safety))  # Set to 75% max token limit\n",
    "                    self.chunker.chunk_text()\n",
    "                    chunks = self.chunker.get_chunks()\n",
    "\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        if self.label_method == 'LDA':\n",
    "                            self.train_lda_on_all_files()\n",
    "                            label = self.label_with_lda(chunk)\n",
    "                            labeled_sections[label] = chunk  # Moved this inside the if block\n",
    "                        elif self.label_method == 'openai':\n",
    "                            # Set questions\n",
    "                            self.questions_dict = self.get_questions()\n",
    "                            # Intializing sections\n",
    "                            for k, v in self.questions_dict.items():\n",
    "                                labeled_sections[v] = []\n",
    "                                                            \n",
    "                            self.openai_evaluator = OpenAIEvaluator(self.api_key_path)\n",
    "                            label_dict = self.openai_evaluator.evaluate_with_openai(chunk, self.questions_dict)\n",
    "                            for question, decision in label_dict.items():\n",
    "                                if decision == 1:\n",
    "                                    print(self.questions_dict[question])\n",
    "                                    print(chunk)\n",
    "                                    labeled_sections[self.questions_dict[question]].append(chunk)\n",
    "\n",
    "                        else:\n",
    "                            raise ValueError(f\"Labelling method {self.label_method} invalid. Select LDA or openai or keyword_matching\")\n",
    "\n",
    "                output_dict[filename] = labeled_sections\n",
    "\n",
    "        self.save_to_json(output_dict)\n",
    "\n",
    "    def save_to_json(self, output_dict):\n",
    "        \"\"\"\n",
    "        Saves the labeled sections to a JSON file.\n",
    "\n",
    "        Parameters:\n",
    "        - output_dict (dict): Dictionary containing the labeled sections.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Create a new directory in the same root folders\n",
    "        out_dir = os.path.join(os.path.dirname(self.folder_path),  f\"{self.label_method}_labeled_text\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        with open(os.path.join(out_dir, 'labeled_sections.json'), 'w') as f:\n",
    "            json.dump(output_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directory paths\n",
    "folder_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/ocr/preprocessed\" \n",
    "article_type = \"research\" \n",
    "api_key_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/openai_key.txt\"\n",
    "\n",
    "# Initialize the SectionLabeler class and process the files\n",
    "section_labeler = SectionLabeler(folder_path=folder_path, article_type=article_type, api_key_path=api_key_path, label_method='keyword_matching')\n",
    "section_labeler.process_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Define Your Research Questions for OpenAI\n",
    "\n",
    "Using the print_question_template Function\n",
    "\n",
    "Overview\n",
    "- The print_question_template function serves as a tool to help users generate a template of questions based on a specific context—be it for inclusion criteria, exclusion criteria, or evaluation questions. \n",
    "- You will then edit the template for your research questions and pass it to the GPT submission class. \n",
    "- This function is particularly useful for researchers or students who want to fine-tune the evaluation process of text-based data.\n",
    "\n",
    "```\n",
    "Function Signature\n",
    "python\n",
    "\n",
    "Copy code\n",
    "def print_question_template(question_type: str) -> None:\n",
    "Parameters\n",
    "question_type (str): This is the type of questions you want to print. The options are 'inclusion', 'exclusion', 'evaluation', or 'custom'.\n",
    "Returns\n",
    "None: The function prints the template to the console but does not return any value.\n",
    "How to Use\n",
    "Choose the Question Type: Decide the type of questions you need. The options are:\n",
    "\n",
    "'inclusion': For questions related to the inclusion criteria.\n",
    "'exclusion': For questions related to the exclusion criteria.\n",
    "'evaluation': For questions that evaluate the quality or specifics of the text.\n",
    "'custom': For your custom set of questions.\n",
    "\n",
    "Use the function like so:\n",
    "```\n",
    "\n",
    ">python\n",
    ">Copy code\n",
    ">print_question_template(\"inclusion\")\n",
    ">This will print a JSON-formatted dictionary of questions related to the inclusion criteria.\n",
    ">\n",
    ">Modify the Template: You can copy the printed dictionary and modify the questions or their corresponding labels as >needed.\n",
    ">\n",
    ">Pass to the Evaluator: Once modified, this dictionary can be passed as an argument to the OpenAIChatEvaluator or >any similar class for further processing.\n",
    ">\n",
    ">Example Usage\n",
    ">Here's how you can use the function to get a template for inclusion questions:\n",
    ">\n",
    ">python\n",
    ">Copy code\n",
    ">print_question_template(\"inclusion\")\n",
    ">The output will look something like this:\n",
    ">\n",
    ">json\n",
    ">Copy code\n",
    ">{\n",
    ">    \"Amnesia case report? (Y/N)\": \"case_report\",\n",
    ">    \"Published in English? (Y/N)\": \"is_english\"\n",
    ">}\n",
    ">Custom Template\n",
    ">If you choose the 'custom' type, the function will return a skeleton template with placeholders, which you can >fill in to create your own set of questions.\n",
    "\n",
    "\n",
    "Remember, the idea is to make it easier for you to generate, modify, and utilize question templates for your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the template for the type of questions you chose:\n",
      "{\n",
      "    \"Amnesia case report? (Y/N)\": \"case_report\",\n",
      "    \"Published in English? (Y/N)\": \"is_english\"\n",
      "}\n",
      "Here is the template for the type of questions you chose:\n",
      "{\n",
      "    \"Transient amnesia, reversible amnesia symptom, severe confabulation or drug use, toxicity, epilepsy-related confusion, psychological or psychiatric-related amnesia (functional amnesia)\": \"other_cause\",\n",
      "    \"Did not examine/report both retrograde and anterograde memory domains\": \"not_both_domains\",\n",
      "    \"Without descriptive/qualitative/quantitative data on amnesia severity/memory tests/questions/scenarios/details\": \"not_enough_information\",\n",
      "    \"Had global cognitive impairment disproportionate to memory loss\": \"disproportionate_impairment\",\n",
      "    \"Without measurable lesion-related brain MR/CT scans\": \"no_scan\",\n",
      "    \"Had focal or widespread brain atrophy\": \"neurodegenerative\",\n",
      "    \"Atypical cases with selective (e.g., semantic) memory loss or material/topographic-specific memory loss\": \"atypical_case\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{' ? (metric/metric/metric)': 'question_label'}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_question_template(question_type):\n",
    "    \"\"\"\n",
    "    Prints out a template for questions based on the specified question type.\n",
    "    \n",
    "    Parameters:\n",
    "    - question_type (str): Type of questions to print ('inclusion', 'exclusion', 'evaluation').\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if question_type == \"inclusion\":\n",
    "        questions = {'Amnesia case report? (Y/N)': 'case_report',\n",
    "                     'Published in English? (Y/N)': 'is_english'}\n",
    "    elif question_type == \"exclusion\":\n",
    "        questions = {'Transient amnesia, reversible amnesia symptom, severe confabulation or drug use, toxicity, epilepsy-related confusion, psychological or psychiatric-related amnesia (functional amnesia)': 'other_cause',\n",
    "                        'Did not examine/report both retrograde and anterograde memory domains': 'not_both_domains',\n",
    "                        'Without descriptive/qualitative/quantitative data on amnesia severity/memory tests/questions/scenarios/details': 'not_enough_information',\n",
    "                        'Had global cognitive impairment disproportionate to memory loss': 'disproportionate_impairment',\n",
    "                        'Without measurable lesion-related brain MR/CT scans': 'no_scan',\n",
    "                        'Had focal or widespread brain atrophy': 'neurodegenerative',\n",
    "                        'Atypical cases with selective (e.g., semantic) memory loss or material/topographic-specific memory loss': 'atypical_case'\n",
    "                    }  \n",
    "    elif question_type == \"evaluation\":\n",
    "        questions = {'Does the patient(s) represent(s) the whole experience of the investigator (center) or is the selection method unclear to the extent that other patients with similar presentation may not have been reported? (Good/Bad/Unclear)': 'representative_case_quality',\n",
    "                        'Was patient’s causal exposure clearly described? (Good/Bad/Unclear)': 'causality_quality',\n",
    "                        'Were diagnostic tests or assessment methods and the results clearly described (amnesia tests)? (Good/Bad/Unclear)': 'phenotyping_quality',\n",
    "                        'Were other alternative causes that may explain the observation (amnesia) ruled out? (Good/Bad/Unclear)': 'workup_quality',\n",
    "                        'Were patient’s demographics, medical history, comobidities clearly described? (Good/Bad/Unclear)': 'clinical_covariates_quality',\n",
    "                        'Were patient’s symptoms, interventions, and clinical outcomes clearly presented as a timeline? (Good/Bad/Unclear)': 'history_quality',\n",
    "                        'Was the lesion image taken around the time of observation (amnesia) assessment? (Good/Bad/Unclear)': 'temporal_causality_quality',\n",
    "                        'Is the case(s) described with sufficient details to allow other investigators to replicate the research or to allow practitioners make inferences related to their own practice? (Good/Bad/Unclear)': 'history_quality_2'\n",
    "        }\n",
    "    elif question_type == \"custom\":\n",
    "        questions = {' ? (metric/metric/metric)': 'question_label',\n",
    "                        ' ? (metric/metric/metric)': 'question_label',\n",
    "                        ' ? (metric/metric/metric)': 'question_label',\n",
    "                        ' ? (metric/metric/metric)': 'question_label',\n",
    "                        ' ? (metric/metric/metric)': 'question_label',\n",
    "                        ' ? (metric/metric/metric)': 'question_label',\n",
    "                        ' ? (metric/metric/metric)': 'question_label',\n",
    "                        ' ? (metric/metric/metric)': 'question_label',\n",
    "        }\n",
    "        return questions\n",
    "    else:\n",
    "        print(\"Invalid question type. Please choose 'inclusion', 'exclusion', or 'evaluation'.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Here is the template for the type of questions you chose:\")\n",
    "    print(json.dumps(questions, indent=4))\n",
    "\n",
    "# # Example usage:\n",
    "print_question_template(\"inclusion\")\n",
    "print_question_template(\"exclusion\")\n",
    "print_question_template(\"custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Critical Note**\n",
    "- You should phrase these questions such that a Yes results in the manuscript 'passing'\n",
    "- This can be made more robust by having users deliberately map a Yes for each question to whether it is good or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = {\n",
    "    \"Does this have case report-style information (Y)? Or is it a different type of article (N)\": \"case_report\",\n",
    "    \"Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\": \"has_imaging\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Ask Questions to OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the OpenAIChatEvaluator Class**\n",
    "\n",
    "The OpenAIChatEvaluator class extends the OpenAIEvaluator class to provide additional functionality for text evaluation based on OpenAI's chat models.\n",
    "\n",
    "Prerequisites\n",
    "```\n",
    "Python 3.x\n",
    "OpenAI Python package\n",
    "A JSON file containing labeled sections\n",
    "```\n",
    "\n",
    "Initialization\n",
    "```\n",
    "To initialize an instance of OpenAIChatEvaluator, you need to provide:\n",
    "\n",
    "API Key Path: The path to a file containing your OpenAI API key.\n",
    "JSON File Path: The path to a JSON file containing the labeled sections you want to evaluate.\n",
    "Keys to Consider: A list of keys you want the evaluator to consider for evaluation.\n",
    "Article Type: The type of article you are evaluating (e.g., 'research', 'case').\n",
    "```\n",
    "\n",
    "Methods\n",
    "```\n",
    "- read_json\n",
    "- This method reads a JSON file from a given file path.\n",
    "- json_data = evaluator.read_json('labeled_sections.json')\n",
    "\n",
    "- get_questions\n",
    "- This method generates evaluation questions based on the article_type. It returns a dictionary of questions.\n",
    "- questions = evaluator.get_questions()\n",
    "\n",
    "- send_to_openai\n",
    "- This method takes a list of text chunks and sends them to OpenAI for evaluation.  It returns a list of answers corresponding to the chunks.\n",
    "- answers = evaluator.send_to_openai(['chunk1', 'chunk2'])\n",
    "```\n",
    "____\n",
    "# Workflow Example\n",
    "\n",
    "Here's how you could use OpenAIChatEvaluator to evaluate a list of text chunks.\n",
    "\n",
    "> python\n",
    "> # Initialize the evaluator\n",
    "> evaluator = OpenAIChatEvaluator('your_api_key.txt', 'labeled_sections.json', ['Introduction', 'Methods'], 'case')\n",
    ">\n",
    "> # Generate questions based on the article type\n",
    "> questions = evaluator.get_questions()\n",
    ">\n",
    "> # Evaluate a list of text chunks\n",
    "> chunks = ['This is a sample chunk.', 'This is another sample chunk.']\n",
    "> answers = evaluator.send_to_openai(chunks)\n",
    ">\n",
    "> # Print the answers\n",
    "> print(answers)\n",
    "\n",
    "By following this guide, you should be able to use the OpenAIChatEvaluator class for evaluating text based on OpenAI's chat models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # Make sure to install the OpenAI package\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class OpenAIChatEvaluator(OpenAIEvaluator):\n",
    "    \"\"\"\n",
    "    Class to evaluate text chunks using OpenAI's chat models.\n",
    "    \n",
    "    Attributes:\n",
    "    - token_limit (int): The maximum number of tokens allowed in each OpenAI API call.\n",
    "    - question_token (int): The number of tokens reserved for the question.\n",
    "    - answer_token (int): The number of tokens reserved for the answer.\n",
    "    - json_data (dict): The data read from the JSON file.\n",
    "    - keys_to_consider (list): List of keys to consider from the JSON file.\n",
    "    - article_type (str): The type of article (e.g., 'research', 'case').\n",
    "    - questions (dict): Dictionary mapping article types to evaluation questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key_path, json_file_path, keys_to_consider, question_type, question, token_limit=16000, question_token=500, answer_token=500):\n",
    "        \"\"\"\n",
    "        Initializes the OpenAIChatEvaluator class.\n",
    "        \n",
    "        Parameters:\n",
    "        - api_key_path (str): Path to the file containing the OpenAI API key.\n",
    "        - json_file_path (str): Path to the JSON file containing the text data.\n",
    "        - keys_to_consider (list): List of keys to consider from the JSON file.\n",
    "        - article_type (str): The type of article (e.g., 'research', 'case').\n",
    "        - token_limit (int): The maximum number of tokens allowed in each OpenAI API call. Default is 16000.\n",
    "        - question_token (int): The number of tokens reserved for the question. Default is 500.\n",
    "        - answer_token (int): The number of tokens reserved for the answer. Default is 500.\n",
    "        \"\"\"\n",
    "        super().__init__(api_key_path)  # Call the parent class's constructor\n",
    "        self.questions = question\n",
    "        self.token_limit = token_limit\n",
    "        self.question_token = question_token\n",
    "        self.answer_token = answer_token\n",
    "        self.json_path = json_file_path\n",
    "        self.json_data = self.read_json(json_file_path)\n",
    "        self.keys_to_consider = keys_to_consider\n",
    "        self.question_type = question_type\n",
    "        self.extract_relevant_text()\n",
    "        self.all_answers = {}\n",
    "\n",
    "    def read_json(self, json_file_path):\n",
    "        \"\"\"\n",
    "        Reads JSON data from a file.\n",
    "        \n",
    "        Parameters:\n",
    "        - json_file_path (str): Path to the JSON file containing the text data.\n",
    "        \n",
    "        Returns:\n",
    "        - dict: The data read from the JSON file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as file:\n",
    "                return json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File {json_file_path} not found.\")\n",
    "            return {}\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Could not decode the JSON file.\")\n",
    "            return {}\n",
    "\n",
    "    \n",
    "    def extract_relevant_text(self):\n",
    "        \"\"\"\n",
    "        Extracts and stores relevant text sections based on keys_to_consider.\n",
    "        \"\"\"\n",
    "        self.relevant_text_by_file = {}\n",
    "        for file_name, sections in self.json_data.items():\n",
    "            selected_text = \"\"\n",
    "            for key, value in sections.items():\n",
    "                if key in self.keys_to_consider:\n",
    "                    selected_text += value\n",
    "            self.relevant_text_by_file[file_name] = selected_text\n",
    "\n",
    "    def evaluate_all_files(self):\n",
    "        for file_name, selected_text in tqdm(self.relevant_text_by_file.items()):\n",
    "            # Initialize a dictionary to store answers for this file\n",
    "            self.all_answers[file_name] = {}\n",
    "            \n",
    "            # Chunk the text\n",
    "            text_chunker = TextChunker(selected_text, np.round((self.token_limit) * 0.7))\n",
    "            text_chunker.chunk_text()\n",
    "            chunks = text_chunker.get_chunks()\n",
    "            \n",
    "            # Initialize a dictionary to store chunk-level answers for each question\n",
    "            for question in self.questions.keys():\n",
    "                self.all_answers[file_name][question] = {}\n",
    "\n",
    "            # Send a query for each chunk\n",
    "            for chunk_index, chunk in enumerate(chunks):\n",
    "                # Reset the conversation each time\n",
    "                conversation = []\n",
    "                conversation.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "                conversation.append({\"role\": \"user\", \"content\": f\"Text Chunk: {chunk}\"})\n",
    "                \n",
    "                # Initialize a conversation with OpenAI for this chunk\n",
    "                try:\n",
    "                    for q_index, q in enumerate(self.questions.keys()):\n",
    "                        # print(self.questions.keys())\n",
    "                        # Add the question to the conversation and send it\n",
    "                        conversation.append({\"role\": \"user\", \"content\": q})\n",
    "                        response = openai.ChatCompletion.create(\n",
    "                            model=\"gpt-3.5-turbo-16k\",\n",
    "                            messages=conversation\n",
    "                        )\n",
    "                        # Retrieve the assistant's last answer\n",
    "                        answer = response['choices'][-1]['message']['content']\n",
    "                        # Store the answer for this question and this chunk\n",
    "                        self.all_answers[file_name][q][f\"chunk_{chunk_index+1}\"] = answer\n",
    "                        \n",
    "                        # Add the assistant's answer back to the conversation to maintain context\n",
    "                        conversation.append({\"role\": \"assistant\", \"content\": answer})\n",
    "                except openai.Error as e:\n",
    "                    print(f\"OpenAI API Error: {e}\")\n",
    "                    self.all_answers[file_name][q] = \"Unidentified\"\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                    self.all_answers[file_name][q] = \"Unidentified\"\n",
    "                    \n",
    "        return self.all_answers\n",
    "        \n",
    "    def send_to_openai(self, chunks):\n",
    "        \"\"\"\n",
    "        Sends text chunks to OpenAI for evaluation.\n",
    "        \n",
    "        Parameters:\n",
    "        - chunks (list): List of text chunks to evaluate.\n",
    "        \n",
    "        Returns:\n",
    "        - list: List of answers received from OpenAI.\n",
    "        \"\"\"\n",
    "        answers = []\n",
    "        for chunk in chunks:\n",
    "            prompt = f\"Text Chunk: {chunk}\\n{self.questions}\"\n",
    "\n",
    "            try:\n",
    "                response = openai.Completion.create(\n",
    "                    engine=\"gpt-3.5-turbo-16k\",\n",
    "                    prompt=prompt,\n",
    "                    max_tokens=self.answer_token  # Adjust as needed\n",
    "                )\n",
    "                decision_text = response.choices[0].text.strip()\n",
    "                answers.append(decision_text)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during response handling: {e}\")\n",
    "                answers.append(\"Unidentified\")\n",
    "\n",
    "        return answers\n",
    "    \n",
    "    def save_to_json(self, output_dict):\n",
    "        \"\"\"\n",
    "        Saves the labeled sections to a JSON file.\n",
    "\n",
    "        Parameters:\n",
    "        - output_dict (dict): Dictionary containing the labeled sections.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Create a new directory in the same root folder\n",
    "        out_dir = os.path.join(os.path.dirname(self.json_path), \"text_evaluations\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the dictionary to a JSON file\n",
    "        with open(os.path.join(out_dir, f'{self.question_type}_evaluations.json'), 'w') as f:\n",
    "            json.dump(output_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/openai_key.txt\"\n",
    "json_file_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/ocr/keyword_matching_labeled_text/labeled_sections.json\"\n",
    "\n",
    "# Define the keys you want to consider (exclude 'References')\n",
    "keys_to_consider = [\"Results\", \"Discussion\"]  # Add or remove keys as per your requirement\n",
    "\n",
    "# Define the type of article and questions\n",
    "question_type = \"testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n",
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n",
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:03<00:10,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n",
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:06<00:05,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n",
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n",
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:09<00:03,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Yes\n",
      "q Does this have case report-style information (Y)? Or is it a different type of article (N)\n",
      "a Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q Do you think there might be a figure in this which has patient neuroimaging? (Y/N)\n",
      "a Y\n",
      "{'Horn 2017PD Fxconn_OCR.txt': {'Does this have case report-style information (Y)? Or is it a different type of article (N)': {'chunk_1': 'N', 'chunk_2': 'N', 'chunk_3': 'N'}, 'Do you think there might be a figure in this which has patient neuroimaging? (Y/N)': {'chunk_1': 'Y', 'chunk_2': 'Y', 'chunk_3': 'Y'}}, 'NEURODEGENERATION IN RELATION TO NETWORKS_OCR.txt': {'Does this have case report-style information (Y)? Or is it a different type of article (N)': {'chunk_1': 'N', 'chunk_2': 'N'}, 'Do you think there might be a figure in this which has patient neuroimaging? (Y/N)': {'chunk_1': 'Y', 'chunk_2': 'Y'}}, 'network_dynamics_in_ad_ftd_OCR.txt': {'Does this have case report-style information (Y)? Or is it a different type of article (N)': {'chunk_1': 'N', 'chunk_2': 'N', 'chunk_3': 'N'}, 'Do you think there might be a figure in this which has patient neuroimaging? (Y/N)': {'chunk_1': 'Y', 'chunk_2': 'Y', 'chunk_3': 'Yes'}}, '1196_OCR.txt': {'Does this have case report-style information (Y)? Or is it a different type of article (N)': {'chunk_1': 'Y'}, 'Do you think there might be a figure in this which has patient neuroimaging? (Y/N)': {'chunk_1': 'Y'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = OpenAIChatEvaluator(api_key_path, json_file_path, keys_to_consider, article_type, question)\n",
    "answers = evaluator.evaluate_all_files()\n",
    "print(answers)\n",
    "evaluator.save_to_json(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Inclusion/Exclusion Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = r'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/ocr/keyword_matching_labeled_text/text_evaluations/research_evaluations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "class InclusionExclusionSummarizer:\n",
    "    \"\"\"\n",
    "    Class to summarize inclusion/exclusion criteria based on the answers received from GPT-3.5.\n",
    "    \n",
    "    Attributes:\n",
    "    - json_path (str): Path to the JSON file containing the answers.\n",
    "    - data (dict): The data read from the JSON file.\n",
    "    - df (DataFrame): Pandas DataFrame to store summarized results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        \"\"\"\n",
    "        Initializes the InclusionExclusionSummarizer class.\n",
    "        \n",
    "        Parameters:\n",
    "        - json_path (str): Path to the JSON file containing the answers.\n",
    "        \"\"\"\n",
    "        self.json_path = json_path\n",
    "        self.data = self.read_json()\n",
    "        self.df = self.summarize_results()\n",
    "    \n",
    "    def read_json(self):\n",
    "        \"\"\"\n",
    "        Reads JSON data from a file.\n",
    "        \n",
    "        Returns:\n",
    "        - dict: The data read from the JSON file.\n",
    "        \"\"\"\n",
    "        with open(self.json_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    \n",
    "    def summarize_results(self):\n",
    "        \"\"\"\n",
    "        Summarizes the results by converting answers to binary form.\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame: Pandas DataFrame containing the summarized results.\n",
    "        \"\"\"\n",
    "        summary_dict = {}\n",
    "        for article, questions in self.data.items():\n",
    "            summary_dict[article] = {}\n",
    "            for question, chunks in questions.items():\n",
    "                # Convert all chunk answers to lowercase and check for \"yes\" keywords\n",
    "                binary_answers = [1 if 'y' in answer.lower() else 0 for answer in chunks.values()]\n",
    "                # Sum up the binary answers for each question\n",
    "                summary_dict[article][question] = sum(binary_answers)\n",
    "        \n",
    "        # Convert the summary dictionary to a DataFrame\n",
    "        df = pd.DataFrame.from_dict(summary_dict, orient='index')\n",
    "        \n",
    "        # Set all values above 0 to 1\n",
    "        df[df > 0] = 1\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def drop_rows_with_zeros(self):\n",
    "        \"\"\"\n",
    "        Drops any row in the DataFrame that contains a zero.\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame: A new DataFrame with rows containing zeros removed.\n",
    "        \"\"\"\n",
    "        return self.df[(self.df == 0).sum(axis=1) == 0]\n",
    "    \n",
    "    def save_to_csv(self, dropped=False):\n",
    "        \"\"\"\n",
    "        Saves the DataFrame to a CSV file.\n",
    "        \n",
    "        Parameters:\n",
    "        - dropped (bool): Indicates whether rows have been dropped from the DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Create a new directory in the same root folder\n",
    "        out_dir = os.path.join(os.path.dirname(self.json_path), \"inclusion_exclusion_results\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        \n",
    "        # Determine the name of the CSV file based on whether rows have been dropped\n",
    "        file_name = \"automated_filtered_results.csv\" if dropped else \"unfiltered_results.csv\"\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        csv_path = os.path.join(out_dir, file_name)\n",
    "        if dropped:\n",
    "            self.drop_rows_with_zeros().to_csv(csv_path)\n",
    "        else:\n",
    "            self.df.to_csv(csv_path)\n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Executes all the summarization, saving and optional row-dropping steps in one method.\n",
    "        \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.save_to_csv()\n",
    "        self.save_to_csv(dropped=True)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Does this have case report-style information (Y)? Or is it a different type of article (N)</th>\n",
       "      <th>Do you think there might be a figure in this which has patient neuroimaging? (Y/N)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Horn 2017PD Fxconn_OCR.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEURODEGENERATION IN RELATION TO NETWORKS_OCR.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>network_dynamics_in_ad_ftd_OCR.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196_OCR.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Does this have case report-style information (Y)? Or is it a different type of article (N)  \\\n",
       "Horn 2017PD Fxconn_OCR.txt                                                                         0                                            \n",
       "NEURODEGENERATION IN RELATION TO NETWORKS_OCR.txt                                                  0                                            \n",
       "network_dynamics_in_ad_ftd_OCR.txt                                                                 0                                            \n",
       "1196_OCR.txt                                                                                       1                                            \n",
       "\n",
       "                                                   Do you think there might be a figure in this which has patient neuroimaging? (Y/N)  \n",
       "Horn 2017PD Fxconn_OCR.txt                                                                         1                                   \n",
       "NEURODEGENERATION IN RELATION TO NETWORKS_OCR.txt                                                  1                                   \n",
       "network_dynamics_in_ad_ftd_OCR.txt                                                                 1                                   \n",
       "1196_OCR.txt                                                                                       1                                   "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summarizer = InclusionExclusionSummarizer(path_to_json)\n",
    "result_df = summarizer.run()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
