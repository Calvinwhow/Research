{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Cortical Thickness W-Mapping Pipeline\n",
    "### Authors: William Drew\n",
    "### Last updated: October 13, 2022\n",
    "***\n",
    "# Introduction\n",
    "This notebook will guide you through our Surface-space Functional Network Mapping Pipeline. This pipeline will outline the following steps:\n",
    "1. FreeSurfer recon-all\n",
    "2. Creating a GLM for cortical thickness\n",
    "3. Creating W-maps (in fsaverage5 space)\n",
    "4. Performing Surface network mapping with the Preprocessing notebook\n",
    "\n",
    "#### The surface-space functional network mapping pipeline requires certain covariate data, namely **age(years)** and **sex** for each of your subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Step 0: Where is your project be located?\n",
    "\n",
    "## Please set a project folder below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your project folder here\n",
    "project_folder = \"/data/nimlab/new_ADNI/william_analysis/preprocessing_bug/test_surface_pipeline\"\n",
    "dataset_name = \"surface_test\"\n",
    "\n",
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from glob import glob\n",
    "from termcolor import cprint\n",
    "from tqdm import tqdm, trange\n",
    "from natsort import natsorted\n",
    "from nimlab import surface as nimsurf\n",
    "\n",
    "project_folder = os.path.join(os.path.abspath(project_folder), dataset_name)\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(project_folder, \"config\"), exist_ok=True)\n",
    "tmpdir = os.path.join(project_folder, \"tmp\")\n",
    "os.makedirs(tmpdir, exist_ok=True)\n",
    "os.makedirs(os.path.join(project_folder, \"scripts\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(project_folder, \"scripts\",\"recon_all\"), exist_ok=True)\n",
    "freesurfer_subjects_folder = os.path.join(project_folder, \"freesurfer_RA_subjects\")\n",
    "os.makedirs(freesurfer_subjects_folder, exist_ok=True)\n",
    "nimsurf.copy_fsaverage(\"fsaverage5\", freesurfer_subjects_folder)\n",
    "outdir = os.path.join(project_folder, \"w_maps\")\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Step 1: Prepare your Data\n",
    "\n",
    "## If you have DICOMs, convert them to Nifti\n",
    "\n",
    "- If you have DICOMs instead of `.nii` or `.nii.gz` files, convert the DICOMs to Nifti using `dcm2niix`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Data CSV\n",
    "\n",
    "## Please create a CSV file with the following data:\n",
    "- In Column 1, titled **`subid`**, enter your subject identifiers.\n",
    "- In Column 2, titled **`t1`**, enter full filepaths to your subjects' T1 MRI Nifti files.\n",
    "- In Column 3, titled **`age`**, enter the ages(years) of your subjects. It is OK (and encouraged) if you have decimals to account for months as well. \n",
    "- In Column 4, titled **`sex`**, enter the sex (M/F) of your subjects. This column must contain only **`M`** or **`F`**. \n",
    "- In Column 5, titled **`field`**, enter the MRI field strength for the captured imaging. This column must contain either only all **`1.5`** or all **`3`**. You **cannot** mix field strengths.\n",
    "- In Column 6, titled **`control`**, enter a **`1`** if you wish to build a GLM using the subject. Otherwise, enter a **`0`**.\n",
    "An example of such a formatted file is below:\n",
    "***\n",
    "```\n",
    "subid,t1,age,sex,field,control\n",
    "100890,/PHShome/wd957/test_subjects/100890.nii,67.9,M,3,1\n",
    "101039,/PHShome/wd957/test_subjects/101039.nii,72.7,M,3,1\n",
    "101747,/PHShome/wd957/test_subjects/101747.nii,71,F,3,1\n",
    "106126,/PHShome/wd957/test_subjects/106126.nii,66.9,F,3,1\n",
    "106127,/PHShome/wd957/test_subjects/106127.nii,69.5,F,3,0\n",
    "```\n",
    "***\n",
    "Save the CSV to disk and enter its file path below to `input_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your input CSV here\n",
    "input_csv = \"/PHShome/wd957/test_subjects/test_t1_subjects.csv\"\n",
    "\n",
    "\n",
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "copy_csv = os.path.join(project_folder, \"subjects.csv\")\n",
    "shutil.copyfile(input_csv, os.path.join(project_folder, \"subjects.csv\"))\n",
    "subject_df = pd.read_csv(copy_csv, dtype={\"subid\":str, \"t1\": str, \"age\": float, \"sex\": str, \"field\": float})\n",
    "for _, r in subject_df.iterrows():\n",
    "    if not os.path.exists(r[\"t1\"]):\n",
    "        raise FileNotFoundError(f\"{r['t1']} doesn't exist!\")\n",
    "    if r[\"age\"]<0:\n",
    "        raise ValueError(f\"Age of {os.path.basename(r['t1'])} is invalid!\")\n",
    "    if r[\"sex\"] not in [\"M\", \"F\"]:\n",
    "        raise ValueError(f\"Sex of {os.path.basename(r['t1'])} is invalid!\")\n",
    "    if r[\"field\"] not in [1.5, 3]:\n",
    "        raise ValueError(f\"Field strength of {os.path.basename(r['t1'])} is invalid!\")\n",
    "if len(subject_df[\"field\"].unique()) != 1:\n",
    "    raise ValueError(f\"Only a single field strength is allowed. Either use only 1.5T images or 3T images!\")\n",
    "if len(subject_df[\"subid\"].unique()) != len(subject_df):\n",
    "    raise ValueError(f\"Duplicate Subject ID detected!\")\n",
    "else:\n",
    "    cprint(f\"I found {len(subject_df)} source T1 images!\\n\", \"green\", attrs=[\"bold\"])\n",
    "    print(\"----- Sample rows of data csv -----\\n\")\n",
    "    print(subject_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Step 2: Run FreeSurfer recon-all\n",
    "\n",
    "If you have just a couple of subjects, it's OK to run this on the ERIS cluster. However, if you're running hundreds of subjects, ideally you will have access to a bigger cluster such as [Harvard FAS's Cannon cluster](https://www.rc.fas.harvard.edu/) or [Harvard Medical School's O2 cluster](https://it.hms.harvard.edu/our-services/research-computing/services/high-performance-computing) so that the recon-all can finish faster.\n",
    "\n",
    "### The below cell will create a script that you can run on the ERIS cluster to submit individual jobs for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "recon_all_settings = ['#!/bin/bash',\n",
    "'#BSUB -q normal',\n",
    "'#BSUB -n 1',\n",
    "'#BSUB -M 4000',         \n",
    "'#BSUB -R \"rusage[mem=4000]\"',\n",
    "f'export SUBJECTS_DIR={freesurfer_subjects_folder}']\n",
    "\n",
    "recon_all_scripts = []\n",
    "for _, r in subject_df.iterrows():\n",
    "    subject_id, t1_path = r[[\"subid\",\"t1\"]]\n",
    "    script_path = os.path.join(project_folder, \"scripts\",\"recon_all\", f\"{subject_id}.sh\")\n",
    "    recon_all_scripts.append(script_path)\n",
    "    with open(script_path, \"w\") as fp:\n",
    "        for item in recon_all_settings:\n",
    "            fp.write(\"%s\\n\" % item)\n",
    "        recon_str = f\"recon-all -s {subject_id} -i {t1_path} -all\"\n",
    "        if r[\"field\"]==3:\n",
    "            recon_str += \" -3T\"\n",
    "        fp.write(recon_str)\n",
    "launch_recon_all_script = os.path.join(project_folder, \"scripts\", \"launch_recon_all.sh\")\n",
    "with open(launch_recon_all_script, \"w\") as fp:\n",
    "    fp.write(\"#!/bin/bash\\n\")\n",
    "    for s in recon_all_scripts:\n",
    "        fp.write(f\"bsub < {s};\\nsleep 0.1;\\n\")\n",
    "os.chmod(launch_recon_all_script, 0o770)\n",
    "\n",
    "cprint(f\"To run FreeSurfer recon-all on the ERIS cluster, run the following on a login node:\\n\\n.{launch_recon_all_script}\", \"green\", attrs=['bold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to run recon-all on a different cluster, you will need to do a couple of things:\n",
    "** Ask William for help with this **\n",
    "\n",
    "1. Copy your T1 weighted MRI Nifti files to the external cluster.\n",
    "2. Edit the `scripts/launch_recon_all.sh` script to match whatever job scheduler the external cluster is using. \n",
    "3. Edit the recon-all job scripts in `scripts/recon_all/` to match whatever job scheduler the external cluster is using.\n",
    "4. Copy the `scripts` folder to the external cluster.\n",
    "5. Run the `scripts/launch_recon_all.sh` script on the external cluster and wait for all your jobs to finish.\n",
    "6. Download the contents of the FreeSurfer `SUBJECTS_DIR` folder from the exernal cluster to the `freesurfer_RA_subjects` folder in your project directory on the ERIS cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check FreeSurfer recon-all progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "success_counter = 0\n",
    "error_counter = 0\n",
    "pending_counter = 0\n",
    "running_counter = 0\n",
    "success_subjects = []\n",
    "error_subjects = []\n",
    "for _, r in subject_df.iterrows():\n",
    "    log_file = f\"{freesurfer_subjects_folder}/{r['subid']}/scripts/recon-all.log\"\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r') as f:\n",
    "            last_line = f.readlines()[-1]\n",
    "            if \"finished without error\" in last_line:\n",
    "                success_counter += 1\n",
    "                success_subjects.append(r[\"subid\"])\n",
    "            elif \"exited with ERRORS\" in last_line:\n",
    "                error_subjects.append(r[\"subid\"])\n",
    "                error_counter += 1\n",
    "            else:\n",
    "                running_counter += 1\n",
    "    else:\n",
    "        pending_counter += 1\n",
    "if len(success_subjects)>0:\n",
    "    pd.Series(success_subjects, dtype=object).to_csv(os.path.join(project_folder, \"recon_all_success.csv\"), index=False, header=None)\n",
    "if len(error_subjects)>0:\n",
    "    pd.Series(error_subjects, dtype=object).to_csv(os.path.join(project_folder, \"recon_all_error.csv\"), index=False, header=None)\n",
    "cprint(f\"Total {len(subject_df)}\", \"blue\")\n",
    "cprint(f\"Pending {pending_counter}\", \"magenta\")\n",
    "cprint(f\"Running {running_counter}\", \"magenta\")\n",
    "print(\"---------------------------\")\n",
    "cprint(f\"Success {success_counter}\", \"green\")\n",
    "cprint(f\"Error {error_counter}\", \"red\")\n",
    "print(\"---------------------------\")\n",
    "recon_all_complete=False\n",
    "\n",
    "if pending_counter==0 and running_counter==0:\n",
    "    recon_all_complete=True\n",
    "    cprint(f\"FreeSurfer recon-all complete! Please check recon_all_success.csv and recon_all_error.csv in your project folder for successful/errored subjects!\", \"green\", attrs=[\"bold\"])\n",
    "else:\n",
    "    raise RuntimeError(f\"FreeSurfer recon-all not yet complete! Please check back again later.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Step 3: Load a Cortical Thickness GLM\n",
    "\n",
    "## IMPORTANT: Only run **ONE** of the following two sets of cells depending on whether you already have a GLM you want to use:\n",
    "\n",
    "## Option 1: If you already have a GLM you want to use...\n",
    "\n",
    "1. Set the path to the GLM directory and GLM name below. This should be a folder containing a `lh` folder and a `rh` folder.\n",
    "2. Set the FWHM smoothing kernel of the GLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the GLM here\n",
    "glm_dir = \"\"\n",
    "model = \"\"\n",
    "\n",
    "# DO NOT USE THIS EXAMPLE (THIS IS A FSAVERAGE7 MODEL AND WILL NOT WORK WITH OUR FSAVERAGE5 FILES)\n",
    "# glm_dir = \"/data/nimlab/Darby_Data/models/\"\n",
    "# model = \"1cn\"\n",
    "\n",
    "# Set the FWHM smoothing kernel of this model, if known\n",
    "fwhm_kernel = 10\n",
    "\n",
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "glm = \"\"\n",
    "if recon_all_complete == True:\n",
    "    check_paths = [\"lh/b0000.nii\",\n",
    "                   \"lh/b0001.nii\",\n",
    "                   \"lh/b0002.nii\",\n",
    "                   \"lh/rstd.mgh\",\n",
    "                   \"lh/y.fsgd\",\n",
    "                   \"rh/b0000.nii\",\n",
    "                   \"rh/b0001.nii\",\n",
    "                   \"rh/b0002.nii\",\n",
    "                   \"rh/rstd.mgh\",\n",
    "                   \"rh/y.fsgd\",]\n",
    "    if np.all([os.path.exists(os.path.join(glm_dir, model, p)) for p in check_paths]):\n",
    "        glm = os.path.join(glm_dir, model)\n",
    "        cprint(f\"GLM at {glm} loaded!\", \"green\", attrs=[\"bold\"])\n",
    "        fwhm = fwhm_kernel\n",
    "    else:\n",
    "        raise RuntimeError(f\"GLM incomplete or not found at {os.path.join(glm_dir, model)}!\")\n",
    "    \n",
    "else:\n",
    "    raise RuntimeError(\"FreeSurfer recon-all is incomplete! Please wait till FreeSurfer recon-all is complete before continuing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 (Part A): If you want to create a GLM with the control subjects in your dataset...\n",
    "### Create FSGD file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "glm_dir = os.path.join(project_folder, \"models\")\n",
    "glms = []\n",
    "fsgds = []\n",
    "os.makedirs(glm_dir, exist_ok=True)\n",
    "if recon_all_complete == True:\n",
    "    successful_subids = list(pd.read_csv(os.path.join(project_folder, \"recon_all_success.csv\"), header = None, dtype=str)[0])\n",
    "    field = subject_df['field'].unique()[0]\n",
    "    filtered_subject_df = subject_df[subject_df['control'] == 1]\n",
    "    filtered_subject_df = filtered_subject_df.replace({'sex': {\"M\": \"Male\", \"F\": \"Female\"}})\n",
    "    glm_name = f\"{dataset_name}_{field}T\"\n",
    "    glm_model_dir = os.path.join(glm_dir, glm_name)\n",
    "    os.makedirs(glm_model_dir, exist_ok = True)\n",
    "    fsgd_fname = os.path.join(project_folder, \"config\", glm_name+\".fsgd\")\n",
    "    print(f\"GLM ({glm_name}) consists of {len(filtered_subject_df)} control subjects with {field}T T1 imaging.\\nIts FSGD file is located at {fsgd_fname}\")\n",
    "    print(\"=======================================================================\")\n",
    "    if len(filtered_subject_df) < 20:\n",
    "        cprint(\"WARNING: This GLM will be built from fewer than 20 subjects!\", \"red\", attrs=[\"bold\"])\n",
    "\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "    with open(fsgd_fname, \"w\") as fp:\n",
    "        fp.write(\"GroupDescriptorFile 1\\n\")\n",
    "        fp.write(f\"Title {glm_name}\\n\")\n",
    "        fp.write(\"Class Male\\n\")\n",
    "        fp.write(\"Class Female\\n\")\n",
    "        fp.write(\"Variables Age\\n\")\n",
    "        for i, row in filtered_subject_df.iterrows():\n",
    "            if row['subid'] in successful_subids:\n",
    "                fp.write(f\"Input {row['subid']} {row['sex']} {row['age']}\\n\")\n",
    "                if row['sex'] == \"Male\":\n",
    "                    male_count += 1\n",
    "                elif row['sex'] == \"Female\":\n",
    "                    female_count += 1\n",
    "    if male_count == 0:\n",
    "        cprint(\"WARNING: There are 0 Male subjects in this GLM!\", \"red\", attrs=[\"bold\"])\n",
    "    else:\n",
    "        cprint(f\"There are {male_count} Male subjects in this GLM.\", \"green\", attrs=[\"bold\"])\n",
    "    if female_count == 0:\n",
    "        cprint(\"WARNING: There are 0 Female subjects in this GLM!\", \"red\", attrs=[\"bold\"])\n",
    "    else:\n",
    "        cprint(f\"There are {female_count} Female subjects in this GLM.\", \"green\", attrs=[\"bold\"])\n",
    "    cprint(f\"Ages span from {np.min(filtered_subject_df['age'])} to {np.max(filtered_subject_df['age'])}\", \"green\", attrs=[\"bold\"])\n",
    "        \n",
    "else:\n",
    "    raise RuntimeError(\"FreeSurfer recon-all is incomplete! Please wait till FreeSurfer recon-all is complete before continuing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 (Part B): Create GLM\n",
    "- Set your FWHM smoothing kernel size (in mm) below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM options; Select Smoothing Kernel\n",
    "fwhm_kernel = 10\n",
    "\n",
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "if recon_all_complete == True:\n",
    "    fwhm = fwhm_kernel\n",
    "    nimsurf.make_cortical_thickness_glm(fsgd_fname, glm_model_dir, freesurfer_subjects_folder, tmpdir, fwhm)\n",
    "    glm = glm_model_dir\n",
    "    cprint(f\"GLM at {glm} exists!\", \"green\", attrs=[\"bold\"])\n",
    "else:\n",
    "    raise RuntimeError(\"FreeSurfer recon-all is incomplete! Please wait till FreeSurfer recon-all is complete before continuing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: W-Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "if recon_all_complete == True and glm:\n",
    "    cprint(f\"Using GLM Model located at: {glm}\", \"green\", attrs=[\"bold\"])\n",
    "    filtered_subject_df = subject_df.replace({'sex': {\"M\": \"Male\", \"F\": \"Female\"}})\n",
    "    wmap_config = os.path.join(project_folder, \"config\", \"wmap_config.txt\")\n",
    "    with open(wmap_config, \"w\") as fp:\n",
    "        for i, row in filtered_subject_df.iterrows():\n",
    "            if row['subid'] in successful_subids:\n",
    "                fp.write(f\"{row['subid']} {row['sex']} {row['age']}\\n\")\n",
    "    nimsurf.make_cortical_thickness_wmap(wmap_config, freesurfer_subjects_folder, tmpdir, glm, outdir, fwhm)\n",
    "    wmap_complete = True\n",
    "elif recon_all_complete == False:\n",
    "    raise RuntimeError(\"FreeSurfer recon-all is incomplete! Please wait till FreeSurfer recon-all is complete before continuing!\")\n",
    "elif not glm:\n",
    "    raise RuntimeError(\"No GLM is selected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 (Optional): Threshold/Binarize your W-Maps\n",
    "**Instructions**\n",
    "1. If you wish to binarize your images, set `binarize = True`. If you just want to threshold, set `binarize = False`.\n",
    "2. Set the level to threshold or binarize at with `threshold`.\n",
    "3. Set the threshold/binarization direction with `direction`.\n",
    "\n",
    "    - If direction is `twosided`, will **threshold/binarize outside** the threshold level.\n",
    "    - Example: if threshold is 1 and direction is \"twosided\", then values **between** -1 and +1 will be zeroed.\n",
    "    ***\n",
    "    - If direction is `less`, will **zero out values greater than** the threshold level. (keeping values \"less\" than the threshold level)\n",
    "    - Example: if threshold is -1 and direction is \"less\", then values **greater** than -1 will be zeroed.\n",
    "    ***\n",
    "    - If direction is `greater`, will **zero out values less than the** threshold level. (keeping values \"greater\" than the threshold level)\n",
    "    - Example: if threshold is +1 and direction is \"greater\", then values **less** than +1 will be zeroed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize = True\n",
    "threshold = -2\n",
    "direction = \"less\"\n",
    "\n",
    "\n",
    "############################## DO NOT EDIT BELOW #####################################################\n",
    "if recon_all_complete == True and glm and wmap_complete:\n",
    "    wmaps = glob(outdir+\"/*.gii\")\n",
    "    wmap_dir = \"w_maps\"\n",
    "    if binarize:\n",
    "        wmap_dir += \"_bin\"\n",
    "    else:\n",
    "        wmap_dir += \"_thr\"\n",
    "    wmap_dir += f\"_{str(threshold)}\"\n",
    "    wmap_dir += f\"_{direction}\"\n",
    "    wmap_dir = os.path.join(project_folder, wmap_dir)\n",
    "    result_string = \"\"\n",
    "    if binarize:\n",
    "        result_string += \"W-Maps binarized at \"\n",
    "    else:\n",
    "        result_string += \"W-Maps thresholded at \"\n",
    "    result_string += f\"{str(threshold)} \"\n",
    "    result_string += f\"({direction}) \"\n",
    "    result_string += f\"are located at {wmap_dir}\"\n",
    "    os.makedirs(wmap_dir, exist_ok=True)\n",
    "    for wmap in tqdm(wmaps):\n",
    "        fname = os.path.basename(wmap)\n",
    "        gifti = nib.load(wmap)\n",
    "        nimsurf.threshold(gifti, threshold, direction, binarize, replace_val=0.0).to_filename(os.path.join(wmap_dir, fname))\n",
    "    cprint(result_string, \"green\", attrs=[\"bold\"])\n",
    "elif recon_all_complete == False:\n",
    "    raise RuntimeError(\"FreeSurfer recon-all is incomplete! Please wait till FreeSurfer recon-all is complete before continuing!\")\n",
    "elif not glm:\n",
    "    raise RuntimeError(\"No GLM is selected!\")\n",
    "elif not wmap_complete:\n",
    "    raise RuntimeError(\"W-Mapping not complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Surface Functional Network Mapping\n",
    "## Use the Preprocessing notebook on your W-Maps to calculate surface functional connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"/data/nimlab/new_ADNI/william_analysis/preprocessing_bug/test_surface_pipeline/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9 (nimlab)",
   "language": "python",
   "name": "nimlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
