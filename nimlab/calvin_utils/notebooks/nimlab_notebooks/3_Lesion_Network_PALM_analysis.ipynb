{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a Lesion Network Mapping GLM using FSL's PALM\n",
    "\n",
    "### Authors: Alexander Cohen, Christopher Lin, William Drew\n",
    "\n",
    "#### Last updated: July 6, 2022\n",
    "\n",
    "Use this to run/test a statistical model (e.g., regression or T-tests) on lesion network maps (or lesions alone!) using PALM, potentially taking into account specific covariates of interest and/or nuisance regressors.\n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with GLM design and Contrast Matrix design. See this webpage to get started:\n",
    "[FSL's GLM page](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM)\n",
    "- This notebook is a combination of the old PALM Notebooks and Christopher's palm_analysis notebooks (does the same thing) and requires the NIMLAB Python 3 environment as a kernel. Directions are on the [NIMLAB software_env README.md](https://github.com/nimlab/software_env)\n",
    "- You will need a csv file that provides the paths to your fcMaps, usually created from the [Preprocessing](https://github.com/nimlab/templates/blob/master/py3_notebooks/1_Preprocessing_LesionQA_fcSurfBcbLqtGen_nimtrack.ipynb) notebook.\n",
    "- Christopher wrote up a really nice description of how to modify code to set up your design matrix within the notebook here: [PALM-Analysis](https://github.com/nimlab/documentation/wiki/PALM-experimental-designs)\n",
    "- I would also recommend reviewing Fred's [slides](https://github.com/nimlab/documentation/blob/master/presentations/presentation_palm_multidataset_analyses_labmeeting_13.4.2020.pdf) from his May 2020 lab meeting For details regarding the difference between implementing a random effects and fixed effects analysis and use of exchangeability blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages and environmental settings:\n",
    "\n",
    "##Packages:\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from nimlab import software as sf\n",
    "from nimlab import datasets as nimds\n",
    "from nilearn import image, plotting\n",
    "\n",
    "MNI_brain_mask = nimds.get_img(\"MNI152_T1_2mm_brain_mask\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input/Output Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Provide your email address for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your email address here in quotes:\n",
    "creator_email = \"wdrew@bwh.harvard.edu\"\n",
    "creator_user = \"wd957\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Where are your data? and where do you want the results to go?\n",
    "NOTES: \n",
    "- `dataset_csv` is the csv file created from the `Preprocessing` or `xnat_grabber` notebooks that points to your Lesions and fcMaps (will also work with older csv files from `xnat_gate`).\n",
    "- If you are comparing multiple datasets, your csv should contain both, i.e., specify both in xnat_grabber, or just concatenate the files in excel, etc...\n",
    "- You can optionally add all the available covariates to this csv file before you begin as well and we'll filter down to the ones you want (my recommendation). However, if you have them in a separate spreadshet, just list the csv file with the imaging data here and we'll address creating a separate phenotype csv file in a few steps...\n",
    "- `VOI` = Variable of Interest = Column Header containing your primary measure for THIS notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your dataset.csv file\n",
    "\n",
    "# dataset_csv = \"your_dataset_csv_file.csv\"\n",
    "# output_dir = \"3_PALM_Analysis_of_datasetA_and_covariateB\"\n",
    "\n",
    "dataset_csv = \"../LNM_Corbetta_Lesions_w_phenotypes.csv\"\n",
    "output_dir = \"3_PALM_Corbetta_Language\"\n",
    "VOI = \"Language\"\n",
    "\n",
    "clean_df = pd.read_csv(dataset_csv)\n",
    "\n",
    "\n",
    "### Code to remove rows where a particular column has no data:\n",
    "clean_df.dropna(how='any', subset=[VOI],inplace=True)\n",
    "###\n",
    "\n",
    "\n",
    "# Specify which files are to be used as input:\n",
    "# This is usually 'func_T' but the other files could be used as well\n",
    "# ('Lesion', 'AvgR', 'AvgR_Fz', or 'func_T')\n",
    "input_imgs = clean_df['t']\n",
    "\n",
    "working_dir = os.path.join(output_dir,\"palm_config\")\n",
    "if not os.path.exists(working_dir):\n",
    "    os.makedirs(working_dir)\n",
    "\n",
    "print(\"I found\", len(clean_df), \"participants in\", len(clean_df.dataset.unique()),\"different datasets:\",clean_df.dataset.unique())\n",
    "print(\"\")\n",
    "print(\"Results will be stored in a sub-directory named: \",output_dir)\n",
    "display(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a design matrix\n",
    "\n",
    "NOTES:\n",
    "- The design matrix tells PALM about the statistical structure of your data\n",
    "- Rows = subjects/maps/observations\n",
    "- Columns = \"explanatory variables\" or EVs\n",
    "    - EVs can be independent binary or continuous variables that you are interested in studying.\n",
    "    - EVs can also be 'nuisance' variables you are not interested in (like lesion size, or type of data).\n",
    "    - By including any EVs you think could effect the fcMaps, your statistical estimate for the EV of interest (your 'contrast' of interest) will be more specific and less likely to be due to a confound, but there are specific reasons to *not* include a nuisance variable from time to time.\n",
    "- Examples:\n",
    "    - [Two Sample T-Test](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Two-Group_Difference_.28Two-Sample_Unpaired_T-Test.29)\n",
    "    - [One Sample with Covariate](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Single-Group_Average_with_Additional_Covariate)\n",
    "\n",
    "#### IMPORTANT: Only run **ONE** of the following two sets of cells depending on how you want to create your design matrix:\n",
    "- If you want to manually edit your design matrix, i.e., in Excel, choose **Option 1**.\n",
    "- If you want to generate your design matrix with code, i.e., using Christopher's [examples](https://github.com/nimlab/documentation/wiki/PALM-experimental-designs), choose **Option 2**.\n",
    "- **Both** options allow you to automatically add lesion sizes.\n",
    "- If you started with a combined imaging + phenotype csv at the top, use **Option 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION ONE (part A) - If you are going to manually add your EVs, first use this cell:\n",
    "NOTE: If a `dataset_phenotype.csv` already exists (you are re-running this notebook), the file will NOT be overwritten. If you want a new template to be created, delete the file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will create a template phenotype file that lists your files and the dataset and subject names:\n",
    "\n",
    "# Do you want me to add lesion sizes to the phenotype file for you?\n",
    "add_lesion_sizes = True\n",
    "\n",
    "phenotype_csv = output_dir +\"/phenotype.csv\"\n",
    "\n",
    "if not os.path.exists(phenotype_csv):\n",
    "    template_design_matrix = clean_df[['dataset','subject']].copy()\n",
    "    template_design_matrix.insert(0,'files',input_imgs)\n",
    "    if add_lesion_sizes:\n",
    "        lesion_sizes=[]\n",
    "        for lesion in tqdm(clean_df.roi):\n",
    "            lesion_sizes.append(np.count_nonzero(np.nan_to_num(image.load_img(lesion, dtype=\"int16\").get_fdata())))\n",
    "        template_design_matrix['lesion_sizes']=lesion_sizes\n",
    "    template_design_matrix.to_csv(phenotype_csv, index=False)\n",
    "    print(\"\")\n",
    "    print(\"A Template Design Matrix (with labels) has been created at\",os.path.abspath(phenotype_csv))\n",
    "else:\n",
    "    print(\"There is already a file named:\",os.path.abspath(phenotype_csv))\n",
    "    print(\"If you want to make a new one, delete this file first and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION ONE (part B) - After you have manually added your EVs, then use this cell to load your modified phenotype.csv:\n",
    "NOTE: Don't change the name, just edit/modify the file in place, and this code will load the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your modified phenotype file and create a design matrix from it:\n",
    "design_matrix = pd.read_csv(phenotype_csv)\n",
    "ordered_input_imgs=design_matrix['files']\n",
    "design_matrix = design_matrix.drop(columns=['files','dataset','subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION TWO - If you are going to construct your design matrix using code, uncomment (Cmd+/ or Control+/) and use this cell:\n",
    "\n",
    "The instructions/examples Christopher put together are on [GitHub](https://github.com/nimlab/documentation/wiki/PALM-experimental-designs), and the possible patterns are listed on the FSL [GLM website](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM).\n",
    "\n",
    "- Typical Examples:\n",
    "    - [Two Sample T-Test](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Two-Group_Difference_.28Two-Sample_Unpaired_T-Test.29)\n",
    "    - [One Sample with Covariate](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Single-Group_Average_with_Additional_Covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this cell according to the documentation page:\n",
    "# https://github.com/nimlab/documentation/wiki/PALM-experimental-designs\n",
    "\n",
    "# Keep these two lines:\n",
    "design_matrix = pd.DataFrame()\n",
    "ordered_input_imgs=input_imgs\n",
    "design_matrix[VOI] = clean_df[VOI].copy()\n",
    "\n",
    "\n",
    "coding_key = {\"Corbetta_Lesions\": 1}\n",
    "design_matrix[\"intercept\"] = [1] * clean_df.shape[0]\n",
    "design_matrix[\"group\"] = clean_df['dataset'].replace(coding_key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Do you want to also add lesion sizes to the design matrix?\n",
    "add_lesion_sizes = True\n",
    "\n",
    "\n",
    "if add_lesion_sizes:\n",
    "    lesion_sizes=[]\n",
    "    for lesion in tqdm(clean_df.Lesion):\n",
    "        lesion_sizes.append(np.count_nonzero(np.nan_to_num(image.load_img(lesion, dtype=\"int16\").get_fdata())))\n",
    "    design_matrix['lesion_sizes']=lesion_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Mean-Center your covariates\n",
    "NOTES:\n",
    "- This is described [here](http://mumford.fmripower.org/mean_centering/) and on the FSL [GLM website](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM).\n",
    "- Add lines as necessary for your covariates.\n",
    "- Your 'dummy' variables (0 vs 1) for group membership do not need to bee mean-centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mean center any continous variables\n",
    "# design_matrix['covariateA'] = design_matrix['covariateA'].sub(design_matrix['covariateA'].mean())  \n",
    "# design_matrix['covariateB'] = design_matrix['covariateB'].sub(design_matrix['covariateB'].mean())  \n",
    "\n",
    "### mean center the lesion sizes AND divide by 1000 to get the numbers ~0-100s or so:\n",
    "# (According to Anderson, having values in the 10,000s could cause statistical weirdness...)\n",
    "design_matrix['lesion_sizes'] = design_matrix['lesion_sizes'].sub(design_matrix['lesion_sizes'].mean()).div(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Show me what the design matrix looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I found\",len(design_matrix. columns),\"EVs IN THIS ORDER:\",list(design_matrix.columns))\n",
    "\n",
    "if 'lesion_sizes' in design_matrix.columns:\n",
    "    fig, axs = plt.subplots(1,2,sharey=True)\n",
    "    a1 = axs[0].imshow(design_matrix.drop(columns=['lesion_sizes']), aspect='auto')\n",
    "    a2 = axs[1].imshow(design_matrix.filter(['lesion_sizes']), aspect='auto')\n",
    "    plt.colorbar(a1,ax=axs[0])\n",
    "    plt.colorbar(a2,ax=axs[1])\n",
    "    print(\"Plotting the lesion sizes separately b/c they overwhelm the 1s and 0s\")\n",
    "else:\n",
    "    plt.imshow(design_matrix, aspect='auto')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Now, Create a contrast matrix\n",
    "\n",
    "NOTES:\n",
    "- Each 'contrast' is a statistical test where you are asking the question: **where** in the brain do the values behave like the single EV, or combination of EVs, that you specifiy in your contrast. This is also discussed on the FSL [GLM website](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM).\n",
    "- Each 'contrast' is a short list of numbers, one per EV, typically +1,0,-1 that are **in the same order as the columns of your design matrix**.\n",
    "- There are different ways to organize your design matrix and contrast matrix to achieve the same goals, this is where collaborating with someone who has done this before is important to make sure you are 'asking' the question you think you are asking.\n",
    "- Note that if you want to use TFCE for both positive and negative contrasts, you have to code for them both and switch from doing a single two-tailed test to doing two one-tailed test (with corrcon correction turned on, which makes it two-tailed again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this cell according to the documentation page:\n",
    "# https://github.com/nimlab/documentation/wiki/PALM-Analyses\n",
    "\n",
    "contrast_df = pd.DataFrame()\n",
    "\n",
    "contrast_df[VOI] = [0, 1, 0]\n",
    "\n",
    "# contrast_df[VOI+\"_A>B\"] = [0, 1, 0]\n",
    "# contrast_df[VOI+\"_B>A\"] = [0, -1, 0]\n",
    "\n",
    "contrast_matrix = contrast_df.T\n",
    "contrast_matrix.columns = design_matrix.columns\n",
    "print(\"Each row is a contrast, each column is an EV:\")\n",
    "print(\"\")\n",
    "display(contrast_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. (Optional) Generate exchangeability blocks if needed\n",
    "NOTES:\n",
    "- This is optional and for when you are doing a 'meta-analysis' of multiple data types, e.g. strokes and DBS sites\n",
    "- This is a column of integers that can usually be generated from the dataset names. Details on the [PALM website](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/PALM/ExchangeabilityBlocks)\n",
    "- To use this, add the following to the `call_palm` command below `eb=eb_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is just an example, you will have to edit to adapt to your data, \n",
    "### but it should be integers, starting with 1,2,3....\n",
    "\n",
    "# coding_key = {\"Prosopagnosia_w_Yeo1000\": 1,\n",
    "#              \"Corbetta_Lesions\": 1,\n",
    "#              \"DBS_dataset\": 2\n",
    "#              }\n",
    "\n",
    "# eb_matrix = pd.DataFrame()\n",
    "# eb_matrix = clean_df['dataset'].replace(coding_key)\n",
    "# display(eb_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. FINALLY, Run PALM\n",
    "\n",
    "NOTES:\n",
    "- This can take awhile depending on the number of subjects and the number of contrasts, make sure you are running this in a 'protected' session, i.e., jupyter was run in a `tmux` session or an onDemand session.\n",
    "- There are options for the `call_palm` function to allow for getting tfce-fwe results, using exchangeability blocks, 1-p, etc... See the documentation here: [GitHub](https://github.com/nimlab/documentation/wiki/PALM-explainer)\n",
    "    - `accel = \"tail\"` only applies to the FWE results, not the FDR or uncorrected results.\n",
    "    - `corrcon_flag = True` does FWER-correction across all contrasts, taking into account any dependency that may exist between these contrasts. This can be used for directional one-way t-tests where you want to do TFCE for each direction.\n",
    "    - **The default is to save 1-p maps**, but set `save_1p=False` and `logp=True` to instead save **-log10(p) maps**, i.e., 0.05 ~ 1.3, 0.01 ~ 2, 0.001 ~3, etc... which is **great** for visualization\n",
    "    - ~5000 permutations is considered standard, running less, like ~1000 with tail acceleration on can be useful for testing, but *the uncorrected p values can be misleading* (more iterations = more precision, not more significance)\n",
    "    - `demean = True` will mean center the data, as well as all columns of the design matrix. If the original design had an intercept, the intercept is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this according to documentation page\n",
    "\n",
    "# Current best default settings:\n",
    "sf.call_palm(ordered_input_imgs,\n",
    "             design_matrix,\n",
    "             contrast_matrix,\n",
    "             working_dir,\n",
    "             output_dir,\n",
    "             2000,\n",
    "             accel=\"tail\",\n",
    "             eb=None,\n",
    "             demean=False,\n",
    "             mask=\"\",\n",
    "             save_1p=True,\n",
    "             logp=False,\n",
    "             tfce=False,\n",
    "             ise_flag=False,\n",
    "             two_tailed_flag=True,\n",
    "             corrcon_flag=False,\n",
    "             fdr_flag=False,\n",
    "             cluster_name=\"eristwo-slurm\",\n",
    "             username=creator_user,\n",
    "             cluster_email=creator_email,\n",
    "             queue=\"normal,nimlab\",\n",
    "             cores=\"1\",\n",
    "             memory=\"8000\",\n",
    "             dryrun=False,\n",
    "             job_name=\"\",\n",
    "             job_time=\"\",\n",
    "             num_nodes=\"\",\n",
    "             num_tasks=\"\",\n",
    "             x11_forwarding=\"\",\n",
    "             service_class=\"\",\n",
    "             debug=False,\n",
    "             extra=\"\"\n",
    "    )\n",
    "\n",
    "# # Settings for looking at TFCE results in both positive and negative directions:\n",
    "# sf.call_palm(ordered_input_imgs,\n",
    "#              design_matrix,\n",
    "#              contrast_matrix,\n",
    "#              working_dir,\n",
    "#              output_dir,\n",
    "#              2000,\n",
    "#              accel=\"tail\",\n",
    "#              eb=None,\n",
    "#              mask=\"\",\n",
    "#              save_1p=True,\n",
    "#              logp=False,\n",
    "#              tfce=True,\n",
    "#              ise_flag=False,\n",
    "#              two_tailed_flag=False,\n",
    "#              corrcon_flag=True,\n",
    "#              fdr_flag=False,\n",
    "#              cluster_name=\"erisone\",\n",
    "#              username=creator_user,\n",
    "#              cluster_email=creator_email,\n",
    "#              queue=\"normal\",\n",
    "#              cores=\"1\",\n",
    "#              memory=\"6000\",\n",
    "#              dryrun=False,\n",
    "#              job_name=\"\",\n",
    "#              job_time=\"\",\n",
    "#              num_nodes=\"\",\n",
    "#              num_tasks=\"\",\n",
    "#              x11_forwarding=\"\",\n",
    "#              service_class=\"\",\n",
    "#              debug=False,\n",
    "#              extra=\"\")\n",
    "\n",
    "# Settings that are more consistent with prior usage:\n",
    "# sf.call_palm(ordered_input_imgs,\n",
    "#              design_matrix,\n",
    "#              contrast_matrix,\n",
    "#              working_dir,\n",
    "#              output_dir,\n",
    "#              1000,\n",
    "#              tfce=True,\n",
    "#              fdr_flag=True,\n",
    "#              accel=\"tail\",\n",
    "#              cluster_name=\"erisone\",\n",
    "#              username=creator_user,\n",
    "#              cluster_email=creator_email,\n",
    "#              queue=\"normal\",\n",
    "#              cores=\"1\",\n",
    "#              memory=\"6000\",\n",
    "#              dryrun=False,\n",
    "#              job_name=\"\",\n",
    "#              job_time=\"\",\n",
    "#              num_nodes=\"\",\n",
    "#              num_tasks=\"\",\n",
    "#              x11_forwarding=\"\",\n",
    "#              service_class=\"\",\n",
    "#              debug=False,\n",
    "#              extra=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Show me the results\n",
    "\n",
    "Notes: \n",
    "- I have intentionally left the function definition here so that you can modify it as needed. Note the option for slices, cmap, and vmax are currently set inside the function to keep all the maps comparable. If this is clunkly, we can change this.\n",
    "- Note the p-value is given as 1-p (so put 0.95 for p<0.05...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that thresholds Tmaps using a specified p-value map and alpha level\n",
    "def thresholded_PALM_Tmap(output_dir,tvalue_file='_vox_tstat.nii', pvalue_file='_vox_tstat_fwep.nii', threshold='0.95',showT=False):\n",
    "    tvalue_map = image.math_img(\"a*b\",a=os.path.join(output_dir,tvalue_file),b=MNI_brain_mask)\n",
    "    pvalue_map = os.path.join(output_dir,pvalue_file)\n",
    "    pvalue_mask = image.math_img(f'MNI_brain_mask * img > {threshold}', img=pvalue_map, MNI_brain_mask=MNI_brain_mask)\n",
    "    combined = image.math_img(\"a*b\",a=tvalue_map,b=pvalue_mask)\n",
    "    print(\"There are\",np.sum(pvalue_mask.get_fdata()),\"non-zero voxels in this maps\")\n",
    "    if showT:\n",
    "        plotting.plot_stat_map(tvalue_map, \n",
    "                display_mode=\"z\", cut_coords=[-42,-24,-12,0,12,24,42,54], cmap=\"cold_hot\", colorbar=True, title=tvalue_file, vmax=6)\n",
    "    plotting.plot_stat_map(combined, \n",
    "                display_mode=\"z\", cut_coords=[-42,-24,-12,0,12,24,42,54], cmap=\"cold_hot\", colorbar=True,title=pvalue_file, vmax=6)\n",
    "\n",
    "    \n",
    "print(\"FWE\")\n",
    "thresholded_PALM_Tmap(output_dir,tvalue_file='_vox_tstat.nii', pvalue_file='_vox_tstat_fwep.nii', threshold='0.95',showT=True)\n",
    "\n",
    "print(\"FDR\")\n",
    "thresholded_PALM_Tmap(output_dir,tvalue_file='_vox_tstat.nii', pvalue_file='_vox_tstat_fdrp.nii', threshold='0.95')\n",
    "\n",
    "print(\"uncorrected\")\n",
    "thresholded_PALM_Tmap(output_dir,tvalue_file='_vox_tstat.nii', pvalue_file='_vox_tstat_uncp.nii', threshold='0.95')\n",
    "\n",
    "# print(\"TFCE FWE\")\n",
    "# thresholded_PALM_Tmap(output_dir,tvalue_file='_tfce_tstat.nii', pvalue_file='_tfce_tstat_fwep.nii', threshold='0.95')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Clean up files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the big temporary file to keep result directories small:\n",
    "os.remove(os.path.join(working_dir,'concat.nii'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.10 Nimlab",
   "language": "python",
   "name": "nimlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
