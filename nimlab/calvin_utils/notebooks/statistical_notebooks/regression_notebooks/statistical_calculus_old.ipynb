{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run A Mixed Effects Model\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: July 6, 2023\n",
    "\n",
    "Use this to assess if a predictors relationship to the predictee is different between two groups. \n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with mixed effects models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/metadata/master_list_proper_subjects.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/retrospective_cohorts_figure/analyses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_T_By_Origin_Group_</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Subiculum_Connectivity_T</th>\n",
       "      <th>Amnesia_Lesion_T_Map</th>\n",
       "      <th>...</th>\n",
       "      <th>Estimated_Outcome</th>\n",
       "      <th>Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline__Lower_is_Better_</th>\n",
       "      <th>Min_Max_Normalized_Baseline</th>\n",
       "      <th>MinMaxNormBaseline_Higher_is_Better</th>\n",
       "      <th>ROI_to_Alz_Max</th>\n",
       "      <th>ROI_to_PD_Max</th>\n",
       "      <th>Standardzied_AD_Max</th>\n",
       "      <th>Standardized_PD_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.392857</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>56.864683</td>\n",
       "      <td>0.447264</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>1.518764</td>\n",
       "      <td>-1.518764</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.222658</td>\n",
       "      <td>14.493929</td>\n",
       "      <td>-1.714513</td>\n",
       "      <td>-1.227368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>52.970984</td>\n",
       "      <td>0.436157</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.020048</td>\n",
       "      <td>15.257338</td>\n",
       "      <td>-1.155843</td>\n",
       "      <td>-1.022243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.447368</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>62.459631</td>\n",
       "      <td>0.497749</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.118727</td>\n",
       "      <td>17.376384</td>\n",
       "      <td>-0.814348</td>\n",
       "      <td>-0.452865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-2.372549</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>59.611631</td>\n",
       "      <td>0.432617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>13.112424</td>\n",
       "      <td>15.287916</td>\n",
       "      <td>-1.437954</td>\n",
       "      <td>-1.014027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.192982</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>57.928350</td>\n",
       "      <td>0.193389</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.086568</td>\n",
       "      <td>12.951426</td>\n",
       "      <td>-0.824344</td>\n",
       "      <td>-1.641831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>211</td>\n",
       "      <td>58.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.415745</td>\n",
       "      <td>-0.189000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>152</td>\n",
       "      <td>69.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.701419</td>\n",
       "      <td>-0.455000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>DECLINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>208</td>\n",
       "      <td>79.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.929958</td>\n",
       "      <td>-0.669000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>DECLINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>223</td>\n",
       "      <td>71.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.829972</td>\n",
       "      <td>-0.575000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>DECLINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>214</td>\n",
       "      <td>76.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.244199</td>\n",
       "      <td>-0.958000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>DECLINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject   Age  Normalized_Percent_Cognitive_Improvement  \\\n",
       "0        101  62.0                                 -0.392857   \n",
       "1        102  77.0                                 -0.666667   \n",
       "2        103  76.0                                 -1.447368   \n",
       "3        104  65.0                                 -2.372549   \n",
       "4        105  50.0                                 -0.192982   \n",
       "..       ...   ...                                       ...   \n",
       "194      211  58.7                                       NaN   \n",
       "195      152  69.4                                       NaN   \n",
       "196      208  79.2                                       NaN   \n",
       "197      223  71.1                                       NaN   \n",
       "198      214  76.6                                       NaN   \n",
       "\n",
       "     Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group  \\\n",
       "0                                             0.314066        \n",
       "1                                             0.013999        \n",
       "2                                            -0.841572        \n",
       "3                                            -1.855477        \n",
       "4                                             0.533109        \n",
       "..                                                 ...        \n",
       "194                                                NaN        \n",
       "195                                                NaN        \n",
       "196                                                NaN        \n",
       "197                                                NaN        \n",
       "198                                                NaN        \n",
       "\n",
       "     Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "0                                  0.314066                     -21.428571   \n",
       "1                                  0.013999                     -36.363636   \n",
       "2                                 -0.841572                     -78.947368   \n",
       "3                                 -1.855477                    -129.411765   \n",
       "4                                  0.533109                     -10.526316   \n",
       "..                                      ...                            ...   \n",
       "194                                     NaN                            NaN   \n",
       "195                                     NaN                            NaN   \n",
       "196                                     NaN                            NaN   \n",
       "197                                     NaN                            NaN   \n",
       "198                                     NaN                            NaN   \n",
       "\n",
       "     Z_Scored_Subiculum_T_By_Origin_Group_  Z_Scored_Subiculum_Connectivity_T  \\\n",
       "0                                -1.282630                          -1.282630   \n",
       "1                                -1.760917                          -1.760917   \n",
       "2                                -0.595369                          -0.595369   \n",
       "3                                -0.945206                          -0.945206   \n",
       "4                                -1.151973                          -1.151973   \n",
       "..                                     ...                                ...   \n",
       "194                              -0.415745                          -0.189000   \n",
       "195                              -0.701419                          -0.455000   \n",
       "196                              -0.929958                          -0.669000   \n",
       "197                              -0.829972                          -0.575000   \n",
       "198                              -1.244199                          -0.958000   \n",
       "\n",
       "     Subiculum_Connectivity_T  Amnesia_Lesion_T_Map  ...  Estimated_Outcome  \\\n",
       "0                   56.864683              0.447264  ...                NaN   \n",
       "1                   52.970984              0.436157  ...                NaN   \n",
       "2                   62.459631              0.497749  ...                NaN   \n",
       "3                   59.611631              0.432617  ...                NaN   \n",
       "4                   57.928350              0.193389  ...                NaN   \n",
       "..                        ...                   ...  ...                ...   \n",
       "194                 19.900000                   NaN  ...               GOOD   \n",
       "195                 17.900000                   NaN  ...            DECLINE   \n",
       "196                 16.300000                   NaN  ...            DECLINE   \n",
       "197                 17.000000                   NaN  ...            DECLINE   \n",
       "198                 14.100000                   NaN  ...            DECLINE   \n",
       "\n",
       "     Cognitive_Baseline  Z_Scored_Cognitive_Baseline  \\\n",
       "0                    28                     1.518764   \n",
       "1                    22                     0.465551   \n",
       "2                    19                    -0.061056   \n",
       "3                    17                    -0.412127   \n",
       "4                    19                    -0.061056   \n",
       "..                  ...                          ...   \n",
       "194                 NaN                          NaN   \n",
       "195                 NaN                          NaN   \n",
       "196                 NaN                          NaN   \n",
       "197                 NaN                          NaN   \n",
       "198                 NaN                          NaN   \n",
       "\n",
       "     Z_Scored_Cognitive_Baseline__Lower_is_Better_  \\\n",
       "0                                        -1.518764   \n",
       "1                                        -0.465551   \n",
       "2                                         0.061056   \n",
       "3                                         0.412127   \n",
       "4                                         0.061056   \n",
       "..                                             ...   \n",
       "194                                            NaN   \n",
       "195                                            NaN   \n",
       "196                                            NaN   \n",
       "197                                            NaN   \n",
       "198                                            NaN   \n",
       "\n",
       "     Min_Max_Normalized_Baseline  MinMaxNormBaseline_Higher_is_Better  \\\n",
       "0                           0.72                                 0.28   \n",
       "1                           0.48                                 0.52   \n",
       "2                           0.36                                 0.64   \n",
       "3                           0.28                                 0.72   \n",
       "4                           0.36                                 0.64   \n",
       "..                           ...                                  ...   \n",
       "194                          NaN                                  NaN   \n",
       "195                          NaN                                  NaN   \n",
       "196                          NaN                                  NaN   \n",
       "197                          NaN                                  NaN   \n",
       "198                          NaN                                  NaN   \n",
       "\n",
       "     ROI_to_Alz_Max  ROI_to_PD_Max  Standardzied_AD_Max  Standardized_PD_Max  \n",
       "0         12.222658      14.493929            -1.714513            -1.227368  \n",
       "1         14.020048      15.257338            -1.155843            -1.022243  \n",
       "2         15.118727      17.376384            -0.814348            -0.452865  \n",
       "3         13.112424      15.287916            -1.437954            -1.014027  \n",
       "4         15.086568      12.951426            -0.824344            -1.641831  \n",
       "..              ...            ...                  ...                  ...  \n",
       "194             NaN            NaN                  NaN                  NaN  \n",
       "195             NaN            NaN                  NaN                  NaN  \n",
       "196             NaN            NaN                  NaN                  NaN  \n",
       "197             NaN            NaN                  NaN                  NaN  \n",
       "198             NaN            NaN                  NaN                  NaN  \n",
       "\n",
       "[199 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet='master_list_proper_subjects')\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T',\n",
       "       'Amnesia_Lesion_T_Map', 'Memory_Network_T', 'Z_Scored_Memory_Network_R',\n",
       "       'Memory_Network_R', 'Subiculum_Grey_Matter', 'Subiculum_White_Matter',\n",
       "       'Subiculum_CSF', 'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Age_Group', 'Age_And_Disease',\n",
       "       'Age_Disease_and_Cohort', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Cognitive_Outcome',\n",
       "       'Estimated_Outcome', 'Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Age', 'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group', 'Z_Scored_Subiculum_T_By_Origin_Group_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_T_By_Origin_Group_</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Subiculum_Connectivity_T</th>\n",
       "      <th>Amnesia_Lesion_T_Map</th>\n",
       "      <th>...</th>\n",
       "      <th>Estimated_Outcome</th>\n",
       "      <th>Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline__Lower_is_Better_</th>\n",
       "      <th>Min_Max_Normalized_Baseline</th>\n",
       "      <th>MinMaxNormBaseline_Higher_is_Better</th>\n",
       "      <th>ROI_to_Alz_Max</th>\n",
       "      <th>ROI_to_PD_Max</th>\n",
       "      <th>Standardzied_AD_Max</th>\n",
       "      <th>Standardized_PD_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.392857</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>56.864683</td>\n",
       "      <td>0.447264</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>1.518764</td>\n",
       "      <td>-1.518764</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.222658</td>\n",
       "      <td>14.493929</td>\n",
       "      <td>-1.714513</td>\n",
       "      <td>-1.227368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>52.970984</td>\n",
       "      <td>0.436157</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.020048</td>\n",
       "      <td>15.257338</td>\n",
       "      <td>-1.155843</td>\n",
       "      <td>-1.022243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.447368</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>62.459631</td>\n",
       "      <td>0.497749</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.118727</td>\n",
       "      <td>17.376384</td>\n",
       "      <td>-0.814348</td>\n",
       "      <td>-0.452865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-2.372549</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>59.611631</td>\n",
       "      <td>0.432617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>13.112424</td>\n",
       "      <td>15.287916</td>\n",
       "      <td>-1.437954</td>\n",
       "      <td>-1.014027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.192982</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>57.928350</td>\n",
       "      <td>0.193389</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.086568</td>\n",
       "      <td>12.951426</td>\n",
       "      <td>-0.824344</td>\n",
       "      <td>-1.641831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>86</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598787</td>\n",
       "      <td>-0.099428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.087220</td>\n",
       "      <td>-0.621000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598787</td>\n",
       "      <td>-0.099428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598397</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>88</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.854050</td>\n",
       "      <td>2.637141</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>0.269872</td>\n",
       "      <td>-0.207000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>89</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598787</td>\n",
       "      <td>-0.099428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.158639</td>\n",
       "      <td>-0.694000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>91</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.818759</td>\n",
       "      <td>0.535847</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.469844</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject   Age  Normalized_Percent_Cognitive_Improvement  \\\n",
       "0        101  62.0                                 -0.392857   \n",
       "1        102  77.0                                 -0.666667   \n",
       "2        103  76.0                                 -1.447368   \n",
       "3        104  65.0                                 -2.372549   \n",
       "4        105  50.0                                 -0.192982   \n",
       "..       ...   ...                                       ...   \n",
       "160       86  57.0                                       NaN   \n",
       "161       87  65.0                                       NaN   \n",
       "162       88  65.0                                       NaN   \n",
       "163       89  67.0                                       NaN   \n",
       "164       91  45.0                                       NaN   \n",
       "\n",
       "     Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group  \\\n",
       "0                                             0.314066        \n",
       "1                                             0.013999        \n",
       "2                                            -0.841572        \n",
       "3                                            -1.855477        \n",
       "4                                             0.533109        \n",
       "..                                                 ...        \n",
       "160                                           0.598787        \n",
       "161                                           0.598787        \n",
       "162                                           5.854050        \n",
       "163                                           0.598787        \n",
       "164                                           1.818759        \n",
       "\n",
       "     Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "0                                  0.314066                     -21.428571   \n",
       "1                                  0.013999                     -36.363636   \n",
       "2                                 -0.841572                     -78.947368   \n",
       "3                                 -1.855477                    -129.411765   \n",
       "4                                  0.533109                     -10.526316   \n",
       "..                                      ...                            ...   \n",
       "160                               -0.099428                       0.000000   \n",
       "161                               -0.099428                       0.000000   \n",
       "162                                2.637141                      15.384615   \n",
       "163                               -0.099428                       0.000000   \n",
       "164                                0.535847                       3.571429   \n",
       "\n",
       "     Z_Scored_Subiculum_T_By_Origin_Group_  Z_Scored_Subiculum_Connectivity_T  \\\n",
       "0                                -1.282630                          -1.282630   \n",
       "1                                -1.760917                          -1.760917   \n",
       "2                                -0.595369                          -0.595369   \n",
       "3                                -0.945206                          -0.945206   \n",
       "4                                -1.151973                          -1.151973   \n",
       "..                                     ...                                ...   \n",
       "160                              -0.087220                          -0.621000   \n",
       "161                               0.598397                           0.173000   \n",
       "162                               0.269872                          -0.207000   \n",
       "163                              -0.158639                          -0.694000   \n",
       "164                               0.469844                           0.019400   \n",
       "\n",
       "     Subiculum_Connectivity_T  Amnesia_Lesion_T_Map  ...  Estimated_Outcome  \\\n",
       "0                   56.864683              0.447264  ...                NaN   \n",
       "1                   52.970984              0.436157  ...                NaN   \n",
       "2                   62.459631              0.497749  ...                NaN   \n",
       "3                   59.611631              0.432617  ...                NaN   \n",
       "4                   57.928350              0.193389  ...                NaN   \n",
       "..                        ...                   ...  ...                ...   \n",
       "160                 22.200000                   NaN  ...                NaN   \n",
       "161                 27.000000                   NaN  ...                NaN   \n",
       "162                 24.700000                   NaN  ...                NaN   \n",
       "163                 21.700000                   NaN  ...                NaN   \n",
       "164                 26.100000                   NaN  ...                NaN   \n",
       "\n",
       "     Cognitive_Baseline  Z_Scored_Cognitive_Baseline  \\\n",
       "0                    28                     1.518764   \n",
       "1                    22                     0.465551   \n",
       "2                    19                    -0.061056   \n",
       "3                    17                    -0.412127   \n",
       "4                    19                    -0.061056   \n",
       "..                  ...                          ...   \n",
       "160                 NaN                          NaN   \n",
       "161                 NaN                          NaN   \n",
       "162                 NaN                          NaN   \n",
       "163                 NaN                          NaN   \n",
       "164                 NaN                          NaN   \n",
       "\n",
       "     Z_Scored_Cognitive_Baseline__Lower_is_Better_  \\\n",
       "0                                        -1.518764   \n",
       "1                                        -0.465551   \n",
       "2                                         0.061056   \n",
       "3                                         0.412127   \n",
       "4                                         0.061056   \n",
       "..                                             ...   \n",
       "160                                            NaN   \n",
       "161                                            NaN   \n",
       "162                                            NaN   \n",
       "163                                            NaN   \n",
       "164                                            NaN   \n",
       "\n",
       "     Min_Max_Normalized_Baseline  MinMaxNormBaseline_Higher_is_Better  \\\n",
       "0                           0.72                                 0.28   \n",
       "1                           0.48                                 0.52   \n",
       "2                           0.36                                 0.64   \n",
       "3                           0.28                                 0.72   \n",
       "4                           0.36                                 0.64   \n",
       "..                           ...                                  ...   \n",
       "160                          NaN                                  NaN   \n",
       "161                          NaN                                  NaN   \n",
       "162                          NaN                                  NaN   \n",
       "163                          NaN                                  NaN   \n",
       "164                          NaN                                  NaN   \n",
       "\n",
       "     ROI_to_Alz_Max  ROI_to_PD_Max  Standardzied_AD_Max  Standardized_PD_Max  \n",
       "0         12.222658      14.493929            -1.714513            -1.227368  \n",
       "1         14.020048      15.257338            -1.155843            -1.022243  \n",
       "2         15.118727      17.376384            -0.814348            -0.452865  \n",
       "3         13.112424      15.287916            -1.437954            -1.014027  \n",
       "4         15.086568      12.951426            -0.824344            -1.641831  \n",
       "..              ...            ...                  ...                  ...  \n",
       "160             NaN            NaN                  NaN                  NaN  \n",
       "161             NaN            NaN                  NaN                  NaN  \n",
       "162             NaN            NaN                  NaN                  NaN  \n",
       "163             NaN            NaN                  NaN                  NaN  \n",
       "164             NaN            NaN                  NaN                  NaN  \n",
       "\n",
       "[148 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T',\n",
       "       'Amnesia_Lesion_T_Map', 'Memory_Network_T', 'Z_Scored_Memory_Network_R',\n",
       "       'Memory_Network_R', 'Subiculum_Grey_Matter', 'Subiculum_White_Matter',\n",
       "       'Subiculum_CSF', 'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Age_Group', 'Age_And_Disease',\n",
       "       'Age_Disease_and_Cohort', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Cognitive_Outcome',\n",
       "       'Estimated_Outcome', 'Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'City'  # The column you'd like to evaluate\n",
    "condition = 'not'  # The condition to check ('equal', 'above', 'below')\n",
    "value = 'Wurzburg'  # The value to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_T_By_Origin_Group_</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Subiculum_Connectivity_T</th>\n",
       "      <th>Amnesia_Lesion_T_Map</th>\n",
       "      <th>...</th>\n",
       "      <th>Estimated_Outcome</th>\n",
       "      <th>Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline__Lower_is_Better_</th>\n",
       "      <th>Min_Max_Normalized_Baseline</th>\n",
       "      <th>MinMaxNormBaseline_Higher_is_Better</th>\n",
       "      <th>ROI_to_Alz_Max</th>\n",
       "      <th>ROI_to_PD_Max</th>\n",
       "      <th>Standardzied_AD_Max</th>\n",
       "      <th>Standardized_PD_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-2.609929</td>\n",
       "      <td>-1.372562</td>\n",
       "      <td>-1.372562</td>\n",
       "      <td>-5.673759</td>\n",
       "      <td>1.080695</td>\n",
       "      <td>1.080695</td>\n",
       "      <td>30.376565</td>\n",
       "      <td>-0.113151</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>22.020300</td>\n",
       "      <td>20.467840</td>\n",
       "      <td>1.056258</td>\n",
       "      <td>0.508516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>1.331414</td>\n",
       "      <td>1.331414</td>\n",
       "      <td>2.158273</td>\n",
       "      <td>-0.930548</td>\n",
       "      <td>-0.930548</td>\n",
       "      <td>16.295870</td>\n",
       "      <td>-0.502484</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>11.487188</td>\n",
       "      <td>4.942970</td>\n",
       "      <td>-0.759238</td>\n",
       "      <td>-1.629565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.638889</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>-1.388889</td>\n",
       "      <td>1.155469</td>\n",
       "      <td>1.155469</td>\n",
       "      <td>30.900051</td>\n",
       "      <td>-0.398033</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.013479</td>\n",
       "      <td>22.145924</td>\n",
       "      <td>1.227443</td>\n",
       "      <td>0.739621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.985714</td>\n",
       "      <td>-0.153533</td>\n",
       "      <td>-0.153533</td>\n",
       "      <td>-2.142857</td>\n",
       "      <td>-0.228971</td>\n",
       "      <td>-0.228971</td>\n",
       "      <td>21.207602</td>\n",
       "      <td>-0.426115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>-0.525235</td>\n",
       "      <td>-0.525235</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>12.198485</td>\n",
       "      <td>18.933435</td>\n",
       "      <td>-0.636638</td>\n",
       "      <td>0.297198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.323944</td>\n",
       "      <td>0.343149</td>\n",
       "      <td>0.343149</td>\n",
       "      <td>-0.704225</td>\n",
       "      <td>0.109572</td>\n",
       "      <td>0.109572</td>\n",
       "      <td>23.577739</td>\n",
       "      <td>-0.454075</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>0.294644</td>\n",
       "      <td>0.294644</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>17.634088</td>\n",
       "      <td>18.128314</td>\n",
       "      <td>0.300247</td>\n",
       "      <td>0.186317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-0.326241</td>\n",
       "      <td>0.341424</td>\n",
       "      <td>0.341424</td>\n",
       "      <td>-0.709220</td>\n",
       "      <td>1.977842</td>\n",
       "      <td>1.977842</td>\n",
       "      <td>36.657479</td>\n",
       "      <td>-0.177886</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>24.162033</td>\n",
       "      <td>27.503198</td>\n",
       "      <td>1.425409</td>\n",
       "      <td>1.477423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>9</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-0.985714</td>\n",
       "      <td>-0.153533</td>\n",
       "      <td>-0.153533</td>\n",
       "      <td>-2.142857</td>\n",
       "      <td>-0.407778</td>\n",
       "      <td>-0.407778</td>\n",
       "      <td>19.955774</td>\n",
       "      <td>-0.494405</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>-0.525235</td>\n",
       "      <td>-0.525235</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>10.782803</td>\n",
       "      <td>14.964053</td>\n",
       "      <td>-0.880646</td>\n",
       "      <td>-0.249464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>11</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.319444</td>\n",
       "      <td>0.346526</td>\n",
       "      <td>0.346526</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>-1.093332</td>\n",
       "      <td>-1.093332</td>\n",
       "      <td>15.156220</td>\n",
       "      <td>-0.507962</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.653427</td>\n",
       "      <td>12.002916</td>\n",
       "      <td>-1.075306</td>\n",
       "      <td>-0.657271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>12</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788134</td>\n",
       "      <td>0.788134</td>\n",
       "      <td>28.328345</td>\n",
       "      <td>-0.220427</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>-2.164991</td>\n",
       "      <td>-2.164991</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.521001</td>\n",
       "      <td>21.243697</td>\n",
       "      <td>0.970198</td>\n",
       "      <td>0.615367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>14</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>0.827710</td>\n",
       "      <td>0.827710</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>-0.455880</td>\n",
       "      <td>-0.455880</td>\n",
       "      <td>19.619016</td>\n",
       "      <td>-0.440579</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>10.881447</td>\n",
       "      <td>15.224677</td>\n",
       "      <td>-0.863644</td>\n",
       "      <td>-0.213571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-3.513889</td>\n",
       "      <td>-2.051014</td>\n",
       "      <td>-2.051014</td>\n",
       "      <td>-7.638889</td>\n",
       "      <td>2.357590</td>\n",
       "      <td>2.357590</td>\n",
       "      <td>39.316089</td>\n",
       "      <td>0.047449</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.430082</td>\n",
       "      <td>33.143996</td>\n",
       "      <td>1.299249</td>\n",
       "      <td>2.254272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>17</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.029012</td>\n",
       "      <td>1.029012</td>\n",
       "      <td>30.014730</td>\n",
       "      <td>-0.372396</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.655083</td>\n",
       "      <td>22.108570</td>\n",
       "      <td>1.338030</td>\n",
       "      <td>0.734477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>18</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.330935</td>\n",
       "      <td>0.834658</td>\n",
       "      <td>0.834658</td>\n",
       "      <td>0.719424</td>\n",
       "      <td>-1.003966</td>\n",
       "      <td>-1.003966</td>\n",
       "      <td>15.781874</td>\n",
       "      <td>-0.313833</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>10.294062</td>\n",
       "      <td>7.983811</td>\n",
       "      <td>-0.964886</td>\n",
       "      <td>-1.210781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>19</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-0.638889</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>-1.388889</td>\n",
       "      <td>0.045394</td>\n",
       "      <td>0.045394</td>\n",
       "      <td>23.128431</td>\n",
       "      <td>-0.345869</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>18.597962</td>\n",
       "      <td>19.229600</td>\n",
       "      <td>0.466381</td>\n",
       "      <td>0.337986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>21</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-4.535211</td>\n",
       "      <td>-2.817552</td>\n",
       "      <td>-2.817552</td>\n",
       "      <td>-9.859155</td>\n",
       "      <td>0.457907</td>\n",
       "      <td>0.457907</td>\n",
       "      <td>26.016428</td>\n",
       "      <td>-0.049282</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>0.294644</td>\n",
       "      <td>0.294644</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>19.765137</td>\n",
       "      <td>23.255821</td>\n",
       "      <td>0.667556</td>\n",
       "      <td>0.892476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>22</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.408153</td>\n",
       "      <td>-0.408153</td>\n",
       "      <td>19.953155</td>\n",
       "      <td>-0.496973</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>16.167584</td>\n",
       "      <td>17.567719</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.109112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>23</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-0.652482</td>\n",
       "      <td>0.096569</td>\n",
       "      <td>0.096569</td>\n",
       "      <td>-1.418440</td>\n",
       "      <td>-1.041401</td>\n",
       "      <td>-1.041401</td>\n",
       "      <td>15.519790</td>\n",
       "      <td>-0.520786</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>10.938624</td>\n",
       "      <td>5.561032</td>\n",
       "      <td>-0.853789</td>\n",
       "      <td>-1.544445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>26</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236757</td>\n",
       "      <td>0.236757</td>\n",
       "      <td>24.468157</td>\n",
       "      <td>-0.276809</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>-0.525235</td>\n",
       "      <td>-0.525235</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>18.644419</td>\n",
       "      <td>23.314943</td>\n",
       "      <td>0.474388</td>\n",
       "      <td>0.900618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>27</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-0.638889</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>-1.388889</td>\n",
       "      <td>-0.572833</td>\n",
       "      <td>-0.572833</td>\n",
       "      <td>18.800226</td>\n",
       "      <td>-0.489221</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14.809775</td>\n",
       "      <td>13.473033</td>\n",
       "      <td>-0.186554</td>\n",
       "      <td>-0.454807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>28</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.336814</td>\n",
       "      <td>1.336814</td>\n",
       "      <td>2.173913</td>\n",
       "      <td>1.355046</td>\n",
       "      <td>1.355046</td>\n",
       "      <td>32.297293</td>\n",
       "      <td>-0.413800</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>24.395433</td>\n",
       "      <td>24.956701</td>\n",
       "      <td>1.465638</td>\n",
       "      <td>1.126720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>29</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886242</td>\n",
       "      <td>0.886242</td>\n",
       "      <td>29.015201</td>\n",
       "      <td>-0.358253</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>-0.115295</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>21.855067</td>\n",
       "      <td>25.033790</td>\n",
       "      <td>1.027778</td>\n",
       "      <td>1.137337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-0.638889</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>-1.388889</td>\n",
       "      <td>-0.590767</td>\n",
       "      <td>-0.590767</td>\n",
       "      <td>18.674670</td>\n",
       "      <td>-0.553686</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>13.873339</td>\n",
       "      <td>15.685024</td>\n",
       "      <td>-0.347959</td>\n",
       "      <td>-0.150172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>31</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.086636</td>\n",
       "      <td>1.086636</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>-1.065220</td>\n",
       "      <td>-1.065220</td>\n",
       "      <td>15.353030</td>\n",
       "      <td>-0.505577</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10.930371</td>\n",
       "      <td>11.599140</td>\n",
       "      <td>-0.855211</td>\n",
       "      <td>-0.712879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>33</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.643357</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>-1.398601</td>\n",
       "      <td>-1.108473</td>\n",
       "      <td>-1.108473</td>\n",
       "      <td>15.050219</td>\n",
       "      <td>-0.659502</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>6.780175</td>\n",
       "      <td>8.774895</td>\n",
       "      <td>-1.570542</td>\n",
       "      <td>-1.101833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>36</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.286713</td>\n",
       "      <td>-0.379443</td>\n",
       "      <td>-0.379443</td>\n",
       "      <td>-2.797203</td>\n",
       "      <td>-0.775406</td>\n",
       "      <td>-0.775406</td>\n",
       "      <td>17.382020</td>\n",
       "      <td>-0.527690</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>9.841726</td>\n",
       "      <td>16.308768</td>\n",
       "      <td>-1.042851</td>\n",
       "      <td>-0.064270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-0.992806</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>-2.158273</td>\n",
       "      <td>-0.690244</td>\n",
       "      <td>-0.690244</td>\n",
       "      <td>17.978233</td>\n",
       "      <td>-0.243491</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>11.101963</td>\n",
       "      <td>10.543942</td>\n",
       "      <td>-0.825635</td>\n",
       "      <td>-0.858200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject   Age  Normalized_Percent_Cognitive_Improvement  \\\n",
       "46        1  57.0                                 -2.609929   \n",
       "47        2  50.0                                  0.992806   \n",
       "48        3  62.0                                 -0.638889   \n",
       "49        4  50.0                                 -0.985714   \n",
       "50        6  60.0                                 -0.323944   \n",
       "51        7  73.0                                 -0.326241   \n",
       "52        9  64.0                                 -0.985714   \n",
       "53       11  62.0                                 -0.319444   \n",
       "54       12  54.0                                  0.000000   \n",
       "55       14  49.0                                  0.321678   \n",
       "56       15  46.0                                 -3.513889   \n",
       "57       17  52.0                                  0.000000   \n",
       "58       18  46.0                                  0.330935   \n",
       "59       19  64.0                                 -0.638889   \n",
       "60       21  58.0                                 -4.535211   \n",
       "61       22  57.0                                  0.000000   \n",
       "62       23  68.0                                 -0.652482   \n",
       "64       26  79.0                                  0.000000   \n",
       "65       27  61.0                                 -0.638889   \n",
       "66       28  56.0                                  1.000000   \n",
       "67       29  47.0                                  0.000000   \n",
       "68       30  58.0                                 -0.638889   \n",
       "69       31  64.0                                  0.666667   \n",
       "70       33  60.0                                 -0.643357   \n",
       "72       36  52.0                                 -1.286713   \n",
       "73       37  64.0                                 -0.992806   \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group  \\\n",
       "46                                          -1.372562        \n",
       "47                                           1.331414        \n",
       "48                                           0.106772        \n",
       "49                                          -0.153533        \n",
       "50                                           0.343149        \n",
       "51                                           0.341424        \n",
       "52                                          -0.153533        \n",
       "53                                           0.346526        \n",
       "54                                           0.586280        \n",
       "55                                           0.827710        \n",
       "56                                          -2.051014        \n",
       "57                                           0.586280        \n",
       "58                                           0.834658        \n",
       "59                                           0.106772        \n",
       "60                                          -2.817552        \n",
       "61                                           0.586280        \n",
       "62                                           0.096569        \n",
       "64                                           0.586280        \n",
       "65                                           0.106772        \n",
       "66                                           1.336814        \n",
       "67                                           0.586280        \n",
       "68                                           0.106772        \n",
       "69                                           1.086636        \n",
       "70                                           0.103418        \n",
       "72                                          -0.379443        \n",
       "73                                          -0.158855        \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "46                               -1.372562                      -5.673759   \n",
       "47                                1.331414                       2.158273   \n",
       "48                                0.106772                      -1.388889   \n",
       "49                               -0.153533                      -2.142857   \n",
       "50                                0.343149                      -0.704225   \n",
       "51                                0.341424                      -0.709220   \n",
       "52                               -0.153533                      -2.142857   \n",
       "53                                0.346526                      -0.694444   \n",
       "54                                0.586280                       0.000000   \n",
       "55                                0.827710                       0.699301   \n",
       "56                               -2.051014                      -7.638889   \n",
       "57                                0.586280                       0.000000   \n",
       "58                                0.834658                       0.719424   \n",
       "59                                0.106772                      -1.388889   \n",
       "60                               -2.817552                      -9.859155   \n",
       "61                                0.586280                       0.000000   \n",
       "62                                0.096569                      -1.418440   \n",
       "64                                0.586280                       0.000000   \n",
       "65                                0.106772                      -1.388889   \n",
       "66                                1.336814                       2.173913   \n",
       "67                                0.586280                       0.000000   \n",
       "68                                0.106772                      -1.388889   \n",
       "69                                1.086636                       1.449275   \n",
       "70                                0.103418                      -1.398601   \n",
       "72                               -0.379443                      -2.797203   \n",
       "73                               -0.158855                      -2.158273   \n",
       "\n",
       "    Z_Scored_Subiculum_T_By_Origin_Group_  Z_Scored_Subiculum_Connectivity_T  \\\n",
       "46                               1.080695                           1.080695   \n",
       "47                              -0.930548                          -0.930548   \n",
       "48                               1.155469                           1.155469   \n",
       "49                              -0.228971                          -0.228971   \n",
       "50                               0.109572                           0.109572   \n",
       "51                               1.977842                           1.977842   \n",
       "52                              -0.407778                          -0.407778   \n",
       "53                              -1.093332                          -1.093332   \n",
       "54                               0.788134                           0.788134   \n",
       "55                              -0.455880                          -0.455880   \n",
       "56                               2.357590                           2.357590   \n",
       "57                               1.029012                           1.029012   \n",
       "58                              -1.003966                          -1.003966   \n",
       "59                               0.045394                           0.045394   \n",
       "60                               0.457907                           0.457907   \n",
       "61                              -0.408153                          -0.408153   \n",
       "62                              -1.041401                          -1.041401   \n",
       "64                               0.236757                           0.236757   \n",
       "65                              -0.572833                          -0.572833   \n",
       "66                               1.355046                           1.355046   \n",
       "67                               0.886242                           0.886242   \n",
       "68                              -0.590767                          -0.590767   \n",
       "69                              -1.065220                          -1.065220   \n",
       "70                              -1.108473                          -1.108473   \n",
       "72                              -0.775406                          -0.775406   \n",
       "73                              -0.690244                          -0.690244   \n",
       "\n",
       "    Subiculum_Connectivity_T  Amnesia_Lesion_T_Map  ...  Estimated_Outcome  \\\n",
       "46                 30.376565             -0.113151  ...                NaN   \n",
       "47                 16.295870             -0.502484  ...                NaN   \n",
       "48                 30.900051             -0.398033  ...                NaN   \n",
       "49                 21.207602             -0.426115  ...                NaN   \n",
       "50                 23.577739             -0.454075  ...                NaN   \n",
       "51                 36.657479             -0.177886  ...                NaN   \n",
       "52                 19.955774             -0.494405  ...                NaN   \n",
       "53                 15.156220             -0.507962  ...                NaN   \n",
       "54                 28.328345             -0.220427  ...                NaN   \n",
       "55                 19.619016             -0.440579  ...                NaN   \n",
       "56                 39.316089              0.047449  ...                NaN   \n",
       "57                 30.014730             -0.372396  ...                NaN   \n",
       "58                 15.781874             -0.313833  ...                NaN   \n",
       "59                 23.128431             -0.345869  ...                NaN   \n",
       "60                 26.016428             -0.049282  ...                NaN   \n",
       "61                 19.953155             -0.496973  ...                NaN   \n",
       "62                 15.519790             -0.520786  ...                NaN   \n",
       "64                 24.468157             -0.276809  ...                NaN   \n",
       "65                 18.800226             -0.489221  ...                NaN   \n",
       "66                 32.297293             -0.413800  ...                NaN   \n",
       "67                 29.015201             -0.358253  ...                NaN   \n",
       "68                 18.674670             -0.553686  ...                NaN   \n",
       "69                 15.353030             -0.505577  ...                NaN   \n",
       "70                 15.050219             -0.659502  ...                NaN   \n",
       "72                 17.382020             -0.527690  ...                NaN   \n",
       "73                 17.978233             -0.243491  ...                NaN   \n",
       "\n",
       "    Cognitive_Baseline  Z_Scored_Cognitive_Baseline  \\\n",
       "46                 141                    -0.115295   \n",
       "47                 139                    -0.935174   \n",
       "48                 144                     1.114522   \n",
       "49                 140                    -0.525235   \n",
       "50                 142                     0.294644   \n",
       "51                 141                    -0.115295   \n",
       "52                 140                    -0.525235   \n",
       "53                 144                     1.114522   \n",
       "54                 136                    -2.164991   \n",
       "55                 143                     0.704583   \n",
       "56                 144                     1.114522   \n",
       "57                 144                     1.114522   \n",
       "58                 139                    -0.935174   \n",
       "59                 144                     1.114522   \n",
       "60                 142                     0.294644   \n",
       "61                 143                     0.704583   \n",
       "62                 141                    -0.115295   \n",
       "64                 140                    -0.525235   \n",
       "65                 144                     1.114522   \n",
       "66                 138                    -1.345113   \n",
       "67                 141                    -0.115295   \n",
       "68                 144                     1.114522   \n",
       "69                 138                    -1.345113   \n",
       "70                 143                     0.704583   \n",
       "72                 143                     0.704583   \n",
       "73                 139                    -0.935174   \n",
       "\n",
       "    Z_Scored_Cognitive_Baseline__Lower_is_Better_  \\\n",
       "46                                      -0.115295   \n",
       "47                                      -0.935174   \n",
       "48                                       1.114522   \n",
       "49                                      -0.525235   \n",
       "50                                       0.294644   \n",
       "51                                      -0.115295   \n",
       "52                                      -0.525235   \n",
       "53                                       1.114522   \n",
       "54                                      -2.164991   \n",
       "55                                       0.704583   \n",
       "56                                       1.114522   \n",
       "57                                       1.114522   \n",
       "58                                      -0.935174   \n",
       "59                                       1.114522   \n",
       "60                                       0.294644   \n",
       "61                                       0.704583   \n",
       "62                                      -0.115295   \n",
       "64                                      -0.525235   \n",
       "65                                       1.114522   \n",
       "66                                      -1.345113   \n",
       "67                                      -0.115295   \n",
       "68                                       1.114522   \n",
       "69                                      -1.345113   \n",
       "70                                       0.704583   \n",
       "72                                       0.704583   \n",
       "73                                      -0.935174   \n",
       "\n",
       "    Min_Max_Normalized_Baseline  MinMaxNormBaseline_Higher_is_Better  \\\n",
       "46                        0.625                                0.625   \n",
       "47                        0.375                                0.375   \n",
       "48                        1.000                                1.000   \n",
       "49                        0.500                                0.500   \n",
       "50                        0.750                                0.750   \n",
       "51                        0.625                                0.625   \n",
       "52                        0.500                                0.500   \n",
       "53                        1.000                                1.000   \n",
       "54                        0.000                                0.000   \n",
       "55                        0.875                                0.875   \n",
       "56                        1.000                                1.000   \n",
       "57                        1.000                                1.000   \n",
       "58                        0.375                                0.375   \n",
       "59                        1.000                                1.000   \n",
       "60                        0.750                                0.750   \n",
       "61                        0.875                                0.875   \n",
       "62                        0.625                                0.625   \n",
       "64                        0.500                                0.500   \n",
       "65                        1.000                                1.000   \n",
       "66                        0.250                                0.250   \n",
       "67                        0.625                                0.625   \n",
       "68                        1.000                                1.000   \n",
       "69                        0.250                                0.250   \n",
       "70                        0.875                                0.875   \n",
       "72                        0.875                                0.875   \n",
       "73                        0.375                                0.375   \n",
       "\n",
       "    ROI_to_Alz_Max  ROI_to_PD_Max  Standardzied_AD_Max  Standardized_PD_Max  \n",
       "46       22.020300      20.467840             1.056258             0.508516  \n",
       "47       11.487188       4.942970            -0.759238            -1.629565  \n",
       "48       23.013479      22.145924             1.227443             0.739621  \n",
       "49       12.198485      18.933435            -0.636638             0.297198  \n",
       "50       17.634088      18.128314             0.300247             0.186317  \n",
       "51       24.162033      27.503198             1.425409             1.477423  \n",
       "52       10.782803      14.964053            -0.880646            -0.249464  \n",
       "53        9.653427      12.002916            -1.075306            -0.657271  \n",
       "54       21.521001      21.243697             0.970198             0.615367  \n",
       "55       10.881447      15.224677            -0.863644            -0.213571  \n",
       "56       23.430082      33.143996             1.299249             2.254272  \n",
       "57       23.655083      22.108570             1.338030             0.734477  \n",
       "58       10.294062       7.983811            -0.964886            -1.210781  \n",
       "59       18.597962      19.229600             0.466381             0.337986  \n",
       "60       19.765137      23.255821             0.667556             0.892476  \n",
       "61       16.167584      17.567719             0.047479             0.109112  \n",
       "62       10.938624       5.561032            -0.853789            -1.544445  \n",
       "64       18.644419      23.314943             0.474388             0.900618  \n",
       "65       14.809775      13.473033            -0.186554            -0.454807  \n",
       "66       24.395433      24.956701             1.465638             1.126720  \n",
       "67       21.855067      25.033790             1.027778             1.137337  \n",
       "68       13.873339      15.685024            -0.347959            -0.150172  \n",
       "69       10.930371      11.599140            -0.855211            -0.712879  \n",
       "70        6.780175       8.774895            -1.570542            -1.101833  \n",
       "72        9.841726      16.308768            -1.042851            -0.064270  \n",
       "73       11.101963      10.543942            -0.825635            -0.858200  \n",
       "\n",
       "[26 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity</th>\n",
       "      <th>Subiculum_Connectivity</th>\n",
       "      <th>Amnesia_Lesion_T_Map</th>\n",
       "      <th>Memory_Network_T</th>\n",
       "      <th>Z_Scored_Memory_Network_R</th>\n",
       "      <th>...</th>\n",
       "      <th>Standardized_Subiculum_Total</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>City</th>\n",
       "      <th>Inclusion_Cohort</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Age_And_Disease</th>\n",
       "      <th>Subiculum_Group</th>\n",
       "      <th>Age_Disease_and_Cohort</th>\n",
       "      <th>Subiculum_Group_By_Inflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.392857</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>56.864683</td>\n",
       "      <td>0.447264</td>\n",
       "      <td>0.494596</td>\n",
       "      <td>-1.895022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.789087</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>1</td>\n",
       "      <td>young</td>\n",
       "      <td>Alzheimer_young</td>\n",
       "      <td>low</td>\n",
       "      <td>Alzheimer_young_Toronto</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>52.970984</td>\n",
       "      <td>0.436157</td>\n",
       "      <td>0.502192</td>\n",
       "      <td>-1.909919</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.093456</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>1</td>\n",
       "      <td>old</td>\n",
       "      <td>Alzheimer_old</td>\n",
       "      <td>low</td>\n",
       "      <td>Alzheimer_old_Toronto</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.447368</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>62.459631</td>\n",
       "      <td>0.497749</td>\n",
       "      <td>0.581148</td>\n",
       "      <td>-0.803738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143505</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>1</td>\n",
       "      <td>old</td>\n",
       "      <td>Alzheimer_old</td>\n",
       "      <td>low</td>\n",
       "      <td>Alzheimer_old_Toronto</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-2.372549</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>59.611631</td>\n",
       "      <td>0.432617</td>\n",
       "      <td>0.520518</td>\n",
       "      <td>-1.401520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126248</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>1</td>\n",
       "      <td>old</td>\n",
       "      <td>Alzheimer_old</td>\n",
       "      <td>low</td>\n",
       "      <td>Alzheimer_old_Toronto</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.192982</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>57.928350</td>\n",
       "      <td>0.193389</td>\n",
       "      <td>0.491742</td>\n",
       "      <td>-1.401705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>1</td>\n",
       "      <td>young</td>\n",
       "      <td>Alzheimer_young</td>\n",
       "      <td>low</td>\n",
       "      <td>Alzheimer_young_Toronto</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>42</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parkinson</td>\n",
       "      <td>9</td>\n",
       "      <td>Boston</td>\n",
       "      <td>7</td>\n",
       "      <td>young</td>\n",
       "      <td>Parkinson_young</td>\n",
       "      <td>low</td>\n",
       "      <td>Parkinson_young_Boston</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>45</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parkinson</td>\n",
       "      <td>12</td>\n",
       "      <td>Boston</td>\n",
       "      <td>10</td>\n",
       "      <td>young</td>\n",
       "      <td>Parkinson_young</td>\n",
       "      <td>high</td>\n",
       "      <td>Parkinson_young_Boston</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>48</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parkinson</td>\n",
       "      <td>14</td>\n",
       "      <td>Boston</td>\n",
       "      <td>12</td>\n",
       "      <td>young</td>\n",
       "      <td>Parkinson_young</td>\n",
       "      <td>high</td>\n",
       "      <td>Parkinson_young_Boston</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>49</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.756000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parkinson</td>\n",
       "      <td>15</td>\n",
       "      <td>Boston</td>\n",
       "      <td>13</td>\n",
       "      <td>young</td>\n",
       "      <td>Parkinson_young</td>\n",
       "      <td>low</td>\n",
       "      <td>Parkinson_young_Boston</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>56</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parkinson</td>\n",
       "      <td>21</td>\n",
       "      <td>Boston</td>\n",
       "      <td>19</td>\n",
       "      <td>young</td>\n",
       "      <td>Parkinson_young</td>\n",
       "      <td>high</td>\n",
       "      <td>Parkinson_young_Boston</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject   Age  Normalized_Percent_Cognitive_Improvement  \\\n",
       "0        101  62.0                                 -0.392857   \n",
       "1        102  77.0                                 -0.666667   \n",
       "2        103  76.0                                 -1.447368   \n",
       "3        104  65.0                                 -2.372549   \n",
       "4        105  50.0                                 -0.192982   \n",
       "..       ...   ...                                       ...   \n",
       "93        42  63.0                                  0.000000   \n",
       "96        45  60.0                                  0.000000   \n",
       "98        48  73.0                                 -0.500000   \n",
       "99        49  68.0                                  0.000000   \n",
       "105       56  55.0                                  0.500000   \n",
       "\n",
       "     Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "0                                  0.314066                     -21.428571   \n",
       "1                                  0.013999                     -36.363636   \n",
       "2                                 -0.841572                     -78.947368   \n",
       "3                                 -1.855477                    -129.411765   \n",
       "4                                  0.533109                     -10.526316   \n",
       "..                                      ...                            ...   \n",
       "93                                 0.000000                            NaN   \n",
       "96                                 0.000000                            NaN   \n",
       "98                                 0.500000                            NaN   \n",
       "99                                 0.000000                            NaN   \n",
       "105                               -0.500000                            NaN   \n",
       "\n",
       "     Z_Scored_Subiculum_Connectivity  Subiculum_Connectivity  \\\n",
       "0                          -1.282630               56.864683   \n",
       "1                          -1.760917               52.970984   \n",
       "2                          -0.595369               62.459631   \n",
       "3                          -0.945206               59.611631   \n",
       "4                          -1.151973               57.928350   \n",
       "..                               ...                     ...   \n",
       "93                         -0.574000                     NaN   \n",
       "96                          0.190000                     NaN   \n",
       "98                          0.390000                     NaN   \n",
       "99                         -0.756000                     NaN   \n",
       "105                         2.080000                     NaN   \n",
       "\n",
       "     Amnesia_Lesion_T_Map  Memory_Network_T  Z_Scored_Memory_Network_R  ...  \\\n",
       "0                0.447264          0.494596                  -1.895022  ...   \n",
       "1                0.436157          0.502192                  -1.909919  ...   \n",
       "2                0.497749          0.581148                  -0.803738  ...   \n",
       "3                0.432617          0.520518                  -1.401520  ...   \n",
       "4                0.193389          0.491742                  -1.401705  ...   \n",
       "..                    ...               ...                        ...  ...   \n",
       "93                    NaN               NaN                        NaN  ...   \n",
       "96                    NaN               NaN                        NaN  ...   \n",
       "98                    NaN               NaN                        NaN  ...   \n",
       "99                    NaN               NaN                        NaN  ...   \n",
       "105                   NaN               NaN                        NaN  ...   \n",
       "\n",
       "     Standardized_Subiculum_Total    Disease  Cohort     City  \\\n",
       "0                        1.789087  Alzheimer       1  Toronto   \n",
       "1                       -1.093456  Alzheimer       1  Toronto   \n",
       "2                        0.143505  Alzheimer       1  Toronto   \n",
       "3                        0.126248  Alzheimer       1  Toronto   \n",
       "4                        0.144737  Alzheimer       1  Toronto   \n",
       "..                            ...        ...     ...      ...   \n",
       "93                            NaN  Parkinson       9   Boston   \n",
       "96                            NaN  Parkinson      12   Boston   \n",
       "98                            NaN  Parkinson      14   Boston   \n",
       "99                            NaN  Parkinson      15   Boston   \n",
       "105                           NaN  Parkinson      21   Boston   \n",
       "\n",
       "     Inclusion_Cohort  Age_Group  Age_And_Disease  Subiculum_Group  \\\n",
       "0                   1      young  Alzheimer_young              low   \n",
       "1                   1        old    Alzheimer_old              low   \n",
       "2                   1        old    Alzheimer_old              low   \n",
       "3                   1        old    Alzheimer_old              low   \n",
       "4                   1      young  Alzheimer_young              low   \n",
       "..                ...        ...              ...              ...   \n",
       "93                  7      young  Parkinson_young              low   \n",
       "96                 10      young  Parkinson_young             high   \n",
       "98                 12      young  Parkinson_young             high   \n",
       "99                 13      young  Parkinson_young              low   \n",
       "105                19      young  Parkinson_young             high   \n",
       "\n",
       "      Age_Disease_and_Cohort  Subiculum_Group_By_Inflection  \n",
       "0    Alzheimer_young_Toronto                            Low  \n",
       "1      Alzheimer_old_Toronto                            Low  \n",
       "2      Alzheimer_old_Toronto                            Low  \n",
       "3      Alzheimer_old_Toronto                            Low  \n",
       "4    Alzheimer_young_Toronto                            Low  \n",
       "..                       ...                            ...  \n",
       "93    Parkinson_young_Boston                            Low  \n",
       "96    Parkinson_young_Boston                           High  \n",
       "98    Parkinson_young_Boston                           High  \n",
       "99    Parkinson_young_Boston                            Low  \n",
       "105   Parkinson_young_Boston                           High  \n",
       "\n",
       "[82 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity</th>\n",
       "      <th>Subiculum_Connectivity</th>\n",
       "      <th>Amnesia_Lesion_T_Map</th>\n",
       "      <th>Memory_Network_T</th>\n",
       "      <th>Z_Scored_Memory_Network_R</th>\n",
       "      <th>...</th>\n",
       "      <th>Subiculum_Total</th>\n",
       "      <th>Standardized_Age</th>\n",
       "      <th>Standardized_Percent_Improvement</th>\n",
       "      <th>Standardized_Subiculum_Connectivity</th>\n",
       "      <th>Standardized_Subiculum_Grey_Matter</th>\n",
       "      <th>Standardized_Subiculum_White_Matter</th>\n",
       "      <th>Standardized_Subiculum_CSF</th>\n",
       "      <th>Standardized_Subiculum_Total</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Inclusion_Cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.487805</td>\n",
       "      <td>63.743902</td>\n",
       "      <td>-0.587478</td>\n",
       "      <td>0.041711</td>\n",
       "      <td>-24.173205</td>\n",
       "      <td>0.051460</td>\n",
       "      <td>51.346147</td>\n",
       "      <td>0.153713</td>\n",
       "      <td>0.396094</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663074</td>\n",
       "      <td>-0.023211</td>\n",
       "      <td>-0.023211</td>\n",
       "      <td>0.035987</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>-0.030977</td>\n",
       "      <td>-0.030128</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>2.426829</td>\n",
       "      <td>1.865854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52.303304</td>\n",
       "      <td>8.788054</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.917012</td>\n",
       "      <td>43.251602</td>\n",
       "      <td>0.980973</td>\n",
       "      <td>22.727710</td>\n",
       "      <td>0.420577</td>\n",
       "      <td>0.322126</td>\n",
       "      <td>0.997213</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184669</td>\n",
       "      <td>1.017104</td>\n",
       "      <td>1.017104</td>\n",
       "      <td>0.972990</td>\n",
       "      <td>1.015150</td>\n",
       "      <td>0.988083</td>\n",
       "      <td>1.021720</td>\n",
       "      <td>0.982599</td>\n",
       "      <td>3.413953</td>\n",
       "      <td>2.938725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>-4.535211</td>\n",
       "      <td>-3.428250</td>\n",
       "      <td>-207.692308</td>\n",
       "      <td>-2.576474</td>\n",
       "      <td>15.050219</td>\n",
       "      <td>-0.659502</td>\n",
       "      <td>-0.363412</td>\n",
       "      <td>-2.427112</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.144075</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-2.412986</td>\n",
       "      <td>-3.303201</td>\n",
       "      <td>-1.732774</td>\n",
       "      <td>-3.303201</td>\n",
       "      <td>-1.685742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.250000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>-0.960550</td>\n",
       "      <td>-0.170116</td>\n",
       "      <td>-37.740385</td>\n",
       "      <td>-0.655969</td>\n",
       "      <td>27.750366</td>\n",
       "      <td>-0.321842</td>\n",
       "      <td>0.070122</td>\n",
       "      <td>-0.570234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829154</td>\n",
       "      <td>-0.361983</td>\n",
       "      <td>-0.361983</td>\n",
       "      <td>-0.674219</td>\n",
       "      <td>-0.644489</td>\n",
       "      <td>-0.728695</td>\n",
       "      <td>-0.579606</td>\n",
       "      <td>-0.683601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>105.500000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>-0.387401</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>-5.217832</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>60.995631</td>\n",
       "      <td>0.434387</td>\n",
       "      <td>0.556495</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035137</td>\n",
       "      <td>0.117964</td>\n",
       "      <td>0.117964</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.182301</td>\n",
       "      <td>-0.079546</td>\n",
       "      <td>-0.235042</td>\n",
       "      <td>0.055132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.750000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734739</td>\n",
       "      <td>69.813800</td>\n",
       "      <td>0.496529</td>\n",
       "      <td>0.652797</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>...</td>\n",
       "      <td>1.445829</td>\n",
       "      <td>0.618322</td>\n",
       "      <td>0.618322</td>\n",
       "      <td>0.723344</td>\n",
       "      <td>0.624959</td>\n",
       "      <td>0.514574</td>\n",
       "      <td>0.627145</td>\n",
       "      <td>0.494347</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.840498</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>2.357590</td>\n",
       "      <td>85.082502</td>\n",
       "      <td>0.569043</td>\n",
       "      <td>0.714419</td>\n",
       "      <td>2.442475</td>\n",
       "      <td>...</td>\n",
       "      <td>8.959061</td>\n",
       "      <td>1.844523</td>\n",
       "      <td>1.844523</td>\n",
       "      <td>2.297968</td>\n",
       "      <td>3.222209</td>\n",
       "      <td>2.909124</td>\n",
       "      <td>2.644521</td>\n",
       "      <td>2.775495</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject        Age  Normalized_Percent_Cognitive_Improvement  \\\n",
       "count   82.000000  82.000000                                 82.000000   \n",
       "mean    81.487805  63.743902                                 -0.587478   \n",
       "std     52.303304   8.788054                                  0.999348   \n",
       "min      1.000000  46.000000                                 -4.535211   \n",
       "25%     29.250000  58.000000                                 -0.960550   \n",
       "50%    105.500000  64.000000                                 -0.387401   \n",
       "75%    127.750000  72.000000                                  0.000000   \n",
       "max    150.000000  79.000000                                  1.000000   \n",
       "\n",
       "       Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "count                               82.000000                      72.000000   \n",
       "mean                                 0.041711                     -24.173205   \n",
       "std                                  0.917012                      43.251602   \n",
       "min                                 -3.428250                    -207.692308   \n",
       "25%                                 -0.170116                     -37.740385   \n",
       "50%                                  0.106772                      -5.217832   \n",
       "75%                                  0.586280                       0.000000   \n",
       "max                                  1.840498                      54.545455   \n",
       "\n",
       "       Z_Scored_Subiculum_Connectivity  Subiculum_Connectivity  \\\n",
       "count                        82.000000               72.000000   \n",
       "mean                          0.051460               51.346147   \n",
       "std                           0.980973               22.727710   \n",
       "min                          -2.576474               15.050219   \n",
       "25%                          -0.655969               27.750366   \n",
       "50%                           0.012710               60.995631   \n",
       "75%                           0.734739               69.813800   \n",
       "max                           2.357590               85.082502   \n",
       "\n",
       "       Amnesia_Lesion_T_Map  Memory_Network_T  Z_Scored_Memory_Network_R  ...  \\\n",
       "count             72.000000         72.000000                  72.000000  ...   \n",
       "mean               0.153713          0.396094                   0.018028  ...   \n",
       "std                0.420577          0.322126                   0.997213  ...   \n",
       "min               -0.659502         -0.363412                  -2.427112  ...   \n",
       "25%               -0.321842          0.070122                  -0.570234  ...   \n",
       "50%                0.434387          0.556495                   0.038842  ...   \n",
       "75%                0.496529          0.652797                   0.711785  ...   \n",
       "max                0.569043          0.714419                   2.442475  ...   \n",
       "\n",
       "       Subiculum_Total  Standardized_Age  Standardized_Percent_Improvement  \\\n",
       "count        70.000000         70.000000                         70.000000   \n",
       "mean          0.663074         -0.023211                         -0.023211   \n",
       "std           2.184669          1.017104                          1.017104   \n",
       "min          -2.144075         -3.523461                         -3.523461   \n",
       "25%          -0.829154         -0.361983                         -0.361983   \n",
       "50%          -0.035137          0.117964                          0.117964   \n",
       "75%           1.445829          0.618322                          0.618322   \n",
       "max           8.959061          1.844523                          1.844523   \n",
       "\n",
       "       Standardized_Subiculum_Connectivity  \\\n",
       "count                            70.000000   \n",
       "mean                              0.035987   \n",
       "std                               0.972990   \n",
       "min                              -2.412986   \n",
       "25%                              -0.674219   \n",
       "50%                               0.002146   \n",
       "75%                               0.723344   \n",
       "max                               2.297968   \n",
       "\n",
       "       Standardized_Subiculum_Grey_Matter  \\\n",
       "count                           70.000000   \n",
       "mean                             0.032359   \n",
       "std                              1.015150   \n",
       "min                             -3.303201   \n",
       "25%                             -0.644489   \n",
       "50%                              0.182301   \n",
       "75%                              0.624959   \n",
       "max                              3.222209   \n",
       "\n",
       "       Standardized_Subiculum_White_Matter  Standardized_Subiculum_CSF  \\\n",
       "count                            70.000000                   70.000000   \n",
       "mean                             -0.030977                   -0.030128   \n",
       "std                               0.988083                    1.021720   \n",
       "min                              -1.732774                   -3.303201   \n",
       "25%                              -0.728695                   -0.579606   \n",
       "50%                              -0.079546                   -0.235042   \n",
       "75%                               0.514574                    0.627145   \n",
       "max                               2.909124                    2.644521   \n",
       "\n",
       "       Standardized_Subiculum_Total     Cohort  Inclusion_Cohort  \n",
       "count                     70.000000  82.000000         82.000000  \n",
       "mean                       0.037356   2.426829          1.865854  \n",
       "std                        0.982599   3.413953          2.938725  \n",
       "min                       -1.685742   1.000000          1.000000  \n",
       "25%                       -0.683601   1.000000          1.000000  \n",
       "50%                        0.055132   1.000000          1.000000  \n",
       "75%                        0.494347   2.000000          1.000000  \n",
       "max                        2.775495  21.000000         19.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Identification of a Saddle Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Partial Derivative Explanation for the Equation $ y = B_1x + B_2z + B_3xz $\n",
    "\n",
    "When taking the partial derivative of the equation $ y = B_1x + B_2z + B_3xz $ with respect to $ x $, the logic is as follows:\n",
    "\n",
    "- Treat $ z $ as a constant since we are differentiating with respect to $ x $. \n",
    "- Derivatives of constants are zero. Derivatives of first-order polynomials ($ x $) are one. \n",
    "- All terms with $ z $ are treated as constants.\n",
    "    - This means both $ B_2z $ and $ B_3z $ are considered constants.\n",
    "    - When differentiated with respect to $ x $:\n",
    "        - $ B_2z $ does not have $ x $. Thus its derivative is zero.\n",
    "        - $ B_3z $ has an $ x $ term in $ B_3zx $, thus its derivative is the constant $ B_3z $. \n",
    "            - This is due to the special situation of the product rule wherein the derivative of a constant and a differentiable variable is = constant * derivative of differentiable variable.\n",
    "\n",
    "Hence, the partial derivative of $ y $ with respect to $ x $ is given by:\n",
    "\n",
    "$$ {\\partial y}/{\\partial x} = {\\partial y}/{\\partial x}(B_1x) + {\\partial y}/{\\partial x}(B_2z) + {\\partial y}/{\\partial x}(B_3xz) $$\n",
    "\n",
    "The product rule is applied to the interaction term, which expanding provides:\n",
    "\n",
    "$$ {\\partial y}/{\\partial x} = {\\partial y}/{\\partial x}(B_1x) + {\\partial y}/{\\partial x}(B_2z) + {\\partial y}/{\\partial x}(B_3x) * {\\partial y}/{\\partial x}(B_3z) $$\n",
    "\n",
    "Which applying the product rule, is equivalent to:\n",
    "\n",
    "$$ {\\partial y}/{\\partial x} = {\\partial y}/{\\partial x}(B_1x) + {\\partial y}/{\\partial x}(B_2z) + 1 * {\\partial y}/{\\partial x}(B_3z) $$\n",
    "\n",
    "The derivative of a constant (z) is equivalent to zero. Thus, simplifying this, we get:\n",
    "\n",
    "$$ {\\partial y}{\\partial x} = B_1 + 0 + B_3z $$\n",
    "\n",
    "Therefore, the resulting equation for the partial derivative is:\n",
    "\n",
    "$$ {\\partial y}{\\partial x} = B_1 + B_3z $$\n",
    "\n",
    "This equation represents the rate of change of $ y $ with respect to $ x $, while holding $ z $ constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mcoefficients\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split & Visualize Data By Saddle Point\n",
    "\n",
    "This code is designed to create an interaction plot to visualize the effects of two factors and their interaction on the outcome variable.\n",
    "\n",
    "The interaction_plot function takes as input a dataframe, two factors (x_one and x_two), two corresponding labels for the conditions when the values of these factors are under the mean (x_one_under_mean and x_two_under_mean) and over the mean (x_one_over_mean and x_two_over_mean), and the response variable (outcome). If binarize is set to True, it converts the two factors into binary variables based on whether their values are above or below the mean. The function then creates a mapping for the x_two variable to numerical values for the purpose of plotting.\n",
    "\n",
    "It uses the interaction_plot function from the statsmodels package to create the plot. In the plot, x_two is represented on the x-axis, x_one is used to color the lines, and the outcome variable is plotted on the y-axis. The function also sets the labels for the x and y axes and the tick labels on the x-axis according to the inputs provided.\n",
    "\n",
    "The function also allows for saving the plot to an output directory specified by the user. If save is set to True, it saves the plot in both PNG and SVG formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/final/supplementary_parkinson/2D_interaction_figure.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/calvin_utils/calvin_utils/statistical_utils/calculus_utils.py:82: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"-o\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  ax.errorbar(x_vals, y_vals, yerr=y_errs, color=color, fmt='-o', capsize=5, capthick=2, elinewidth=2, label=group, linestyle='-')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from calvin_utils.statistical_utils.calculus_utils import saddle_binarization\n",
    "# Running the function to display the interaction plot\n",
    "save = False\n",
    "#----------------------------------------------------------------\n",
    "interaction_figure = saddle_binarization(data_df.copy(), \n",
    "                 x_one='Age', x_one_under_mean='Young', x_one_over_mean='Old', x_one_split_point=65,\n",
    "                 x_two='Z_Scored_Subiculum_Connectivity', x_two_under_mean='Low Connectivity', x_two_over_mean='High Connectivity', x_two_split_point=-0.1,\n",
    "                 response='Z_Scored_Percent_Cognitive_Improvement', \n",
    "                 x_label='Subiculum Connectivity', \n",
    "                 y_label='Average Cognitive Improvement (Standardized)',\n",
    "                 plot_error_bars=False,\n",
    "                 save=True, out_dir=out_dir)\n",
    "\n",
    "interaction_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
