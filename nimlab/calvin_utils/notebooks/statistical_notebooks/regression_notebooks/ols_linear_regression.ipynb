{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will take your regression or classification problem, the y variables (dependent) and x variables (independent) and determine which have what level of contribution to your dataset.\n",
    "## This will allow you to visualize the information context of Xn to Y, and decide what to keep in future analyses, such as development of lienar regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import glob as glob\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Calculate Correlation\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = 'ols_linear_regression/regression'\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    conn_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/final_analyses/interaction_analysis/spcorrel_interaction_effect/ferguson_memory_derivatives_with_clinical_data.csv'\n",
    "    clin_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/vta_published_t_connectivity'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = os.path.join(conn_path.split('.')[0], f'{analysis}')\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/analyses/roi-roi_correl/addbs_vta_to_memory_net_maxima/matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    \n",
    "    print('I have set pathnames in the Mac style')\n",
    "    print('I will save to :', out_dir)\n",
    "else: #----------------------------------------------------------------Windows----------------------------------------------------------------\n",
    "    conn_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_AvgR.csv'\n",
    "    clin_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\patient_data\\AD_Clinical_Data_CDR_ADAS_COG_13.xlsx'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\AD_to_memory_net'\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    print('I have set pathnames in the Windows style')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pre-prepared Regression Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_change = {}\n",
    "variables_to_change['original'] = [\n",
    "    '% Change from baseline (ADAS-Cog11)'\n",
    "  \n",
    "    ]\n",
    "variables_to_change['destination'] = [\n",
    "    'percent_change_adascog11'\n",
    "    \n",
    "    ]\n",
    "#----------------------------------------------------------------user input above----------------------------------------------------------------\n",
    "data_df = pd.read_csv(conn_path)\n",
    "try:\n",
    "    change_string = ''\n",
    "    for i in range (0, len(variables_to_change['original'])):\n",
    "        change_string += f\"variables_to_change['original'][{i}]: variables_to_change['destination'][{i}],\"\n",
    "    change_string = 'data_df.rename(columns={' + change_string[0:-1] + '})'\n",
    "    data_df = eval(change_string)\n",
    "except:\n",
    "    print('no change necessary')\n",
    "\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "#Select specific subgroup\n",
    "# outlier_index = (data_df['percent_change_adascog11'] <= -50)\n",
    "# data_df = data_df.loc[outlier_index, :]\n",
    "\n",
    "# Remove outlier\n",
    "outlier_index=[11, 47, 48, 49]\n",
    "data_df = data_df.drop(index=outlier_index)\n",
    "data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "try:    \n",
    "    data_df.pop('Unnamed: 0')\n",
    "    data_df.pop('Patient # CDR, ADAS')\n",
    "    # data_df.pop('Age at DOS')\n",
    "    data_df.pop('Randomization Arm')\n",
    "    data_df.pop('Baseline ADAS-Cog11')\n",
    "    data_df.pop('Baseline CDR (sum of squares)')\n",
    "    data_df.pop('% Change from baseline (CDR)')\n",
    "    data_df.dropna(inplace=True)\n",
    "    data_df.reset_index(drop=True, inplace=True)\n",
    "except:\n",
    "    print('none to pop')\n",
    "    \n",
    "#Standardize the data\n",
    "preserved_df = data_df.copy()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "# data_df = data_df.apply(scaler.fit_transform(), axis=0)\n",
    "data_df[data_df.columns] = scaler.fit_transform(data_df[data_df.columns])\n",
    "\n",
    "\n",
    "# #move outcomes to start\n",
    "try:\n",
    "    first_column = data_df.pop('percent_change_adascog11')  # Remove column and store it in a variable\n",
    "    data_df.insert(0, 'percent_change_adascog11', first_column)  # Insert column at the first position\n",
    "except:\n",
    "    print('Could not move outcomes to start')\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check multicollinearity\n",
    "mc_test = data_df.copy()\n",
    "mc_test.pop('percent_change_adascog11')\n",
    "\n",
    "from calvin_utils.statistical_measurements import calculate_vif\n",
    "calculate_vif(mc_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Statsmodel Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function attempt\n",
    "from calvin_utils.custom_regressions import basic_trivariate_regression, generalizable_multivariate_regression\n",
    "# results = basic_trivariate_regression(x=col2, y=col3, z=ycolumn_of_interest, conjoined_df=merged_dataframe)\n",
    "# data_df.pop('RMap')\n",
    "\n",
    "#Select all regressors\n",
    "all_indeps = data_df.columns.tolist()[-1:]\n",
    "#Select specific regressors\n",
    "# all_indeps = np.array(all_indeps)[[-1]]\n",
    "# all_indeps = ['pca_component_0']#, 'Ventral_Attention', 'Visual', 'Dorsal_Attention', 'Limbic', 'Default']#, 'SBC'] #,Thal_Ant_Med_L 'PFC_Mid_Vent'] #,'', #'Front_Sup_L'] #, 'SBC'] #, 'Cereb_IX_R', 'Occ_med_L', 'Par_Lat_L', 'SBC_L', 'Sbc_Retrospl_L', 'Temp_Lat_R']\n",
    "\n",
    "#Select outcome variable \n",
    "dep_var = 'percent_change_adascog11'\n",
    "\n",
    "# if isinstance(all_indeps[0], tuple):\n",
    "#     print('Found tuple, correcting')\n",
    "#     new_indeps = []\n",
    "#     for indep in all_indeps:\n",
    "#         new_indeps.append(indep[0])\n",
    "#     data_df = data_df.set_axis([['percent_change_adascog11'] + new_indeps], axis=1, inplace=False)\n",
    "#     all_indeps = data_df.columns.tolist()[1:]\n",
    "#     results = generalizable_multivariate_regression(data_df, 'percent_change_adascog11', all_indeps)\n",
    "# else:\n",
    "results, formula = generalizable_multivariate_regression(data_df, f'{dep_var}', all_indeps)\n",
    "print(results.summary2())\n",
    "print(results.mse_model, results.mse_total, results.mse_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.makedirs(out_dir)\n",
    "    try:\n",
    "        with open(os.path.join(out_dir, f'summary_{formula}.txt'), 'w') as f:\n",
    "            f.write(results.summary().as_text())\n",
    "    except:\n",
    "        with open(os.path.join(out_dir, f'summary_full_formula.txt'), 'w') as f:\n",
    "            f.write(results.summary().as_text())\n",
    "        print('saved as full formula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Pearson R for the model\n",
    "correlation_selections = ['pearsonr', 'spearmanr']\n",
    "correlation = 'pearsonr'\n",
    "\n",
    "##--------------------------------USER INPUT--------------------------------\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "#receive predictions from model\n",
    "predictions = results.predict(data_df.dropna(inplace=True))\n",
    "\n",
    "#Perform correlation\n",
    "if correlation == 'spearmanr':\n",
    "    r, p = spearmanr(data_df['percent_change_adascog11'], predictions)\n",
    "elif correlation == 'pearsonr':\n",
    "    r, p = pearsonr(data_df['percent_change_adascog11'], predictions)\n",
    "else:\n",
    "    print('Could not perform correlation, please retry')\n",
    "    \n",
    "#Put predictions in DF\n",
    "pearson_df = pd.DataFrame({'R': r, 'P': p}, index=[0])\n",
    "display(pearson_df)\n",
    "\n",
    "#Save predicitons\n",
    "save=False\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) != True:\n",
    "        os.makedirs(out_dir)\n",
    "    try:\n",
    "        pearson_df.to_csv(out_dir + f'{correlation}_results{formula}.csv')\n",
    "    except:\n",
    "        pearson_df.to_csv(out_dir + f'{correlation}_results_full_formula.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get residual diagnostics\n",
    "from calvin_utils.statistical_measurements import model_diagnostics\n",
    "fig = model_diagnostics(results)\n",
    "fig.savefig(os.path.join(out_dir, f'multivariate_regression.png'))\n",
    "fig.savefig(os.path.join(out_dir, f'multivariate_regression.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize\n",
    "#Partial Regression Grid\n",
    "from statsmodels.graphics.regressionplots import plot_partregress_grid\n",
    "sns.set_style('white')\n",
    "sns.set_palette('Greys', 1, desat=1)\n",
    "fig = plt.figure(figsize=(40, 80))\n",
    "plot_partregress_grid(results, fig=fig)\n",
    "\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "    try:\n",
    "        fig.savefig(os.path.join(out_dir, f'partial_regression_grid{formula}.png'))\n",
    "        fig.savefig(os.path.join(out_dir, f'partial_regression_grid{formula}.svg'))\n",
    "    except:\n",
    "        fig.savefig(os.path.join(out_dir, f'partial_regression_grid_full_formula.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Coefficient Partial Regression Plot\n",
    "from statsmodels.graphics.regressionplots import plot_partregress\n",
    "##--Exog_others set to all co-regressors to generate plot when all held stable--##\n",
    "# fig = plot_partregress(endog='percent_change_adascog11', exog_i='SBC',\n",
    "#                         exog_others=all_indeps[0:6],\n",
    "#                         data=data_df, obs_labels=False)\n",
    "\n",
    "#---Change exog_others to set the independent variables to account for\n",
    "# fig = plot_partregress(endog='percent_change_adascog11', exog_i='memory_roi',\n",
    "#                         exog_others=['conjunction_rios_r_to_ferguson_t_95th_percentile_stdevthresh_0_voxthresh_10_absval_True_cluster_6'],\n",
    "#                         data=data_df, obs_labels=False)\n",
    "\n",
    "# plt.xlabel('Residual')\n",
    "# plt.ylabel('Percent Change ADAS-Cog 11')\n",
    "# plt.title('')\n",
    "\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    fig.savefig(os.path.join(out_dir, 'memory_roi.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_ccpr\n",
    "sns.set_style('white')\n",
    "# sns.set_palette('blue')\n",
    "\n",
    "# ax = plot_ccpr(results, 'SBC')\n",
    "# plt.xlabel('Independent Variable by Order')\n",
    "# plt.ylabel('Error (Residual + BX)')\n",
    "# plt.title('')\n",
    "\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    # ax.savefig(os.path.join(out_dir, f'ccpr_plot_{formula}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-----------Generate Residual Plot---------------------------------------------\n",
    "#Make Predictions\n",
    "sns.set_style('white')\n",
    "plt.figure(figsize=(10,10))\n",
    "colors = ['#696969', '#BAB1B0', '#D3D3D3', '#D8D6D5']\n",
    "customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "predictions = results.fittedvalues\n",
    "r, p = pearson_df['R'][0], pearson_df['P'][0]\n",
    "\n",
    "# plt.axes(aspect='equal')\n",
    "sns.residplot(x=preserved_df.iloc[:,0], y=results.resid, lowess=True)\n",
    "plt.title(f'r = {r:.2f}, p = {p:.5f}')\n",
    "plt.xlabel('Actual % Improvement ADAS-Cog 11')\n",
    "plt.ylabel('Model Residual (Standard Deviations)')\n",
    "\n",
    "if save:\n",
    "    try:\n",
    "        plt.savefig(os.path.join(out_dir, f'residplot_{formula}.png'))\n",
    "    except:\n",
    "        plt.savefig(os.path.join(out_dir, f'summary_full_formula.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a New Dataframe from Specified Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = data_df.copy()\n",
    "# columns_to_extract = ['percent_change_adascog11', 'Ventral_Attention', 'Frontoparietal']\n",
    "new_df = new_df.iloc[:, 0:]\n",
    "new_df.head(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform K Folds with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.cross_validation import k_folds\n",
    "\n",
    "#Write the function to be passed to the LOO analysis\n",
    "k=5\n",
    "try:\n",
    "    data_df.dropna(inplace=True)\n",
    "    # data_df.reset_index(inplace=True, drop=True)\n",
    "except:\n",
    "    print('Cannot operate on DF')\n",
    "function = 'generalizable_multivariate_regression(train_df, \"percent_change_adascog11\", train_df.columns.tolist()[1:])'\n",
    "\n",
    "results_df = k_folds(data_df=new_df,train_function=function, k=k)\n",
    "display(results_df)\n",
    "\n",
    "# results_df.to_csv(os.path.join(out_dir, f'{k}_folds_analysis_{formula}.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform leave-one-out analysis with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.cross_validation import leave_one_out\n",
    "#Write the function to be passed to the LOO analysis\n",
    "function = 'generalizable_multivariate_regression(iterating_df, \"percent_change_adascog11\", iterating_df.columns.tolist()[1:])'\n",
    "\n",
    "#Pass the variables to the LOO analysis, with specific outcomes to extract as a list. \n",
    "loo_results = leave_one_out(data_df=new_df, outcome_var='percent_change_adascog11', function=function, leave_out_variable='index')\n",
    "display(loo_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loo_df = pd.DataFrame(loo_results)\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "#Calculate pearson predicted vs actual metrics\n",
    "loo_results.dropna(inplace=True)\n",
    "loo_results['loocv_pearson_r'], loo_results['loocv_pearson_p'] = spearmanr(loo_results['predictions'], loo_results['actuals'], alternative='greater')\n",
    "loo_results['loocv_r_squared'] = np.square(loo_results['loocv_pearson_r'])\n",
    "_, loo_results['loocv_pearson_p_greater'] = spearmanr(loo_results['predictions'], loo_results['actuals'], alternative='greater')\n",
    "_, loo_results['loocv_pearson_p_lesser'] = spearmanr(loo_results['predictions'], loo_results['actuals'], alternative='less')\n",
    "_, loo_results['loocv_pearson_p_two-sided'] = spearmanr(loo_results['predictions'], loo_results['actuals'], alternative='two-sided')\n",
    "\n",
    "\n",
    "#Calculate MSE predicted vs actual metrics\n",
    "loo_results['loocv_mse'] = (np.sum(np.square((loo_results['actuals']-loo_results['predictions'])))) / len(loo_results['actuals'])\n",
    "loo_results['loocv_rmse'] = np.sqrt(loo_results['loocv_mse'])\n",
    "\n",
    "#Calculate Mean Absolute Error\n",
    "loo_results['mean_absolute_error'] = np.sum(np.absolute(loo_results['predictions']-loo_results['actuals']))/len(loo_results['predictions'])\n",
    "\n",
    "# x = data_df['percent_change_adascog11'].values.tolist()\n",
    "# display(loo_results['predictions'][1][0])\n",
    "display(loo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) != True:\n",
    "        os.makedirs(out_dir)\n",
    "        print('Made directory')\n",
    "    try:\n",
    "        loo_results.to_csv(os.path.join(out_dir, f'ols_leave_one_out_{formula}.csv'))\n",
    "    except:\n",
    "        loo_results.to_csv(os.path.join(out_dir, f'ols_leave_one_out_full_formula.csv'))\n",
    "\n",
    "\n",
    "print('Saved to: ' + out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Permutation Analysis of the Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.import_matrices import import_matrices_from_folder\n",
    "\n",
    "#This code is expecting a dataframe with patients in rows, outcomes in a column, and voxels in all other columns. \n",
    "#The voxel column titles at this point must be strings\n",
    "\n",
    "# Load the flattened dataframe\n",
    "# df = import_matrices_from_folder(clin_path, file_pattern='/*.nii')\n",
    "df = pd.read_csv('/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/response_topology/voxelwise_glm/age_interaction_rios_vtas/t_values_topology/matrix_to_test.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achieve Voxels to Regress Upon \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Load the csv with voxel coordinates in it\n",
    "coordinate_df = pd.read_csv(r'/Users/cu135/Dropbox (Partners HealthCare)/memory/final_analyses/maxima_and_minima_rois/ferguson_maxima_coordinates.csv')\n",
    "\n",
    "#Convert coordinates to flattened coordinates\n",
    "import nibabel as nib\n",
    "from nimlab import datasets as nimds\n",
    "from calvin_utils.matrix_utilities import convert_coordinate_to_index, convert_voxel_index_to_flattened_index\n",
    "\n",
    "#Achieve relevant brain mask\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_affine = mni_mask.affine\n",
    "mask_shape = mni_mask.shape\n",
    "\n",
    "# Convert MNI coordinates to voxel space coordinates (i, j, k)\n",
    "coordinate_df['voxel_coords'] = coordinate_df.apply(lambda row: convert_coordinate_to_index((row['x'], row['y'], row['z']), mask_affine), axis=1)\n",
    "\n",
    "# Convert voxel space coordinates (i, j, k) to index coordinates\n",
    "coordinate_df['index_coords'] = coordinate_df['voxel_coords'].apply(lambda coords: convert_voxel_index_to_flattened_index(coords, mask_shape))\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "coordinate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_closest_values(list_one, list_two):\n",
    "    list_one_int = [int(x) for x in list_one]\n",
    "    list_two_int = [int(x) for x in list_two]\n",
    "\n",
    "    intersection_list = list(set(list_one_int) & set(list_two_int))\n",
    "    complement_list = list(set(list_one_int) - set(intersection_list))\n",
    "\n",
    "    closest_values = []\n",
    "    for value in complement_list:\n",
    "        min_distance = None\n",
    "        closest_value = None\n",
    "        for item in list_two_int:\n",
    "            distance = abs(value - item)\n",
    "            if min_distance is None or distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_value = item\n",
    "        closest_values.append(closest_value)\n",
    "\n",
    "    return closest_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, double check that the coordiantes you are going to test are in the flattened niftis\n",
    "nifti_coordinates = df.columns.values.tolist()\n",
    "test_coordinates = coordinate_df.loc[:,'index_coords'].values.tolist()\n",
    "test_coordinates = [str(test_coordinate) for test_coordinate in test_coordinates]\n",
    "shared_elements = list(set(nifti_coordinates).intersection(test_coordinates))\n",
    "print('Number of shared coordinates: ', np.count_nonzero(shared_elements))\n",
    "print('Numbder of total coordiantes: ', len(coordinate_df['index_coords'].values))\n",
    "print('---')\n",
    "print(shared_elements)\n",
    "print('Now attempting to find the missing value')\n",
    "missing_vals = find_closest_values(test_coordinates, nifti_coordinates[3:])[0]\n",
    "print('Missing value(s): ', missing_vals)\n",
    "test_coordinates.append(str(missing_vals))\n",
    "test_coordinates\n",
    "shared_elements = list(set(nifti_coordinates).intersection(test_coordinates))\n",
    "print('Number of shared coordinates: ', np.count_nonzero(shared_elements))\n",
    "print('Numbder of total coordiantes: ', len(coordinate_df['index_coords'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "X = df.loc[:, shared_elements]\n",
    "X = sm.add_constant(X)\n",
    "y = df.loc[:, 'stdev_improvement_adascog11']\n",
    "model = sm.OLS(y, X).fit()\n",
    "observed_r_squared = model.rsquared\n",
    "print(model.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PALM assessment of the Regression\n",
    "from calvin_utils.palm import permute_row\n",
    "from tqdm import tqdm\n",
    "n_permutations = 10000\n",
    "# permuted_indices = permute_row(df.columns.values[3:])\n",
    "empiric_r_squareds = []\n",
    "y = df.loc[:, 'stdev_improvement_adascog11']\n",
    "for i in tqdm(range(0, n_permutations)):\n",
    "    randomly_sampled_indices = np.random.choice(df.columns.values[3:], size=len(shared_elements), replace=False)\n",
    "    X = df.loc[:, randomly_sampled_indices]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    empiric_r_squareds.append(model.rsquared)\n",
    "print(empiric_r_squareds)\n",
    "print('empiric p: ', np.count_nonzero(empiric_r_squareds>observed_r_squared)/n_permutations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform partial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "def partial_regression_plots(data_df, dep_var, all_indeps):\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    # Define the formula for the full model\n",
    "    formula = f\"{dep_var} ~ {' + '.join(all_indeps)}\"\n",
    "\n",
    "    # Fit the full model\n",
    "    results = smf.ols(formula, data=data_df).fit()\n",
    "\n",
    "    # Create the partial regression plots\n",
    "    plot_data = pd.melt(data_df, id_vars=[dep_var], value_vars=all_indeps, var_name='indep_var')\n",
    "    grid = sns.FacetGrid(plot_data, col='indep_var', col_wrap=4, sharex=False, sharey=True)\n",
    "    grid.map(sns.regplot, 'value', dep_var, truncate=False)\n",
    "    grid.set_axis_labels('Regressed Connectivity (Standard Deviation)', 'Improvement (Standard Deviation)')\n",
    "    grid.set_titles(col_template=\"{col_name}\")\n",
    "\n",
    "    for ax, indep_var in zip(grid.axes.flat, all_indeps):\n",
    "        # Calculate Spearman correlation and p-value\n",
    "\n",
    "        # Get partial regression coefficients\n",
    "        pr_formula = f\"{dep_var} ~ {indep_var} + {' + '.join([var for var in all_indeps if var != indep_var])}\"\n",
    "        pr_results = smf.ols(pr_formula, data=data_df).fit()\n",
    "        coef = pr_results.params[indep_var]\n",
    "        pval = pr_results.pvalues[indep_var]\n",
    "        print(coef, pval)\n",
    "\n",
    "        #Get the Rho of the residuals to outcomes (currently unused)\n",
    "        r, p = spearmanr(pr_results.resid, data_df[dep_var])\n",
    "\n",
    "\n",
    "        # Annotate the plot with correlation and p-value\n",
    "        ax.annotate(f\"coeff = {coef:.2f}, p = {pval:.5f}\", xy=(.5, 1.0), xycoords='axes fraction',\n",
    "                    xytext=(0, 0), textcoords='offset points',\n",
    "                    ha='center', va='top',\n",
    "                    bbox=dict(boxstyle='round,pad=0.0', alpha=0.0),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "        return grid\n",
    "\n",
    "grid = partial_regression_plots(data_df=data_df, dep_var=dep_var, all_indeps=all_indeps)\n",
    "\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    try:\n",
    "        grid.savefig(os.path.join(out_dir, f'partial_regression_grid{formula}.png'))\n",
    "        grid.savefig(os.path.join(out_dir, f'partial_regression_grid{formula}.svg'))\n",
    "    except:\n",
    "        grid.savefig(os.path.join(out_dir, f'partial_regression_grid_full_formula.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Simple Neural Network Stuff Below\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals for each regression, less one independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def create_residual_df(data_df, dep_var, all_indeps):\n",
    "    # Initialize empty dictionary to store residuals\n",
    "    residual_dict = {}\n",
    "\n",
    "    # Loop through each independent variable\n",
    "    for indep_var in all_indeps:\n",
    "        # Define the formula for the partial model\n",
    "        formula = f\"{dep_var} ~ {' + '.join([var for var in all_indeps if var != indep_var])}\"\n",
    "\n",
    "        # Fit the partial model\n",
    "        results = smf.ols(formula, data=data_df).fit()\n",
    "\n",
    "        # Add the residuals to the dictionary with the independent variable name as the key\n",
    "        residual_dict[indep_var] = results.resid\n",
    "\n",
    "    # Add the dependent variable to the dictionary\n",
    "    residual_dict[dep_var] = data_df[dep_var]\n",
    "\n",
    "    # Convert the dictionary to a dataframe\n",
    "    residual_df = pd.DataFrame(residual_dict)\n",
    "\n",
    "    return residual_df\n",
    "residual_df = create_residual_df(data_df, dep_var, all_indeps)\n",
    "display(residual_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regressions using the residual against the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def plot_residuals(residual_df, dep_var, indep_vars):\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    # Melt the residual dataframe\n",
    "    melted_df = pd.melt(residual_df, id_vars=[dep_var], value_vars=indep_vars, var_name='indep_var')\n",
    "\n",
    "    # Create the facet grid of lmplots\n",
    "    facet_plot = sns.lmplot(y=dep_var, x='value', data=melted_df,\n",
    "                            col='indep_var', col_wrap=4,\n",
    "                            truncate=False, sharex=False, sharey=True)\n",
    "    facet_plot.set_titles(col_template=\"{col_name}\")\n",
    "    facet_plot.set_axis_labels('Regressed Connectivity (Standard Deviation)', 'Improvement (Standard Deviation)')\n",
    "    \n",
    "    # Calculate Spearman correlation and p-value for each independent variable\n",
    "    correlations = {}\n",
    "    for iv in indep_vars:\n",
    "        r, p = spearmanr(residual_df[iv], residual_df[dep_var])\n",
    "        correlations[iv] = (r, p)\n",
    "\n",
    "    # Add annotations to the facet grid\n",
    "    for i, ax in enumerate(facet_plot.axes.flat):\n",
    "        iv = indep_vars[i]\n",
    "        r, p = correlations[iv]\n",
    "        ax.annotate(f\"r = {r:.2f}, p = {p:.5f}\", xy=(.5, 1.0), xycoords='axes fraction',\n",
    "                    xytext=(0, 0), textcoords='offset points',\n",
    "                    ha='center', va='top',\n",
    "                    bbox=dict(boxstyle='round,pad=0.0', alpha=0.0),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "    return facet_plot\n",
    "\n",
    "plot_residuals(residual_df, dep_var, all_indeps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the results of the partial regression from a multivariate regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def multiple_regression(residual_df, dep_var):\n",
    "    X = residual_df.drop([dep_var], axis=1)\n",
    "    y = residual_df[dep_var]\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = multiple_regression(residual_df, dep_var)\n",
    "print(model.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def create_residual_df(data_df, dep_var, all_indeps):\n",
    "    # Initialize empty dictionary to store residuals\n",
    "    residual_dict = {}\n",
    "\n",
    "    # Loop through each independent variable\n",
    "    for indep_var in all_indeps:\n",
    "        # Define the formula for the partial model\n",
    "        partial_formula = f\"{dep_var} ~ {' + '.join([var for var in all_indeps if var != indep_var])}\"\n",
    "\n",
    "        # Fit the partial model\n",
    "        partial_results = smf.ols(partial_formula, data=data_df).fit()\n",
    "\n",
    "        # Add the residuals to the dictionary with the independent variable name as the key\n",
    "        partial_col_name = re.sub(r'\\W+', '', indep_var) + '_partial_dep'\n",
    "        residual_dict[partial_col_name] = partial_results.resid\n",
    "\n",
    "        # Define the formula for the second model\n",
    "        second_formula = f\"{indep_var} ~ {' + '.join([var for var in all_indeps if var != indep_var])}\"\n",
    "\n",
    "        # Fit the second model\n",
    "        second_results = smf.ols(second_formula, data=data_df).fit()\n",
    "\n",
    "        # Add the residuals to the dictionary with the independent variable name as the key\n",
    "        second_col_name = re.sub(r'\\W+', '', indep_var) + '_partial_indep'\n",
    "        residual_dict[second_col_name] = second_results.resid\n",
    "\n",
    "    # Add the dependent variable to the dictionary\n",
    "    dep_col_name = re.sub(r'\\W+', '', dep_var)\n",
    "    residual_dict[dep_col_name] = data_df[dep_var]\n",
    "\n",
    "    # Convert the dictionary to a dataframe\n",
    "    residual_df = pd.DataFrame(residual_dict)\n",
    "    residual_df = residual_df.drop(columns=[dep_col_name]) # remove dependent variable column\n",
    "    return residual_df\n",
    "\n",
    "res_df = create_residual_df(residual_df, dep_var, all_indeps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Get the unique first words in the column names\n",
    "first_words = set([col.split()[0].split('_')[0] for col in res_df.columns])\n",
    "print(first_words)\n",
    "\n",
    "col_pairs = []\n",
    "for word in first_words:\n",
    "    cols = [col for col in res_df.columns if word in col]\n",
    "    if len(cols) == 2:\n",
    "        col_pairs.append(cols)\n",
    "print(col_pairs)\n",
    "# Create facet grid of lmplots for columns with the same first word\n",
    "g = sns.FacetGrid(res_df, col=col_pairs, col_wrap=3)\n",
    "g.map(sns.lmplot, x=col_pairs[i][0], y=col_pairs[i][1], data=res_df, scatter_kws={'s': 10}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Visual_partial_indep\", y=\"Visual_partial_dep\", data=res_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Get the unique first words in the column names\n",
    "first_words = set([col.split()[0].split('_')[0] for col in res_df.columns])\n",
    "print(first_words)\n",
    "\n",
    "col_pairs = []\n",
    "for word in first_words:\n",
    "    cols = [col for col in res_df.columns if word in col]\n",
    "    if len(cols) == 2:\n",
    "        col_pairs.append(cols)\n",
    "\n",
    "# Create facet grid of lmplots for columns with the same first word\n",
    "g = sns.FacetGrid(res_df, col=first_words, col_wrap=3)\n",
    "\n",
    "# Map lmplot onto each pair of columns\n",
    "for pair in col_pairs:\n",
    "    x, y = pair\n",
    "    g.map(sns.lmplot, x=x, y=y, data=res_df, scatter_kws={'s': 10})\n",
    "    \n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62880161f19d28ddb8a8f59c63374d84ace356c39e36cc839cb3fb3bb03fb010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
