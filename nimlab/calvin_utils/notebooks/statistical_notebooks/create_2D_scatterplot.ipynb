{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973063e7-db5c-4580-b681-8dec7ef6a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871072b-36be-4b6f-9207-5d9ece916f2a",
   "metadata": {},
   "source": [
    "# ENTER CSV INFORMATION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1c7ae1-6ce7-4649-b748-1ec4c55cab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will save to: /Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/scatterplot_analysis\n"
     ]
    }
   ],
   "source": [
    "## Paths Input Here\n",
    "analysis = \"scatterplot_analysis\"\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    conn_path = r'/Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/ad_pd_full_data.csv'\n",
    "    clin_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/patient_data/AD_Clinical_Data_CDR_ADAS_COG_13.xlsx'\n",
    "    out_dir = os.path.join(os.path.dirname(conn_path), f'{analysis}')\n",
    "\n",
    "if os.path.isdir(out_dir) != True:\n",
    "    os.makedirs(out_dir)\n",
    "print('I will save to:', out_dir)\n",
    "save = True\n",
    "do_transform = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b12638f",
   "metadata": {},
   "source": [
    "## Import Pre-Prepared DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2546f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_change = {}\n",
    "variables_to_change['original'] = [\n",
    "    'percent_change_adascog11'\n",
    "  \n",
    "    ]\n",
    "variables_to_change['destination'] = [\n",
    "    '% Cognitive Improvement'\n",
    "    \n",
    "    ]\n",
    "#----------------------------------------------------------------user input above----------------------------------------------------------------\n",
    "data_df = pd.read_csv(conn_path)\n",
    "# try:\n",
    "#     data_df = data_df.set_index('Unnamed: 0')\n",
    "# except:\n",
    "#     print('Could not find (\"Unnamed: 0\") ')\n",
    "#Rename variables to prevent errors\n",
    "## Set a list of the variables to be fed into DF\n",
    "change_string = ''\n",
    "try:\n",
    "    for i in range (0, len(variables_to_change['original'])):\n",
    "        change_string += f\"variables_to_change['original'][{i}]: variables_to_change['destination'][{i}],\"\n",
    "    change_string = 'data_df.rename(columns={' + change_string[0:-1] + '})'\n",
    "    data_df = eval(change_string)\n",
    "except:\n",
    "    print('Could not change name of input string')\n",
    "#Organize the columns\n",
    "# import natsort\n",
    "# natsorted_columns = natsort.natsorted(data_df.columns)\n",
    "# data_df = data_df.reindex(columns=natsorted_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a109931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient # CDR, ADAS</th>\n",
       "      <th>Age</th>\n",
       "      <th>% Change from baseline (ADAS-Cog11)</th>\n",
       "      <th>Subiculum Connectivity</th>\n",
       "      <th>Subiculum Grey Matter</th>\n",
       "      <th>Subiculum White Matter</th>\n",
       "      <th>Subiculum CSF</th>\n",
       "      <th>Subiculum Total</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Standardized Age</th>\n",
       "      <th>Standardized Percent Improvement</th>\n",
       "      <th>Standardized Subiculum Connectivity</th>\n",
       "      <th>Standardized Subiculum Grey Matter</th>\n",
       "      <th>Standardized Subiculum White Matter</th>\n",
       "      <th>Standardized Subiculum CSF</th>\n",
       "      <th>Standardized Subiculum Total</th>\n",
       "      <th>Cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>56.864683</td>\n",
       "      <td>1.646994</td>\n",
       "      <td>0.510111</td>\n",
       "      <td>2.975675</td>\n",
       "      <td>1.280978</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>-1.179578</td>\n",
       "      <td>1.970962</td>\n",
       "      <td>0.663981</td>\n",
       "      <td>1.773701</td>\n",
       "      <td>1.789087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>52.970984</td>\n",
       "      <td>-0.865158</td>\n",
       "      <td>-1.615736</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>-1.560273</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-1.635523</td>\n",
       "      <td>-0.125938</td>\n",
       "      <td>-1.611307</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-1.093456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>62.459631</td>\n",
       "      <td>0.319460</td>\n",
       "      <td>-0.796399</td>\n",
       "      <td>0.532453</td>\n",
       "      <td>-0.341032</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>-0.524419</td>\n",
       "      <td>0.862866</td>\n",
       "      <td>-0.734373</td>\n",
       "      <td>-0.463295</td>\n",
       "      <td>0.143505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>59.611631</td>\n",
       "      <td>-0.440643</td>\n",
       "      <td>-0.159752</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>-0.358042</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>-0.857915</td>\n",
       "      <td>0.228406</td>\n",
       "      <td>-0.052972</td>\n",
       "      <td>-0.579749</td>\n",
       "      <td>0.126248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>57.928350</td>\n",
       "      <td>-0.328427</td>\n",
       "      <td>-0.229875</td>\n",
       "      <td>-0.988805</td>\n",
       "      <td>-0.339817</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>-1.055024</td>\n",
       "      <td>0.322072</td>\n",
       "      <td>-0.128024</td>\n",
       "      <td>-1.856148</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>37_MD_STN_WUE</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-2.158273</td>\n",
       "      <td>17.978233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>38_MD_STN_WUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>14.611144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>39_MD_STN_WUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.225352</td>\n",
       "      <td>21.551613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>43_MD_STN_WUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.836879</td>\n",
       "      <td>20.200341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>44_MD_STN_WUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.468351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient # CDR, ADAS   Age  % Change from baseline (ADAS-Cog11)  \\\n",
       "0                  101  62.0                           -21.428571   \n",
       "1                  102  77.0                           -36.363636   \n",
       "2                  103  76.0                           -78.947368   \n",
       "3                  104  65.0                          -129.411765   \n",
       "4                  105  50.0                           -10.526316   \n",
       "..                 ...   ...                                  ...   \n",
       "77       37_MD_STN_WUE  64.0                            -2.158273   \n",
       "78       38_MD_STN_WUE   NaN                            -0.694444   \n",
       "79       39_MD_STN_WUE   NaN                            -4.225352   \n",
       "80       43_MD_STN_WUE   NaN                            -2.836879   \n",
       "81       44_MD_STN_WUE   NaN                             0.000000   \n",
       "\n",
       "    Subiculum Connectivity  Subiculum Grey Matter  Subiculum White Matter  \\\n",
       "0                56.864683               1.646994                0.510111   \n",
       "1                52.970984              -0.865158               -1.615736   \n",
       "2                62.459631               0.319460               -0.796399   \n",
       "3                59.611631              -0.440643               -0.159752   \n",
       "4                57.928350              -0.328427               -0.229875   \n",
       "..                     ...                    ...                     ...   \n",
       "77               17.978233                    NaN                     NaN   \n",
       "78               14.611144                    NaN                     NaN   \n",
       "79               21.551613                    NaN                     NaN   \n",
       "80               20.200341                    NaN                     NaN   \n",
       "81               14.468351                    NaN                     NaN   \n",
       "\n",
       "    Subiculum CSF  Subiculum Total    Disease  Standardized Age  \\\n",
       "0        2.975675         1.280978  Alzheimer          0.289341   \n",
       "1        0.740780        -1.560273  Alzheimer         -0.016378   \n",
       "2        0.532453        -0.341032  Alzheimer         -0.888064   \n",
       "3        0.405263        -0.358042  Alzheimer         -1.921065   \n",
       "4       -0.988805        -0.339817  Alzheimer          0.512509   \n",
       "..            ...              ...        ...               ...   \n",
       "77            NaN              NaN        NaN               NaN   \n",
       "78            NaN              NaN        NaN               NaN   \n",
       "79            NaN              NaN        NaN               NaN   \n",
       "80            NaN              NaN        NaN               NaN   \n",
       "81            NaN              NaN        NaN               NaN   \n",
       "\n",
       "    Standardized Percent Improvement  Standardized Subiculum Connectivity  \\\n",
       "0                           0.289341                            -1.179578   \n",
       "1                          -0.016378                            -1.635523   \n",
       "2                          -0.888064                            -0.524419   \n",
       "3                          -1.921065                            -0.857915   \n",
       "4                           0.512509                            -1.055024   \n",
       "..                               ...                                  ...   \n",
       "77                               NaN                                  NaN   \n",
       "78                               NaN                                  NaN   \n",
       "79                               NaN                                  NaN   \n",
       "80                               NaN                                  NaN   \n",
       "81                               NaN                                  NaN   \n",
       "\n",
       "    Standardized Subiculum Grey Matter  Standardized Subiculum White Matter  \\\n",
       "0                             1.970962                             0.663981   \n",
       "1                            -0.125938                            -1.611307   \n",
       "2                             0.862866                            -0.734373   \n",
       "3                             0.228406                            -0.052972   \n",
       "4                             0.322072                            -0.128024   \n",
       "..                                 ...                                  ...   \n",
       "77                                 NaN                                  NaN   \n",
       "78                                 NaN                                  NaN   \n",
       "79                                 NaN                                  NaN   \n",
       "80                                 NaN                                  NaN   \n",
       "81                                 NaN                                  NaN   \n",
       "\n",
       "    Standardized Subiculum CSF  Standardized Subiculum Total  Cohort  \n",
       "0                     1.773701                      1.789087       1  \n",
       "1                    -0.272553                     -1.093456       1  \n",
       "2                    -0.463295                      0.143505       1  \n",
       "3                    -0.579749                      0.126248       1  \n",
       "4                    -1.856148                      0.144737       1  \n",
       "..                         ...                           ...     ...  \n",
       "77                         NaN                           NaN       0  \n",
       "78                         NaN                           NaN       0  \n",
       "79                         NaN                           NaN       0  \n",
       "80                         NaN                           NaN       0  \n",
       "81                         NaN                           NaN       0  \n",
       "\n",
       "[82 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#place response column at start of dataframe\n",
    "# response_series = data_df.pop(variables_to_change['destination'][0])\n",
    "# data_df.insert(0, variables_to_change['destination'][0], response_series)\n",
    "\n",
    "# #Remove outlier\n",
    "# outlier_index=[11, 47, 48, 49]\n",
    "# data_df = data_df.drop(index=outlier_index)\n",
    "\n",
    "#Handle NaNs\n",
    "#Drop NANs\n",
    "# data_df.dropna(inplace=True)\n",
    "\n",
    "#One Hot Encode\n",
    "# data_df.loc[:, 'Randomization Arm'] \n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10164a",
   "metadata": {},
   "source": [
    "Optional - Drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b205e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03b7ead3",
   "metadata": {},
   "source": [
    "## Generate Overall Linear Model Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1beec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_variable = 'Age'\n",
    "independent_variable = ['Atrophy Pattern Index']\n",
    "what_are_the_independent_variables = 'Atrophy Pattern Index'\n",
    "independent_measurement_name = 'Age'\n",
    "#Stratify by variable\n",
    "# index = popped_df['Age at DOS'] > 65\n",
    "# popped_df = popped_df[index]\n",
    "\n",
    "print(independent_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ba5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "from natsort import index_natsorted\n",
    "\n",
    "##----------------------------------------------------------------User Input Above\n",
    "popped_df = data_df.copy()\n",
    "popped_df = popped_df.loc[:, independent_variable.__add__([dependent_variable])]\n",
    "\n",
    "# assuming df is a pandas DataFrame and order is a list of column names\n",
    "order = natsorted(popped_df.columns)\n",
    "\n",
    "# reorganize the columns of df based on the order of column names\n",
    "df_organized = popped_df.reindex(columns=order)\n",
    "\n",
    "#Melt the data frame\n",
    "melted_df = pd.melt(popped_df, \n",
    "                    id_vars=dependent_variable, value_vars=independent_variable,\n",
    "                    var_name=what_are_the_independent_variables, value_name=independent_measurement_name\n",
    "                    );\n",
    "# sort the DataFrame by the Connectivity Region column\n",
    "melted_df = melted_df.sort_values(by=what_are_the_independent_variables, key=lambda x: np.argsort(index_natsorted(melted_df[what_are_the_independent_variables])))\n",
    "display(melted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "num_columns=3\n",
    "###----------------------------------------------------------------\n",
    "sns.set_style('white')\n",
    "sns.set_palette('Greys', 1, desat=1)\n",
    "facet_plot = sns.lmplot(y=dependent_variable, x=independent_measurement_name, data=melted_df,\n",
    "           col=what_are_the_independent_variables,\n",
    "           truncate=False, col_wrap=num_columns,\n",
    "           facet_kws=dict(sharex=False, sharey=True)) #sharex and sharey disallows axis from ranging across subplots. Good for visualizaiton. \n",
    "\n",
    "#Calculate pearsonr for each cluster of Connection Regions\n",
    "grouped_df = melted_df.groupby(what_are_the_independent_variables)\n",
    "result = grouped_df.apply(lambda x: spearmanr(x[independent_measurement_name], x[dependent_variable]))\n",
    "\n",
    "\n",
    "#Organize the outputs of the pearson to match the facet plot\n",
    "rearranged_results = []\n",
    "for region in melted_df[what_are_the_independent_variables].unique():\n",
    "    rearranged_results.append(result[region])\n",
    "result = rearranged_results\n",
    "    \n",
    "for i, ax in enumerate(facet_plot.axes):\n",
    "    r, p = result[i]\n",
    "    region = melted_df[what_are_the_independent_variables].unique()[i]\n",
    "    title = f\"{region}\"\n",
    "    ax.set_title(title)\n",
    "    ax.annotate(f\"r = {r:.2f}, p = {p:.5f}\", xy=(.5, 1.0), xycoords='axes fraction',\n",
    "            xytext=(0, 0), textcoords='offset points',\n",
    "            ha='center', va='top',\n",
    "            bbox=dict(boxstyle='round,pad=0.0', alpha=0.0),\n",
    "            arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "facet_plot.set_xlabels(what_are_the_independent_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b86e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Elbow Plot Above\n",
    "if save:\n",
    "    save_dirsvg = os.path.join(out_dir, 'linear_model_facet_plot.svg')\n",
    "    save_dirpng = os.path.join(out_dir, 'linear_model_facet_plot.png')\n",
    "    facet_plot.savefig(save_dirsvg)\n",
    "    facet_plot.savefig(save_dirpng)\n",
    "    print(f'Fig saved to ', save_dirpng)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bed8763",
   "metadata": {},
   "source": [
    "## Assess overall dsitributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff701e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View distributions\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.set_style('white')\n",
    "sns.set_palette('Greys', 1, desat=1)\n",
    "facet_grid = sns.FacetGrid(data=melted_df, col=what_are_the_independent_variables,\n",
    "                           col_wrap=4, sharex=False, sharey=False);\n",
    "facet_grid.set_titles(col_template=\"{col_name}\")\n",
    "facet_grid.map(sns.kdeplot,independent_measurement_name);\n",
    "# sns.kdeplot(data=melted_df, x='Connectivity', col='Connection Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Elbow Plot Above\n",
    "if save:\n",
    "    save_dir = os.path.join(out_dir, 'kde_plot_facet_plot.png')\n",
    "    facet_plot.savefig(save_dir)\n",
    "    print(f'Fig saved to ', save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ced39b",
   "metadata": {},
   "source": [
    "# Plot the Difference Between 2 Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a304c",
   "metadata": {},
   "source": [
    "ScatterWithConfidence class:\n",
    "\n",
    "ScatterWithConfidence Class\n",
    "The ScatterWithConfidence class is designed to generate scatter plots with associated confidence intervals and permutation-based p-values. It creates plots of two variables and segregates them by a specified criterion, such as age. These plots are further enhanced by overlaying regression lines with their associated confidence intervals. The class can also perform permutation tests to compute a p-value, which is then prominently displayed in the plot title.\n",
    "\n",
    "Attributes:\n",
    "data_df (pandas.DataFrame): The main dataframe containing the data intended for plotting.\n",
    "Key Methods:\n",
    "1. compute_analytic_confidence_interval(x, y, x_vals)\n",
    "Purpose: Computes the regression line and its 95% confidence intervals using analytic methods.\n",
    "Parameters:\n",
    "x (pandas.Series): The x-values of the data.\n",
    "y (pandas.Series): The y-values of the data.\n",
    "x_vals (numpy.ndarray): The x-values where the regression line and confidence intervals should be computed.\n",
    "Returns:\n",
    "y_fit: Regression line values.\n",
    "lower_bound: Lower 95% confidence interval.\n",
    "upper_bound: Upper 95% confidence interval.\n",
    "2. permute_data_and_difference_in_pearson_r(...)\n",
    "Purpose: Computes the difference in Pearson R between two groups using permutation tests.\n",
    "Parameters:\n",
    "x_one, x_two (str): Column names of the two variables to be correlated.\n",
    "split_by (str): Column name used to segregate the data.\n",
    "split_value (float): The criterion value for data segregation.\n",
    "n_permutations (int, optional): Number of permutations to perform (default is 1000).\n",
    "permute_columns (list of str, optional): List of column names to be permuted.\n",
    "Returns:\n",
    "original_diff: Difference in Pearson R of the original data between two groups.\n",
    "p_value: Permutation-based p-value.\n",
    "3. plot_with_analytic_ci_manual_pvalue(...)\n",
    "Purpose: Generates a scatter plot with regression lines, confidence intervals, and the permutation-based p-value in the title.\n",
    "Parameters:\n",
    "x_one, x_two (str): Column names of the two variables for plotting.\n",
    "split_by (str): Column name for data segregation.\n",
    "... (Other parameters for customization, saving, etc.)\n",
    "Returns:\n",
    "A matplotlib scatter plot.\n",
    "To utilize this class:\n",
    "\n",
    "Initialize the class with your dataset.\n",
    "Use the methods described above to compute confidence intervals or perform permutation tests.\n",
    "Generate and visualize your enhanced scatter plot using the provided methods.\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "scatter_plotter = ScatterWithConfidence(data_df)\n",
    "scatter_plotter.plot_with_analytic_ci_manual_pvalue(...)\n",
    "Remember to replace ... with appropriate arguments as your situation demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the class and its methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "import seaborn as sns\n",
    "class ScatterWithConfidence:\n",
    "    def __init__(self, data_df):\n",
    "        self.data_df = data_df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_analytic_confidence_interval(x, y, x_vals):\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        y_fit = slope * x_vals + intercept\n",
    "        \n",
    "        residuals = y - (slope * x + intercept)\n",
    "        stderr = np.sqrt(np.sum(residuals**2) / (len(y) - 2))\n",
    "        \n",
    "        t_value = t.ppf(0.975, df=len(x)-2)\n",
    "        ci = t_value * stderr * np.sqrt(1/len(x) + (x_vals - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "        \n",
    "        upper_bound = y_fit + ci\n",
    "        lower_bound = y_fit - ci\n",
    "        \n",
    "        return y_fit, lower_bound, upper_bound\n",
    "\n",
    "    def permute_data_and_difference_in_pearson_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, permute_columns=[]):\n",
    "        original_diff = self.data_df[self.data_df[split_by] < split_value][x_one].corr(self.data_df[self.data_df[split_by] < split_value][x_two]) - \\\n",
    "                       self.data_df[self.data_df[split_by] >= split_value][x_one].corr(self.data_df[self.data_df[split_by] >= split_value][x_two])\n",
    "\n",
    "        permuted_diffs = []\n",
    "\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "            \n",
    "            diff = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                   permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            \n",
    "            permuted_diffs.append(diff)\n",
    "\n",
    "        p_value = np.mean([diff <= original_diff for diff in permuted_diffs])\n",
    "        return original_diff, p_value\n",
    "\n",
    "    def plot_with_analytic_ci_manual_pvalue(self, x_one, x_two, split_by, split_value, x_label='X1', y_label='X2', alpha=0.3, manual_p_value=None, permute_column=None, save=False, out_dir=None):\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        \n",
    "        group1 = self.data_df[self.data_df[split_by] < split_value]\n",
    "        group2 = self.data_df[self.data_df[split_by] >= split_value]\n",
    "        \n",
    "        ax.scatter(group1[x_one], group1[x_two], color='blue', label='Young', s=40, alpha=0.6, marker='o')\n",
    "        ax.scatter(group2[x_one], group2[x_two], color='red', label='Old', s=40, alpha=0.6, marker='o')\n",
    "        \n",
    "        x_vals = np.linspace(self.data_df[x_one].min(), self.data_df[x_one].max(), 400)\n",
    "        \n",
    "        for group, color in [(group1, 'blue'), (group2, 'red')]:\n",
    "            y_fit, lower_bound, upper_bound = self.compute_analytic_confidence_interval(group[x_one], group[x_two], x_vals)\n",
    "            ax.plot(x_vals, y_fit, color=color)\n",
    "            ax.fill_between(x_vals, lower_bound, upper_bound, color=color, alpha=alpha)\n",
    "        \n",
    "        if manual_p_value is None:\n",
    "            if permute_column:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=1000, permute_columns=[permute_column])\n",
    "            else:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=1000, permute_columns=[x_one, x_two, split_by])\n",
    "        \n",
    "        ax.set_title(f\"Delta Rho: {rho:.2f} | p-value: {manual_p_value:.4f}\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc='best', frameon=False)\n",
    "        ax.grid(False)\n",
    "        sns.despine(ax=ax)\n",
    "        \n",
    "        if save and out_dir is not None:\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.png\", bbox_inches='tight')\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.svg\", bbox_inches='tight')\n",
    "            print(f'Saved to {out_dir}/scatter_with_polyfit_and_analytic_ci.svg')\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461cd108",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7707d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d74661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the class\n",
    "scatter_plotter = ScatterWithConfidence(data_df)\n",
    "\n",
    "# Generate and display the plot\n",
    "fig = scatter_plotter.plot_with_analytic_ci_manual_pvalue(x_one=\"Subiculum Connectivity\",\n",
    "                                                         x_two=\"perc_improvement\",\n",
    "                                                         split_by=\"Age\",\n",
    "                                                         split_value=65.7,\n",
    "                                                         x_label=\"Subiculum Connectivity\",\n",
    "                                                         y_label=\"% Improvement (MDRS)\",\n",
    "                                                         manual_p_value=None,\n",
    "                                                         save=True, \n",
    "                                                         out_dir=out_dir)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11c19503",
   "metadata": {},
   "source": [
    "# Analyze an Individual Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Above to Determine Calculation Method\n",
    "ycolumn_of_interest = '% Improvement (ADAS-Cog11)'\n",
    "y_vals = data_df[ycolumn_of_interest].values.tolist()\n",
    "# y_vals = data_df.iloc[:, 0].tolist()\n",
    "\n",
    "xcolumn_of_interest = 'Maxima'\n",
    "x_vals = data_df[xcolumn_of_interest].values.tolist()\n",
    "# x_vals = data_df.iloc[:, 1].tolist()\n",
    "\n",
    "\n",
    "print('No. datapoints in y_vals: ', len(y_vals))\n",
    "print(y_vals)\n",
    "\n",
    "print('No. datapoints in x_vals: ', len(x_vals))\n",
    "print(x_vals)\n",
    "# print(x_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4292894",
   "metadata": {},
   "source": [
    "## Transform Data if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88397528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Q-Q Plots\n",
    "import scipy.stats as stats\n",
    "stats.probplot(x_vals, plot=plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Transformations\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "#function to return plots for the feature\n",
    "def normality_plot(data, transform_function=None):\n",
    "    sns.set_style('white')\n",
    "    if transform_function is not None:\n",
    "        data = eval(transform_function)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.kdeplot(data)\n",
    "    plt.subplot(1,2,2)\n",
    "    stats.probplot(data, plot=plt)\n",
    "    plt.show()\n",
    "    return data, fig\n",
    "\n",
    "def linear_transform(data):\n",
    "    transformed = data\n",
    "    return transformed\n",
    "\n",
    "def natlog_transform(data):\n",
    "    transformed=np.log(data)\n",
    "    return transformed\n",
    "\n",
    "def reciprocal_transform(data):\n",
    "    transformed = np.divide(1,data)\n",
    "    return transformed\n",
    "\n",
    "def root_transform(data):\n",
    "    transformed = np.sqrt(data)\n",
    "    return transformed\n",
    "\n",
    "def exponential_transform(data, exponent=2):\n",
    "    transformed = np.power(data, exponent)\n",
    "    return transformed\n",
    "\n",
    "def boxcox_transform(data):\n",
    "    transformed = stats.boxcox(data)\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3586df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- transforms = linear_transform, natlog_transform, reciprocal_transform, root_transform, exponential_transform, boxcox_transform\n",
    "transform = 'linear_transform' #'#'boxcox_transform'\n",
    "transformed_data, transform_fig = normality_plot(x_vals, f'{transform}({x_vals})')\n",
    "if save:\n",
    "    transform_fig.savefig(os.path.join(out_dir, f'transformed_data_{transform}_{xcolumn_of_interest}.png'))\n",
    "    print(f'Fig saved to ', out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62581c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn transformed data into x_vals\n",
    "if do_transform: \n",
    "    try:\n",
    "        x_vals = transformed_data.tolist()\n",
    "        x_vals = np.nan_to_num(x_vals, nan=1, posinf=1, neginf=1) #np.replace(np.nan, np.mean(x_vals))\n",
    "        mean = np.mean(x_vals)\n",
    "        x_vals[x_vals == 1] = mean\n",
    "        print(len(x_vals))\n",
    "        print(x_vals)\n",
    "    except:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0505ed-2490-4f51-ac52-d828b7ccc02b",
   "metadata": {},
   "source": [
    "## Calculate Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdbd42-3d86-4ce0-b158-bce1688c697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "x=x_vals\n",
    "y=y_vals\n",
    "r, p = pearsonr(x, y)\n",
    "\n",
    "\n",
    "#Creating regression line\n",
    "m, b = np.polyfit(x,y,1)\n",
    "plotline = []\n",
    "for a in range(0,len(x_vals)):\n",
    "    plotline.append(x_vals[a]*m+b)\n",
    "\n",
    "arb = np.polyfit(x,y,1)\n",
    "p1 = np.poly1d(arb)\n",
    "fit1 = np.polyval(arb, x); res1 = np.sum((y-fit1)**2)\n",
    "\n",
    "arb = np.polyfit(x,y,2)\n",
    "p2 = np.poly1d(arb)\n",
    "fit2 = np.polyval(arb, x); res2 = np.sum((y-fit2)**2)\n",
    "\n",
    "arb = np.polyfit(x,y,3)\n",
    "p3 = np.poly1d(arb)\n",
    "fit3 = np.polyval(arb, x); res3 = np.sum((y-fit3)**2)\n",
    "\n",
    "arb = np.polyfit(x,y,4)\n",
    "p4 = np.poly1d(arb)\n",
    "fit4 = np.polyval(arb, x); res4 = np.sum((y-fit4)**2)\n",
    "\n",
    "arb = np.polyfit(x,y,5)\n",
    "p5 = np.poly1d(arb)\n",
    "fit5 = np.polyval(arb, x); res5 = np.sum((y-fit5)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate spearman's rho\n",
    "from scipy.stats import spearmanr\n",
    "correlation_dict = {}\n",
    "pearson_results = pearsonr(x, y)\n",
    "correlation_dict['pearson_r'] = pearson_results[0]\n",
    "correlation_dict['pearson_p'] = pearson_results[1]\n",
    "spearman_results = spearmanr(x, y)\n",
    "correlation_dict['spearman_r'] = spearman_results[0]\n",
    "correlation_dict['spearman_p'] = spearman_results[1]\n",
    "\n",
    "print(pearson_results)\n",
    "print(spearman_results)\n",
    "correlation_df = pd.DataFrame(correlation_dict, index=['results'])\n",
    "display(correlation_df)\n",
    "\n",
    "if save:\n",
    "    correlation_df.to_csv(os.path.join(out_dir, f'correlation_results_{xcolumn_of_interest}_{transform}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d1bd1-fb3d-486c-84fe-0fd3afc2f3a5",
   "metadata": {},
   "source": [
    "## Plot the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the LOBF Least Squares Distribution\n",
    "resids = [res1, res2, res3, res4, res5]\n",
    "xres = range(0+1, len(resids)+1)\n",
    "figure_res = plt.figure(figsize = (10,10))\n",
    "plt.plot(xres, resids, 'o-')\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('Least squares error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5727835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Elbow Plot Above\n",
    "save_dir = os.path.join(out_dir, analysis) + f'{xcolumn_of_interest}_{transform}polynomial_elbow_plot.png'\n",
    "figure_res.savefig(save_dir)\n",
    "print(f'Fig {figure_res} \\n saved to ', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2876019-ae2b-4b7a-a3bd-20378278621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.style.use('grayscale')\n",
    "sns.set_style('white')\n",
    "figure = plt.figure(figsize = (10,10))\n",
    "\n",
    "#plot the datapoints\n",
    "sns.scatterplot(x=x, y=y) \n",
    "\n",
    "#Plot regresison line\n",
    "smooth = np.linspace(np.min(x), np.max(x), 100)\n",
    "plt.plot(smooth, p1(smooth), '-')#, smooth, p2(smooth), '-', smooth, p3(smooth), '-', smooth, p4(smooth), '-', smooth, p5(smooth), '-')\n",
    "# plt.legend([1, 2, 3, 4, 5])\n",
    "\n",
    "plt.xlabel('Connectivity')\n",
    "plt.ylabel('Percent Improvement (ADAS-Cog 11)')\n",
    "plt.title('Pearson: ' + str(r) + ' & p value: ' + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f1782-9d86-4b4c-92d0-db77e9d78d59",
   "metadata": {},
   "source": [
    "## Save Figure if Desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b54e6-d75e-434a-8914-1f6e71d8d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(out_dir, analysis) + f'{xcolumn_of_interest}_{transform}_linear_fit.png'\n",
    "figure.savefig(save_dir)\n",
    "print('Fig saved to ', save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f106f",
   "metadata": {},
   "source": [
    "# Perform Secondary Analysis Stratifying By Third Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2394080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Third Variable\n",
    "#User Input Below -- What dataframe has your third variable?\n",
    "metric = 'Age at DOS' #-- What column has your third variable?\n",
    "metric_val = 65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb826db",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vals = data_df[metric].values.tolist()\n",
    "print('No. datapoints in z_vals: ', len(z_vals))\n",
    "print(z_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipute z vals\n",
    "\n",
    "over_65_x = []\n",
    "over_65_y = []\n",
    "under_65_x = []\n",
    "under_65_y = []\n",
    "#THE BELOW LOOP WILL CREATE NEW DATASETS DETERMINED BY THE Z VALUE: AGE. \n",
    "for i in range(0, len(z_vals)):\n",
    "    if z_vals[i] > metric_val:\n",
    "        over_65_x.append(x_vals[i])\n",
    "        over_65_y.append(y_vals[i])\n",
    "    elif z_vals[i] <= metric_val:\n",
    "        under_65_x.append(x_vals[i])\n",
    "        under_65_y.append(y_vals[i])\n",
    "    else:\n",
    "        print('Some error occured')\n",
    "print('Len >65: ', len(over_65_x))\n",
    "print('Len <=65: ', len(under_65_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations on new lists\n",
    "r_over_65, p_over_65 = pearsonr(over_65_x, over_65_y)\n",
    "print('Over 65 \\n r: ', r_over_65, ' | p: ', p_over_65)\n",
    "r_under_65, p_under_65 = pearsonr(under_65_x, under_65_y)\n",
    "print('Under 65 \\n r: ', r_under_65, ' | p: ', p_under_65)\n",
    "\n",
    "#Line of Best Fit on New Lists\n",
    "m_over, b_over = np.polyfit(over_65_x,over_65_y,1)\n",
    "over_plotline = []\n",
    "for a in range(0,len(over_65_x)):\n",
    "    over_plotline.append(over_65_x[a]*m_over+b_over)\n",
    "\n",
    "m_under, b_under = np.polyfit(under_65_x,under_65_y,1)\n",
    "under_plotline = []\n",
    "for a in range(0,len(under_65_x)):\n",
    "    under_plotline.append(under_65_x[a]*m_under+b_under)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4deb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the new data\n",
    "figure2 = plt.figure(figsize = (10,10))\n",
    "x_label = 'connectivity'\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel('% Improvement (ADAS-Cog11)')\n",
    "plt.tick_params(labelsize=12, pad=6)\n",
    "\n",
    "plt.title(f'{metric}>{metric_val} r: {r_over_65} & p: ' + str(p_over_65)[0:7] + '\\n' + \n",
    "            f'{metric}<={metric_val} r: ' +str(r_under_65) + ' & p: ' +str(p_under_65)[0:7])\n",
    "\n",
    "#Plot Over 65s\n",
    "plt.scatter(over_65_x, over_65_y, c='red')\n",
    "plt.plot(over_65_x, over_plotline, color='red')\n",
    "#Plot Under 65s\n",
    "plt.scatter(under_65_x, under_65_y, c='blue')\n",
    "plt.plot(under_65_x, under_plotline, color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db941d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir2 = os.path.join(out_dir, 'by_age')\n",
    "if os.path.isdir(out_dir2)==False:\n",
    "    os.mkdir(out_dir2)\n",
    "save_dir2 = os.path.join(out_dir2, analysis) + '_split_by_outcome_outlier_removed.png'\n",
    "figure2.savefig(save_dir2)\n",
    "\n",
    "print(f'saved to {out_dir2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
