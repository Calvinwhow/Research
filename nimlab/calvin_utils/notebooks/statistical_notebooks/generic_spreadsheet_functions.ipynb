{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the CSV\n",
    "spreadsheet_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/KiTH_Solutions/Research/Clinical Trial/study_metadata/all_performances.xlsx'\n",
    "out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/KiTH_Solutions/Research/Clinical Trial/analyses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "if os.path.exists(out_dir) != True:\n",
    "    os.makedirs(out_dir)\n",
    "    print('Made directory', out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Relevant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Randomization Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cognitive Status</th>\n",
       "      <th>Question_2</th>\n",
       "      <th>Question_3</th>\n",
       "      <th>Question_4</th>\n",
       "      <th>Question_5</th>\n",
       "      <th>Question_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Expert Algorithm Equivalent</th>\n",
       "      <th>Subjective Complaint</th>\n",
       "      <th>Attention Complaint</th>\n",
       "      <th>Memory Complaint</th>\n",
       "      <th>Fluency Complaint</th>\n",
       "      <th>Language Complaint</th>\n",
       "      <th>Visuospatial Complaint</th>\n",
       "      <th>Impaired on ACE3</th>\n",
       "      <th>iADL Impaired</th>\n",
       "      <th>ADL Impaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "      <td>Intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>MCI</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48</td>\n",
       "      <td>Intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>patient_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>patient_26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>patient_30</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33</td>\n",
       "      <td>Intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patient_33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>patient_38</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>patient_40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>patient_42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>patient_47</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>patient_108</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>patient_109</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>patient_106</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>Intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>patient_110</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>patient_104</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>patient_111</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>MCI</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>patient_112</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83</td>\n",
       "      <td>Intact</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>patient_102</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>MCI</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>patient_103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43</td>\n",
       "      <td>MCI</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>patient_114</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>patient_107</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>patient_115</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>patient_119</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>patient_121</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>intact</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>patient_122</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>patient_123</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>patient_126</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>patient_128</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>patient_130</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>patient_131</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>patient_132</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>patient_1020</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>patient_1021</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>patient_1003</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>patient_1004</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>patient_1005</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>patient_1006</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>patient_1007</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>patient_1008</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>patient_1009</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>patient_1010</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>MCI</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>patient_1011</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>intact</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measurement  Cohort  Randomization Group  Age Cognitive Status  \\\n",
       "0     patient_11       1                  2.0   50           Intact   \n",
       "1     patient_15       1                  1.0   42              MCI   \n",
       "2     patient_17       1                  1.0   35              MCI   \n",
       "3     patient_19       1                  1.0   71              MCI   \n",
       "4     patient_24       1                  2.0   48           Intact   \n",
       "5     patient_25       1                  1.0   53              MCI   \n",
       "6     patient_26       1                  1.0   49              MCI   \n",
       "7     patient_30       1                  2.0   33           Intact   \n",
       "8     patient_33       1                  2.0   36              MCI   \n",
       "9     patient_38       1                  2.0   27              MCI   \n",
       "10    patient_40       1                  1.0   51           intact   \n",
       "11    patient_42       1                  1.0   46           intact   \n",
       "12    patient_47       1                  1.0   37              MCI   \n",
       "13   patient_108       2                  1.0   35           intact   \n",
       "14   patient_109       2                  1.0   41              MCI   \n",
       "15   patient_106       2                  1.0   39           Intact   \n",
       "16   patient_110       2                  2.0   39           intact   \n",
       "17   patient_104       2                  1.0   63              MCI   \n",
       "18   patient_111       2                  1.0   61              MCI   \n",
       "19   patient_103       2                  2.0   43              MCI   \n",
       "20   patient_112       2                  2.0   83           Intact   \n",
       "21   patient_102       2                  2.0   39              MCI   \n",
       "22   patient_103       2                  2.0   43              MCI   \n",
       "23   patient_114       2                  2.0   35           Intact   \n",
       "24   patient_107       2                  1.0   54              MCI   \n",
       "25   patient_115       2                  1.0   35           intact   \n",
       "26   patient_119       4                  2.0   37           intact   \n",
       "27   patient_121       4                  2.0   36           intact   \n",
       "28   patient_122       4                  1.0   35           intact   \n",
       "29   patient_123       4                  2.0   35           intact   \n",
       "30   patient_126       4                  1.0   37           intact   \n",
       "31   patient_128       4                  2.0   78           intact   \n",
       "32   patient_130       4                  1.0   47           intact   \n",
       "33   patient_131       4                  1.0   49           intact   \n",
       "34   patient_132       4                  2.0   45           intact   \n",
       "35  patient_1020       3                  NaN   41           intact   \n",
       "36  patient_1021       3                  NaN   33           intact   \n",
       "37  patient_1003       3                  NaN   65           intact   \n",
       "38  patient_1004       3                  NaN   70           intact   \n",
       "39  patient_1005       3                  NaN   82           intact   \n",
       "40  patient_1006       3                  NaN   80           intact   \n",
       "41  patient_1007       3                  NaN   62           intact   \n",
       "42  patient_1008       3                  NaN   52           intact   \n",
       "43  patient_1009       3                  NaN   49              MCI   \n",
       "44  patient_1010       3                  NaN   66              MCI   \n",
       "45  patient_1011       3                  NaN   71           intact   \n",
       "\n",
       "    Question_2  Question_3  Question_4  Question_5  Question_6  ...  \\\n",
       "0           10           3           5           3          13  ...   \n",
       "1           10           3           1           2           6  ...   \n",
       "2           10           3           2           3           5  ...   \n",
       "3            8           3           5           3           7  ...   \n",
       "4            9           3           5           3          11  ...   \n",
       "5           10           3           1           3           7  ...   \n",
       "6           10           3           5           2          12  ...   \n",
       "7           10           3           5           3          10  ...   \n",
       "8           10           3           5           3           8  ...   \n",
       "9            9           3           4           3          10  ...   \n",
       "10           9           3           5           3          10  ...   \n",
       "11          10           3           5           3          10  ...   \n",
       "12           9           3           4           3          14  ...   \n",
       "13          10           3           5           3           8  ...   \n",
       "14          10           3           5           3           9  ...   \n",
       "15           9           3           0           3          11  ...   \n",
       "16          10           3           3           3           9  ...   \n",
       "17          10           3           0           2           6  ...   \n",
       "18           6           3           0           3           4  ...   \n",
       "19           9           3           3           1           0  ...   \n",
       "20           9           2           5           2           4  ...   \n",
       "21           8           2           5           0           4  ...   \n",
       "22           9           3           4           1           6  ...   \n",
       "23          10           3           5           3          11  ...   \n",
       "24          10           3           3           1           5  ...   \n",
       "25          10           3           5           3          14  ...   \n",
       "26          10           3           5           3          13  ...   \n",
       "27           9           3           5           3          14  ...   \n",
       "28          10           3           5           3          14  ...   \n",
       "29          10           3           5           3          14  ...   \n",
       "30          10           3           5           3          14  ...   \n",
       "31          10           3           5           3          14  ...   \n",
       "32          10           3           5           3          14  ...   \n",
       "33          10           3           5           3          14  ...   \n",
       "34          10           2           4           2          13  ...   \n",
       "35          10           3           5           3          14  ...   \n",
       "36          10           3           5           3          14  ...   \n",
       "37          10           1           1           1          13  ...   \n",
       "38          10           3           3           1          13  ...   \n",
       "39          10           1           5           3          12  ...   \n",
       "40          10           0           5           1          12  ...   \n",
       "41          10           1           5           0          13  ...   \n",
       "42          10           1           3           1          13  ...   \n",
       "43          10           0           1           0           8  ...   \n",
       "44          10           1           5           1           7  ...   \n",
       "45          10           1           4           3          14  ...   \n",
       "\n",
       "    Expert Algorithm Equivalent  Subjective Complaint  Attention Complaint  \\\n",
       "0                          33.0                  None                  NaN   \n",
       "1                          26.0                  None                  NaN   \n",
       "2                          30.0                   Yes                  NaN   \n",
       "3                          32.0                   Yes                  NaN   \n",
       "4                          32.0                   Yes                  NaN   \n",
       "5                          28.0                   Yes                  NaN   \n",
       "6                          31.0                   Yes                  NaN   \n",
       "7                          32.0                   Yes                  Yes   \n",
       "8                          32.0                   Yes                  NaN   \n",
       "9                          24.0                   Yes                  NaN   \n",
       "10                         26.0                   Yes                  NaN   \n",
       "11                         31.0                   Yes                  NaN   \n",
       "12                         30.0                    No                  NaN   \n",
       "13                         33.0                   NaN                  NaN   \n",
       "14                         29.0                   NaN                  NaN   \n",
       "15                         30.0                   NaN                  NaN   \n",
       "16                         29.0                   NaN                  NaN   \n",
       "17                         26.0                   NaN                  NaN   \n",
       "18                         21.0                   NaN                  NaN   \n",
       "19                         30.0                   NaN                  NaN   \n",
       "20                         30.0                   NaN                  NaN   \n",
       "21                         26.0                   NaN                  NaN   \n",
       "22                         30.0                   NaN                  NaN   \n",
       "23                         32.0                   NaN                  NaN   \n",
       "24                         26.0                   NaN                  NaN   \n",
       "25                         32.0                   NaN                  NaN   \n",
       "26                         33.0                   NaN                  NaN   \n",
       "27                         31.0                   NaN                  NaN   \n",
       "28                         31.0                   NaN                  NaN   \n",
       "29                         32.0                   NaN                  NaN   \n",
       "30                         33.0                   NaN                  NaN   \n",
       "31                         31.0                   NaN                  NaN   \n",
       "32                         31.0                   NaN                  NaN   \n",
       "33                         31.0                   NaN                  NaN   \n",
       "34                         30.0                   NaN                  NaN   \n",
       "35                          NaN                   NaN                  NaN   \n",
       "36                          NaN                   NaN                  NaN   \n",
       "37                          NaN                   NaN                  NaN   \n",
       "38                          NaN                   NaN                  NaN   \n",
       "39                          NaN                   NaN                  NaN   \n",
       "40                          NaN                   NaN                  NaN   \n",
       "41                          NaN                   NaN                  NaN   \n",
       "42                          NaN                   NaN                  NaN   \n",
       "43                          NaN                   NaN                  NaN   \n",
       "44                          NaN                   NaN                  NaN   \n",
       "45                          NaN                   NaN                  NaN   \n",
       "\n",
       "    Memory Complaint  Fluency Complaint  Language Complaint  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                Yes                NaN                 Yes   \n",
       "3                Yes                NaN                 Yes   \n",
       "4                NaN                NaN                 Yes   \n",
       "5                Yes                NaN                 NaN   \n",
       "6                NaN                NaN                 Yes   \n",
       "7                Yes                NaN                 Yes   \n",
       "8                Yes                NaN                 NaN   \n",
       "9                Yes                NaN                 NaN   \n",
       "10               Yes                NaN                 Yes   \n",
       "11               Yes                NaN                 Yes   \n",
       "12               NaN                NaN                 NaN   \n",
       "13               NaN                NaN                 NaN   \n",
       "14               NaN                NaN                 NaN   \n",
       "15               NaN                NaN                 NaN   \n",
       "16               NaN                NaN                 NaN   \n",
       "17               NaN                NaN                 NaN   \n",
       "18               NaN                NaN                 NaN   \n",
       "19               NaN                NaN                 NaN   \n",
       "20               NaN                NaN                 NaN   \n",
       "21               NaN                NaN                 NaN   \n",
       "22               NaN                NaN                 NaN   \n",
       "23               NaN                NaN                 NaN   \n",
       "24               NaN                NaN                 NaN   \n",
       "25               NaN                NaN                 NaN   \n",
       "26               NaN                NaN                 NaN   \n",
       "27               NaN                NaN                 NaN   \n",
       "28               NaN                NaN                 NaN   \n",
       "29               NaN                NaN                 NaN   \n",
       "30               NaN                NaN                 NaN   \n",
       "31               NaN                NaN                 NaN   \n",
       "32               NaN                NaN                 NaN   \n",
       "33               NaN                NaN                 NaN   \n",
       "34               NaN                NaN                 NaN   \n",
       "35               NaN                NaN                 NaN   \n",
       "36               NaN                NaN                 NaN   \n",
       "37               NaN                NaN                 NaN   \n",
       "38               NaN                NaN                 NaN   \n",
       "39               NaN                NaN                 NaN   \n",
       "40               NaN                NaN                 NaN   \n",
       "41               NaN                NaN                 NaN   \n",
       "42               NaN                NaN                 NaN   \n",
       "43               NaN                NaN                 NaN   \n",
       "44               NaN                NaN                 NaN   \n",
       "45               NaN                NaN                 NaN   \n",
       "\n",
       "    Visuospatial Complaint  Impaired on ACE3  iADL Impaired  ADL Impaired  \n",
       "0                      NaN                No           None          None  \n",
       "1                      NaN               Yes           None          None  \n",
       "2                      NaN               Yes           None          None  \n",
       "3                      NaN               Yes           None          None  \n",
       "4                      NaN                No           None          None  \n",
       "5                      NaN               Yes           None          None  \n",
       "6                      NaN               Yes           None          None  \n",
       "7                      NaN                No           None          None  \n",
       "8                      NaN               Yes           None          None  \n",
       "9                      NaN               Yes           None          None  \n",
       "10                     NaN                No           None          None  \n",
       "11                     NaN                No           None          None  \n",
       "12                     NaN                No           None          None  \n",
       "13                     NaN               NaN            NaN           NaN  \n",
       "14                     NaN               NaN            NaN           NaN  \n",
       "15                     NaN               NaN            NaN           NaN  \n",
       "16                     NaN               NaN            NaN           NaN  \n",
       "17                     NaN               NaN            NaN           NaN  \n",
       "18                     NaN               NaN            NaN           NaN  \n",
       "19                     NaN               NaN            NaN           NaN  \n",
       "20                     NaN               NaN            NaN           NaN  \n",
       "21                     NaN               NaN            NaN           NaN  \n",
       "22                     NaN               NaN            NaN           NaN  \n",
       "23                     NaN               NaN            NaN           NaN  \n",
       "24                     NaN               NaN            NaN           NaN  \n",
       "25                     NaN               NaN            NaN           NaN  \n",
       "26                     NaN               NaN            NaN           NaN  \n",
       "27                     NaN               NaN            NaN           NaN  \n",
       "28                     NaN               NaN            NaN           NaN  \n",
       "29                     NaN               NaN            NaN           NaN  \n",
       "30                     NaN               NaN            NaN           NaN  \n",
       "31                     NaN               NaN            NaN           NaN  \n",
       "32                     NaN               NaN            NaN           NaN  \n",
       "33                     NaN               NaN            NaN           NaN  \n",
       "34                     NaN               NaN            NaN           NaN  \n",
       "35                     NaN               NaN            NaN           NaN  \n",
       "36                     NaN               NaN            NaN           NaN  \n",
       "37                     NaN               NaN            NaN           NaN  \n",
       "38                     NaN               NaN            NaN           NaN  \n",
       "39                     NaN               NaN            NaN           NaN  \n",
       "40                     NaN               NaN            NaN           NaN  \n",
       "41                     NaN               NaN            NaN           NaN  \n",
       "42                     NaN               NaN            NaN           NaN  \n",
       "43                     NaN               NaN            NaN           NaN  \n",
       "44                     NaN               NaN            NaN           NaN  \n",
       "45                     NaN               NaN            NaN           NaN  \n",
       "\n",
       "[46 rows x 73 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User Input\n",
    "## Input the sheet you would like to use below\n",
    "sheet_name = 'study_results'\n",
    "\n",
    "if os.path.basename(spreadsheet_dir).split('.')[1] == 'csv':\n",
    "    data_df = pd.read_csv(spreadsheet_dir)\n",
    "else:\n",
    "    data_df = pd.read_excel(spreadsheet_dir, sheet_name=sheet_name)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take Slice of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient # CDR, ADAS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Percent Cognitive Improvement</th>\n",
       "      <th>Z-Scored Cognitive Improvement By Group</th>\n",
       "      <th>Subiculum Connectivity</th>\n",
       "      <th>Subiculum Grey Matter</th>\n",
       "      <th>Subiculum White Matter</th>\n",
       "      <th>Subiculum CSF</th>\n",
       "      <th>Subiculum Total</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Standardized Age</th>\n",
       "      <th>Standardized Percent Improvement</th>\n",
       "      <th>Standardized Subiculum Connectivity</th>\n",
       "      <th>Standardized Subiculum Grey Matter</th>\n",
       "      <th>Standardized Subiculum White Matter</th>\n",
       "      <th>Standardized Subiculum CSF</th>\n",
       "      <th>Standardized Subiculum Total</th>\n",
       "      <th>Cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>56.864683</td>\n",
       "      <td>1.646994</td>\n",
       "      <td>0.510111</td>\n",
       "      <td>2.975675</td>\n",
       "      <td>1.280978</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>-1.179578</td>\n",
       "      <td>1.970962</td>\n",
       "      <td>0.663981</td>\n",
       "      <td>1.773701</td>\n",
       "      <td>1.789087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>52.970984</td>\n",
       "      <td>-0.865158</td>\n",
       "      <td>-1.615736</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>-1.560273</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-1.635523</td>\n",
       "      <td>-0.125938</td>\n",
       "      <td>-1.611307</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-1.093456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>62.459631</td>\n",
       "      <td>0.319460</td>\n",
       "      <td>-0.796399</td>\n",
       "      <td>0.532453</td>\n",
       "      <td>-0.341032</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>-0.524419</td>\n",
       "      <td>0.862866</td>\n",
       "      <td>-0.734373</td>\n",
       "      <td>-0.463295</td>\n",
       "      <td>0.143505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>59.611631</td>\n",
       "      <td>-0.440643</td>\n",
       "      <td>-0.159752</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>-0.358042</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>-0.857915</td>\n",
       "      <td>0.228406</td>\n",
       "      <td>-0.052972</td>\n",
       "      <td>-0.579749</td>\n",
       "      <td>0.126248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>57.928350</td>\n",
       "      <td>-0.328427</td>\n",
       "      <td>-0.229875</td>\n",
       "      <td>-0.988805</td>\n",
       "      <td>-0.339817</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>-1.055024</td>\n",
       "      <td>0.322072</td>\n",
       "      <td>-0.128024</td>\n",
       "      <td>-1.856148</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-2.158273</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>17.978233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>0.346526</td>\n",
       "      <td>14.611144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.225352</td>\n",
       "      <td>-0.872505</td>\n",
       "      <td>21.551613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.836879</td>\n",
       "      <td>-0.393141</td>\n",
       "      <td>20.200341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>14.468351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient # CDR, ADAS   Age  Percent Cognitive Improvement  \\\n",
       "0                   101  62.0                     -21.428571   \n",
       "1                   102  77.0                     -36.363636   \n",
       "2                   103  76.0                     -78.947368   \n",
       "3                   104  65.0                    -129.411765   \n",
       "4                   105  50.0                     -10.526316   \n",
       "..                  ...   ...                            ...   \n",
       "77                   37  64.0                      -2.158273   \n",
       "78                   38   NaN                      -0.694444   \n",
       "79                   39   NaN                      -4.225352   \n",
       "80                   43   NaN                      -2.836879   \n",
       "81                   44   NaN                       0.000000   \n",
       "\n",
       "    Z-Scored Cognitive Improvement By Group  Subiculum Connectivity  \\\n",
       "0                                  0.289341               56.864683   \n",
       "1                                 -0.016378               52.970984   \n",
       "2                                 -0.888064               62.459631   \n",
       "3                                 -1.921065               59.611631   \n",
       "4                                  0.512509               57.928350   \n",
       "..                                      ...                     ...   \n",
       "77                                -0.158855               17.978233   \n",
       "78                                 0.346526               14.611144   \n",
       "79                                -0.872505               21.551613   \n",
       "80                                -0.393141               20.200341   \n",
       "81                                 0.586280               14.468351   \n",
       "\n",
       "    Subiculum Grey Matter  Subiculum White Matter  Subiculum CSF  \\\n",
       "0                1.646994                0.510111       2.975675   \n",
       "1               -0.865158               -1.615736       0.740780   \n",
       "2                0.319460               -0.796399       0.532453   \n",
       "3               -0.440643               -0.159752       0.405263   \n",
       "4               -0.328427               -0.229875      -0.988805   \n",
       "..                    ...                     ...            ...   \n",
       "77                    NaN                     NaN            NaN   \n",
       "78                    NaN                     NaN            NaN   \n",
       "79                    NaN                     NaN            NaN   \n",
       "80                    NaN                     NaN            NaN   \n",
       "81                    NaN                     NaN            NaN   \n",
       "\n",
       "    Subiculum Total    Disease  Standardized Age  \\\n",
       "0          1.280978  Alzheimer          0.289341   \n",
       "1         -1.560273  Alzheimer         -0.016378   \n",
       "2         -0.341032  Alzheimer         -0.888064   \n",
       "3         -0.358042  Alzheimer         -1.921065   \n",
       "4         -0.339817  Alzheimer          0.512509   \n",
       "..              ...        ...               ...   \n",
       "77              NaN        NaN               NaN   \n",
       "78              NaN        NaN               NaN   \n",
       "79              NaN        NaN               NaN   \n",
       "80              NaN        NaN               NaN   \n",
       "81              NaN        NaN               NaN   \n",
       "\n",
       "    Standardized Percent Improvement  Standardized Subiculum Connectivity  \\\n",
       "0                           0.289341                            -1.179578   \n",
       "1                          -0.016378                            -1.635523   \n",
       "2                          -0.888064                            -0.524419   \n",
       "3                          -1.921065                            -0.857915   \n",
       "4                           0.512509                            -1.055024   \n",
       "..                               ...                                  ...   \n",
       "77                               NaN                                  NaN   \n",
       "78                               NaN                                  NaN   \n",
       "79                               NaN                                  NaN   \n",
       "80                               NaN                                  NaN   \n",
       "81                               NaN                                  NaN   \n",
       "\n",
       "    Standardized Subiculum Grey Matter  Standardized Subiculum White Matter  \\\n",
       "0                             1.970962                             0.663981   \n",
       "1                            -0.125938                            -1.611307   \n",
       "2                             0.862866                            -0.734373   \n",
       "3                             0.228406                            -0.052972   \n",
       "4                             0.322072                            -0.128024   \n",
       "..                                 ...                                  ...   \n",
       "77                                 NaN                                  NaN   \n",
       "78                                 NaN                                  NaN   \n",
       "79                                 NaN                                  NaN   \n",
       "80                                 NaN                                  NaN   \n",
       "81                                 NaN                                  NaN   \n",
       "\n",
       "    Standardized Subiculum CSF  Standardized Subiculum Total  Cohort  \n",
       "0                     1.773701                      1.789087       1  \n",
       "1                    -0.272553                     -1.093456       1  \n",
       "2                    -0.463295                      0.143505       1  \n",
       "3                    -0.579749                      0.126248       1  \n",
       "4                    -1.856148                      0.144737       1  \n",
       "..                         ...                           ...     ...  \n",
       "77                         NaN                           NaN       0  \n",
       "78                         NaN                           NaN       0  \n",
       "79                         NaN                           NaN       0  \n",
       "80                         NaN                           NaN       0  \n",
       "81                         NaN                           NaN       0  \n",
       "\n",
       "[82 rows x 18 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#always run this\n",
    "# trim the dataframe as needed\n",
    "row_to_stop_at = None\n",
    "col_to_stop_at = None\n",
    "\n",
    "#----------------------------------------------------------------Do Not Touch----------------------------------------------------------------\n",
    "if row_to_stop_at is not None:\n",
    "    pass\n",
    "else:\n",
    "    row_to_stop_at = pd.IndexSlice[:]\n",
    "    \n",
    "if col_to_stop_at is not None:\n",
    "    pass\n",
    "else:\n",
    "    col_to_stop_at = pd.IndexSlice[:]\n",
    "    \n",
    "data_df = data_df.loc[row_to_stop_at, col_to_stop_at].copy()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient # CDR, ADAS', 'Age', 'Percent Cognitive Improvement',\n",
       "       'Z-Scored Cognitive Improvement By Group', 'Subiculum Connectivity',\n",
       "       'Subiculum Grey Matter', 'Subiculum White Matter', 'Subiculum CSF',\n",
       "       'Subiculum Total', 'Disease', 'Standardized Age',\n",
       "       'Standardized Percent Improvement',\n",
       "       'Standardized Subiculum Connectivity',\n",
       "       'Standardized Subiculum Grey Matter',\n",
       "       'Standardized Subiculum White Matter', 'Standardized Subiculum CSF',\n",
       "       'Standardized Subiculum Total', 'Cohort'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient # CDR, ADAS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Percent Cognitive Improvement</th>\n",
       "      <th>Z-Scored Cognitive Improvement By Group</th>\n",
       "      <th>Subiculum Connectivity</th>\n",
       "      <th>Subiculum Grey Matter</th>\n",
       "      <th>Subiculum White Matter</th>\n",
       "      <th>Subiculum CSF</th>\n",
       "      <th>Subiculum Total</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Standardized Age</th>\n",
       "      <th>Standardized Percent Improvement</th>\n",
       "      <th>Standardized Subiculum Connectivity</th>\n",
       "      <th>Standardized Subiculum Grey Matter</th>\n",
       "      <th>Standardized Subiculum White Matter</th>\n",
       "      <th>Standardized Subiculum CSF</th>\n",
       "      <th>Standardized Subiculum Total</th>\n",
       "      <th>Cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>56.864683</td>\n",
       "      <td>1.646994</td>\n",
       "      <td>0.510111</td>\n",
       "      <td>2.975675</td>\n",
       "      <td>1.280978</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>0.289341</td>\n",
       "      <td>-1.179578</td>\n",
       "      <td>1.970962</td>\n",
       "      <td>0.663981</td>\n",
       "      <td>1.773701</td>\n",
       "      <td>1.789087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>52.970984</td>\n",
       "      <td>-0.865158</td>\n",
       "      <td>-1.615736</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>-1.560273</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-1.635523</td>\n",
       "      <td>-0.125938</td>\n",
       "      <td>-1.611307</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-1.093456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>62.459631</td>\n",
       "      <td>0.319460</td>\n",
       "      <td>-0.796399</td>\n",
       "      <td>0.532453</td>\n",
       "      <td>-0.341032</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>-0.888064</td>\n",
       "      <td>-0.524419</td>\n",
       "      <td>0.862866</td>\n",
       "      <td>-0.734373</td>\n",
       "      <td>-0.463295</td>\n",
       "      <td>0.143505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>59.611631</td>\n",
       "      <td>-0.440643</td>\n",
       "      <td>-0.159752</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>-0.358042</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>-1.921065</td>\n",
       "      <td>-0.857915</td>\n",
       "      <td>0.228406</td>\n",
       "      <td>-0.052972</td>\n",
       "      <td>-0.579749</td>\n",
       "      <td>0.126248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>57.928350</td>\n",
       "      <td>-0.328427</td>\n",
       "      <td>-0.229875</td>\n",
       "      <td>-0.988805</td>\n",
       "      <td>-0.339817</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>0.512509</td>\n",
       "      <td>-1.055024</td>\n",
       "      <td>0.322072</td>\n",
       "      <td>-0.128024</td>\n",
       "      <td>-1.856148</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-2.158273</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>17.978233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>0.346526</td>\n",
       "      <td>14.611144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.225352</td>\n",
       "      <td>-0.872505</td>\n",
       "      <td>21.551613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.836879</td>\n",
       "      <td>-0.393141</td>\n",
       "      <td>20.200341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>14.468351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient # CDR, ADAS   Age  Percent Cognitive Improvement  \\\n",
       "0                   101  62.0                     -21.428571   \n",
       "1                   102  77.0                     -36.363636   \n",
       "2                   103  76.0                     -78.947368   \n",
       "3                   104  65.0                    -129.411765   \n",
       "4                   105  50.0                     -10.526316   \n",
       "..                  ...   ...                            ...   \n",
       "77                   37  64.0                      -2.158273   \n",
       "78                   38   NaN                      -0.694444   \n",
       "79                   39   NaN                      -4.225352   \n",
       "80                   43   NaN                      -2.836879   \n",
       "81                   44   NaN                       0.000000   \n",
       "\n",
       "    Z-Scored Cognitive Improvement By Group  Subiculum Connectivity  \\\n",
       "0                                  0.289341               56.864683   \n",
       "1                                 -0.016378               52.970984   \n",
       "2                                 -0.888064               62.459631   \n",
       "3                                 -1.921065               59.611631   \n",
       "4                                  0.512509               57.928350   \n",
       "..                                      ...                     ...   \n",
       "77                                -0.158855               17.978233   \n",
       "78                                 0.346526               14.611144   \n",
       "79                                -0.872505               21.551613   \n",
       "80                                -0.393141               20.200341   \n",
       "81                                 0.586280               14.468351   \n",
       "\n",
       "    Subiculum Grey Matter  Subiculum White Matter  Subiculum CSF  \\\n",
       "0                1.646994                0.510111       2.975675   \n",
       "1               -0.865158               -1.615736       0.740780   \n",
       "2                0.319460               -0.796399       0.532453   \n",
       "3               -0.440643               -0.159752       0.405263   \n",
       "4               -0.328427               -0.229875      -0.988805   \n",
       "..                    ...                     ...            ...   \n",
       "77                    NaN                     NaN            NaN   \n",
       "78                    NaN                     NaN            NaN   \n",
       "79                    NaN                     NaN            NaN   \n",
       "80                    NaN                     NaN            NaN   \n",
       "81                    NaN                     NaN            NaN   \n",
       "\n",
       "    Subiculum Total    Disease  Standardized Age  \\\n",
       "0          1.280978  Alzheimer          0.289341   \n",
       "1         -1.560273  Alzheimer         -0.016378   \n",
       "2         -0.341032  Alzheimer         -0.888064   \n",
       "3         -0.358042  Alzheimer         -1.921065   \n",
       "4         -0.339817  Alzheimer          0.512509   \n",
       "..              ...        ...               ...   \n",
       "77              NaN        NaN               NaN   \n",
       "78              NaN        NaN               NaN   \n",
       "79              NaN        NaN               NaN   \n",
       "80              NaN        NaN               NaN   \n",
       "81              NaN        NaN               NaN   \n",
       "\n",
       "    Standardized Percent Improvement  Standardized Subiculum Connectivity  \\\n",
       "0                           0.289341                            -1.179578   \n",
       "1                          -0.016378                            -1.635523   \n",
       "2                          -0.888064                            -0.524419   \n",
       "3                          -1.921065                            -0.857915   \n",
       "4                           0.512509                            -1.055024   \n",
       "..                               ...                                  ...   \n",
       "77                               NaN                                  NaN   \n",
       "78                               NaN                                  NaN   \n",
       "79                               NaN                                  NaN   \n",
       "80                               NaN                                  NaN   \n",
       "81                               NaN                                  NaN   \n",
       "\n",
       "    Standardized Subiculum Grey Matter  Standardized Subiculum White Matter  \\\n",
       "0                             1.970962                             0.663981   \n",
       "1                            -0.125938                            -1.611307   \n",
       "2                             0.862866                            -0.734373   \n",
       "3                             0.228406                            -0.052972   \n",
       "4                             0.322072                            -0.128024   \n",
       "..                                 ...                                  ...   \n",
       "77                                 NaN                                  NaN   \n",
       "78                                 NaN                                  NaN   \n",
       "79                                 NaN                                  NaN   \n",
       "80                                 NaN                                  NaN   \n",
       "81                                 NaN                                  NaN   \n",
       "\n",
       "    Standardized Subiculum CSF  Standardized Subiculum Total  Cohort  \n",
       "0                     1.773701                      1.789087       1  \n",
       "1                    -0.272553                     -1.093456       1  \n",
       "2                    -0.463295                      0.143505       1  \n",
       "3                    -0.579749                      0.126248       1  \n",
       "4                    -1.856148                      0.144737       1  \n",
       "..                         ...                           ...     ...  \n",
       "77                         NaN                           NaN       0  \n",
       "78                         NaN                           NaN       0  \n",
       "79                         NaN                           NaN       0  \n",
       "80                         NaN                           NaN       0  \n",
       "81                         NaN                           NaN       0  \n",
       "\n",
       "[82 rows x 18 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_df.dropna(inplace=True)\n",
    "\n",
    "# data_df = data_df.fillna(method='pad')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Dataframe Rows by Value in a Given Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df[data_df['Cohort'] != 3]\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Patient # CDR, ADAS</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.243780e+02</td>\n",
       "      <td>217.580276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>109.500000</td>\n",
       "      <td>130.750000</td>\n",
       "      <td>1203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>76.0</td>\n",
       "      <td>6.430263e+01</td>\n",
       "      <td>9.143332</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent Cognitive Improvement</th>\n",
       "      <td>82.0</td>\n",
       "      <td>-2.234777e+01</td>\n",
       "      <td>41.511290</td>\n",
       "      <td>-207.692308</td>\n",
       "      <td>-36.722488</td>\n",
       "      <td>-4.286589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z-Scored Cognitive Improvement By Group</th>\n",
       "      <td>82.0</td>\n",
       "      <td>4.738757e-17</td>\n",
       "      <td>0.993808</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-0.386280</td>\n",
       "      <td>0.118857</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>1.844523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum Connectivity</th>\n",
       "      <td>82.0</td>\n",
       "      <td>4.971761e+01</td>\n",
       "      <td>23.063976</td>\n",
       "      <td>14.468351</td>\n",
       "      <td>24.295083</td>\n",
       "      <td>59.255681</td>\n",
       "      <td>69.680858</td>\n",
       "      <td>85.082502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum Grey Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-7.142802e-01</td>\n",
       "      <td>1.198031</td>\n",
       "      <td>-3.151819</td>\n",
       "      <td>-1.497430</td>\n",
       "      <td>-0.643373</td>\n",
       "      <td>-0.112465</td>\n",
       "      <td>3.146027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum White Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.102596e-01</td>\n",
       "      <td>0.934320</td>\n",
       "      <td>-1.729225</td>\n",
       "      <td>-0.818543</td>\n",
       "      <td>-0.141298</td>\n",
       "      <td>0.347720</td>\n",
       "      <td>2.569525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum CSF</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.038459e+00</td>\n",
       "      <td>1.092189</td>\n",
       "      <td>-1.421123</td>\n",
       "      <td>0.422337</td>\n",
       "      <td>0.752527</td>\n",
       "      <td>1.683734</td>\n",
       "      <td>3.926774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum Total</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-4.824810e-01</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>-2.254639</td>\n",
       "      <td>-1.156289</td>\n",
       "      <td>-0.401478</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>1.898799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Age</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.000000e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-0.523832</td>\n",
       "      <td>0.145158</td>\n",
       "      <td>0.657756</td>\n",
       "      <td>1.844523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Percent Improvement</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.000000e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-0.523832</td>\n",
       "      <td>0.145158</td>\n",
       "      <td>0.657756</td>\n",
       "      <td>1.844523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum Connectivity</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-8.000001e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.412986</td>\n",
       "      <td>-0.663002</td>\n",
       "      <td>0.055256</td>\n",
       "      <td>0.648596</td>\n",
       "      <td>2.124682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum Grey Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-8.881784e-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.034620</td>\n",
       "      <td>-0.653697</td>\n",
       "      <td>0.059187</td>\n",
       "      <td>0.502337</td>\n",
       "      <td>3.222209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum White Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.732774</td>\n",
       "      <td>-0.758074</td>\n",
       "      <td>-0.033221</td>\n",
       "      <td>0.490174</td>\n",
       "      <td>2.868167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum CSF</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-2.000004e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.251975</td>\n",
       "      <td>-0.564117</td>\n",
       "      <td>-0.261797</td>\n",
       "      <td>0.590809</td>\n",
       "      <td>2.644521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum Total</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.000002e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.797913</td>\n",
       "      <td>-0.683601</td>\n",
       "      <td>0.082181</td>\n",
       "      <td>0.494347</td>\n",
       "      <td>2.415888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <td>82.0</td>\n",
       "      <td>6.097561e-01</td>\n",
       "      <td>0.490807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count          mean         std  \\\n",
       "Patient # CDR, ADAS                       82.0  1.243780e+02  217.580276   \n",
       "Age                                       76.0  6.430263e+01    9.143332   \n",
       "Percent Cognitive Improvement             82.0 -2.234777e+01   41.511290   \n",
       "Z-Scored Cognitive Improvement By Group   82.0  4.738757e-17    0.993808   \n",
       "Subiculum Connectivity                    82.0  4.971761e+01   23.063976   \n",
       "Subiculum Grey Matter                     50.0 -7.142802e-01    1.198031   \n",
       "Subiculum White Matter                    50.0 -1.102596e-01    0.934320   \n",
       "Subiculum CSF                             50.0  1.038459e+00    1.092189   \n",
       "Subiculum Total                           50.0 -4.824810e-01    0.985675   \n",
       "Standardized Age                          50.0  2.000000e-11    1.000000   \n",
       "Standardized Percent Improvement          50.0  2.000000e-11    1.000000   \n",
       "Standardized Subiculum Connectivity       50.0 -8.000001e-11    1.000000   \n",
       "Standardized Subiculum Grey Matter        50.0 -8.881784e-18    1.000000   \n",
       "Standardized Subiculum White Matter       50.0  0.000000e+00    1.000000   \n",
       "Standardized Subiculum CSF                50.0 -2.000004e-11    1.000000   \n",
       "Standardized Subiculum Total              50.0  2.000002e-11    1.000000   \n",
       "Cohort                                    82.0  6.097561e-01    0.490807   \n",
       "\n",
       "                                                min        25%         50%  \\\n",
       "Patient # CDR, ADAS                        1.000000  28.250000  109.500000   \n",
       "Age                                       46.000000  58.000000   64.500000   \n",
       "Percent Cognitive Improvement           -207.692308 -36.722488   -4.286589   \n",
       "Z-Scored Cognitive Improvement By Group   -3.523461  -0.386280    0.118857   \n",
       "Subiculum Connectivity                    14.468351  24.295083   59.255681   \n",
       "Subiculum Grey Matter                     -3.151819  -1.497430   -0.643373   \n",
       "Subiculum White Matter                    -1.729225  -0.818543   -0.141298   \n",
       "Subiculum CSF                             -1.421123   0.422337    0.752527   \n",
       "Subiculum Total                           -2.254639  -1.156289   -0.401478   \n",
       "Standardized Age                          -3.523461  -0.523832    0.145158   \n",
       "Standardized Percent Improvement          -3.523461  -0.523832    0.145158   \n",
       "Standardized Subiculum Connectivity       -2.412986  -0.663002    0.055256   \n",
       "Standardized Subiculum Grey Matter        -2.034620  -0.653697    0.059187   \n",
       "Standardized Subiculum White Matter       -1.732774  -0.758074   -0.033221   \n",
       "Standardized Subiculum CSF                -2.251975  -0.564117   -0.261797   \n",
       "Standardized Subiculum Total              -1.797913  -0.683601    0.082181   \n",
       "Cohort                                     0.000000   0.000000    1.000000   \n",
       "\n",
       "                                                75%          max  \n",
       "Patient # CDR, ADAS                      130.750000  1203.000000  \n",
       "Age                                       72.000000    79.000000  \n",
       "Percent Cognitive Improvement              0.000000    54.545455  \n",
       "Z-Scored Cognitive Improvement By Group    0.586280     1.844523  \n",
       "Subiculum Connectivity                    69.680858    85.082502  \n",
       "Subiculum Grey Matter                     -0.112465     3.146027  \n",
       "Subiculum White Matter                     0.347720     2.569525  \n",
       "Subiculum CSF                              1.683734     3.926774  \n",
       "Subiculum Total                            0.004784     1.898799  \n",
       "Standardized Age                           0.657756     1.844523  \n",
       "Standardized Percent Improvement           0.657756     1.844523  \n",
       "Standardized Subiculum Connectivity        0.648596     2.124682  \n",
       "Standardized Subiculum Grey Matter         0.502337     3.222209  \n",
       "Standardized Subiculum White Matter        0.490174     2.868167  \n",
       "Standardized Subiculum CSF                 0.590809     2.644521  \n",
       "Standardized Subiculum Total               0.494347     2.415888  \n",
       "Cohort                                     1.000000     1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats = data_df.describe().transpose()\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize to Max Value in Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dz = data_df.pop('One Hot Disease'\n",
    "# )\n",
    "# age = data_df.pop('Age'\n",
    "# )\n",
    "# for col in data_df.columns.to_list():\n",
    "#     try:\n",
    "#         df_1[col] = (data_df[col])/(data_df[col].max())\n",
    "#     except:\n",
    "#         print(f'Cannot normalize {col}')\n",
    "# data_df['Age'] = age\n",
    "# data_df['One Hot Disease'] = dz\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df['autocog_status'] = np.where(data_df['Total'] < 82/100, 1, 0)\n",
    "# data_df['ace_status'] = np.where(data_df['Total'] < 82/100, 1, 0)\n",
    "# data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Patient # CDR, ADAS</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.243780e+02</td>\n",
       "      <td>217.580276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>109.500000</td>\n",
       "      <td>130.750000</td>\n",
       "      <td>1203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>76.0</td>\n",
       "      <td>6.430263e+01</td>\n",
       "      <td>9.143332</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent Cognitive Improvement</th>\n",
       "      <td>82.0</td>\n",
       "      <td>-2.234777e+01</td>\n",
       "      <td>41.511290</td>\n",
       "      <td>-207.692308</td>\n",
       "      <td>-36.722488</td>\n",
       "      <td>-4.286589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z-Scored Cognitive Improvement By Group</th>\n",
       "      <td>82.0</td>\n",
       "      <td>4.738757e-17</td>\n",
       "      <td>0.993808</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-0.386280</td>\n",
       "      <td>0.118857</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>1.844523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum Connectivity</th>\n",
       "      <td>82.0</td>\n",
       "      <td>4.971761e+01</td>\n",
       "      <td>23.063976</td>\n",
       "      <td>14.468351</td>\n",
       "      <td>24.295083</td>\n",
       "      <td>59.255681</td>\n",
       "      <td>69.680858</td>\n",
       "      <td>85.082502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum Grey Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-7.142802e-01</td>\n",
       "      <td>1.198031</td>\n",
       "      <td>-3.151819</td>\n",
       "      <td>-1.497430</td>\n",
       "      <td>-0.643373</td>\n",
       "      <td>-0.112465</td>\n",
       "      <td>3.146027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum White Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.102596e-01</td>\n",
       "      <td>0.934320</td>\n",
       "      <td>-1.729225</td>\n",
       "      <td>-0.818543</td>\n",
       "      <td>-0.141298</td>\n",
       "      <td>0.347720</td>\n",
       "      <td>2.569525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum CSF</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.038459e+00</td>\n",
       "      <td>1.092189</td>\n",
       "      <td>-1.421123</td>\n",
       "      <td>0.422337</td>\n",
       "      <td>0.752527</td>\n",
       "      <td>1.683734</td>\n",
       "      <td>3.926774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subiculum Total</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-4.824810e-01</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>-2.254639</td>\n",
       "      <td>-1.156289</td>\n",
       "      <td>-0.401478</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>1.898799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Age</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.000000e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-0.523832</td>\n",
       "      <td>0.145158</td>\n",
       "      <td>0.657756</td>\n",
       "      <td>1.844523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Percent Improvement</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.000000e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.523461</td>\n",
       "      <td>-0.523832</td>\n",
       "      <td>0.145158</td>\n",
       "      <td>0.657756</td>\n",
       "      <td>1.844523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum Connectivity</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-8.000001e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.412986</td>\n",
       "      <td>-0.663002</td>\n",
       "      <td>0.055256</td>\n",
       "      <td>0.648596</td>\n",
       "      <td>2.124682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum Grey Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-8.881784e-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.034620</td>\n",
       "      <td>-0.653697</td>\n",
       "      <td>0.059187</td>\n",
       "      <td>0.502337</td>\n",
       "      <td>3.222209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum White Matter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.732774</td>\n",
       "      <td>-0.758074</td>\n",
       "      <td>-0.033221</td>\n",
       "      <td>0.490174</td>\n",
       "      <td>2.868167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum CSF</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-2.000004e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.251975</td>\n",
       "      <td>-0.564117</td>\n",
       "      <td>-0.261797</td>\n",
       "      <td>0.590809</td>\n",
       "      <td>2.644521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized Subiculum Total</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.000002e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.797913</td>\n",
       "      <td>-0.683601</td>\n",
       "      <td>0.082181</td>\n",
       "      <td>0.494347</td>\n",
       "      <td>2.415888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <td>82.0</td>\n",
       "      <td>6.097561e-01</td>\n",
       "      <td>0.490807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count          mean         std  \\\n",
       "Patient # CDR, ADAS                       82.0  1.243780e+02  217.580276   \n",
       "Age                                       76.0  6.430263e+01    9.143332   \n",
       "Percent Cognitive Improvement             82.0 -2.234777e+01   41.511290   \n",
       "Z-Scored Cognitive Improvement By Group   82.0  4.738757e-17    0.993808   \n",
       "Subiculum Connectivity                    82.0  4.971761e+01   23.063976   \n",
       "Subiculum Grey Matter                     50.0 -7.142802e-01    1.198031   \n",
       "Subiculum White Matter                    50.0 -1.102596e-01    0.934320   \n",
       "Subiculum CSF                             50.0  1.038459e+00    1.092189   \n",
       "Subiculum Total                           50.0 -4.824810e-01    0.985675   \n",
       "Standardized Age                          50.0  2.000000e-11    1.000000   \n",
       "Standardized Percent Improvement          50.0  2.000000e-11    1.000000   \n",
       "Standardized Subiculum Connectivity       50.0 -8.000001e-11    1.000000   \n",
       "Standardized Subiculum Grey Matter        50.0 -8.881784e-18    1.000000   \n",
       "Standardized Subiculum White Matter       50.0  0.000000e+00    1.000000   \n",
       "Standardized Subiculum CSF                50.0 -2.000004e-11    1.000000   \n",
       "Standardized Subiculum Total              50.0  2.000002e-11    1.000000   \n",
       "Cohort                                    82.0  6.097561e-01    0.490807   \n",
       "\n",
       "                                                min        25%         50%  \\\n",
       "Patient # CDR, ADAS                        1.000000  28.250000  109.500000   \n",
       "Age                                       46.000000  58.000000   64.500000   \n",
       "Percent Cognitive Improvement           -207.692308 -36.722488   -4.286589   \n",
       "Z-Scored Cognitive Improvement By Group   -3.523461  -0.386280    0.118857   \n",
       "Subiculum Connectivity                    14.468351  24.295083   59.255681   \n",
       "Subiculum Grey Matter                     -3.151819  -1.497430   -0.643373   \n",
       "Subiculum White Matter                    -1.729225  -0.818543   -0.141298   \n",
       "Subiculum CSF                             -1.421123   0.422337    0.752527   \n",
       "Subiculum Total                           -2.254639  -1.156289   -0.401478   \n",
       "Standardized Age                          -3.523461  -0.523832    0.145158   \n",
       "Standardized Percent Improvement          -3.523461  -0.523832    0.145158   \n",
       "Standardized Subiculum Connectivity       -2.412986  -0.663002    0.055256   \n",
       "Standardized Subiculum Grey Matter        -2.034620  -0.653697    0.059187   \n",
       "Standardized Subiculum White Matter       -1.732774  -0.758074   -0.033221   \n",
       "Standardized Subiculum CSF                -2.251975  -0.564117   -0.261797   \n",
       "Standardized Subiculum Total              -1.797913  -0.683601    0.082181   \n",
       "Cohort                                     0.000000   0.000000    1.000000   \n",
       "\n",
       "                                                75%          max  \n",
       "Patient # CDR, ADAS                      130.750000  1203.000000  \n",
       "Age                                       72.000000    79.000000  \n",
       "Percent Cognitive Improvement              0.000000    54.545455  \n",
       "Z-Scored Cognitive Improvement By Group    0.586280     1.844523  \n",
       "Subiculum Connectivity                    69.680858    85.082502  \n",
       "Subiculum Grey Matter                     -0.112465     3.146027  \n",
       "Subiculum White Matter                     0.347720     2.569525  \n",
       "Subiculum CSF                              1.683734     3.926774  \n",
       "Subiculum Total                            0.004784     1.898799  \n",
       "Standardized Age                           0.657756     1.844523  \n",
       "Standardized Percent Improvement           0.657756     1.844523  \n",
       "Standardized Subiculum Connectivity        0.648596     2.124682  \n",
       "Standardized Subiculum Grey Matter         0.502337     3.222209  \n",
       "Standardized Subiculum White Matter        0.490174     2.868167  \n",
       "Standardized Subiculum CSF                 0.590809     2.644521  \n",
       "Standardized Subiculum Total               0.494347     2.415888  \n",
       "Cohort                                     1.000000     1.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats = data_df.describe().transpose()\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient # CDR, ADAS', 'Age', 'Percent Cognitive Improvement',\n",
       "       'Z-Scored Cognitive Improvement By Group', 'Subiculum Connectivity',\n",
       "       'Subiculum Grey Matter', 'Subiculum White Matter', 'Subiculum CSF',\n",
       "       'Subiculum Total', 'Disease', 'Standardized Age',\n",
       "       'Standardized Percent Improvement',\n",
       "       'Standardized Subiculum Connectivity',\n",
       "       'Standardized Subiculum Grey Matter',\n",
       "       'Standardized Subiculum White Matter', 'Standardized Subiculum CSF',\n",
       "       'Standardized Subiculum Total', 'Cohort'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.rename(columns={\"Convolutional Neural Network Equivalent\": \"Paper Test\"}, inplace=True)\n",
    "data_df.rename(columns={\"Convolutional Neural Network\": \"RoCA\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "def plot_with_annotation(dataframe, col1, col2, xlabel, ylabel, test_type, colours):\n",
    "    # Validate the test type\n",
    "    valid_tests = ['t-test_ind', 't-test_paired', 'Mann-Whitney', 'Wilcoxon']\n",
    "    if test_type not in valid_tests:\n",
    "        raise ValueError(f\"Invalid test type. Choose from: {', '.join(valid_tests)}\")\n",
    "    \n",
    "    # Extract series\n",
    "    series1 = dataframe[col1]\n",
    "    series2 = dataframe[col2]\n",
    "    \n",
    "    # Prepare data\n",
    "    data = pd.DataFrame({'Group': [col1] * len(series1) + [col2] * len(series2),\n",
    "                         'Value': series1.tolist() + series2.tolist()})\n",
    "    \n",
    "    # Pairs for comparison\n",
    "    pairs = [(col1, col2)]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(6.5, 2.5))\n",
    "    \n",
    "    sns.set_palette(colours, 2, desat=1)\n",
    "    \n",
    "    # Plot with seaborn\n",
    "    sns.boxplot(x='Group', y='Value', data=data, ax=ax)\n",
    "    \n",
    "    # Add annotations\n",
    "    annotator = Annotator(ax=ax,\n",
    "                          data=data,\n",
    "                          x='Group',\n",
    "                          y='Value',\n",
    "                          pairs=pairs,\n",
    "                          test=test_type,\n",
    "                          text_format='full',\n",
    "                          loc='inside',\n",
    "                          verbose=2)\n",
    "    \n",
    "    # Configure and annotate\n",
    "    _, corrected_results = annotator.configure(test=test_type, comparisons_correction=\"bonferroni\").apply_and_annotate()\n",
    "    \n",
    "    # Label and show plot\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient # CDR, ADAS', 'Age', 'Percent Cognitive Improvement',\n",
       "       'Z-Scored Cognitive Improvement By Group', 'Subiculum Connectivity',\n",
       "       'Subiculum Grey Matter', 'Subiculum White Matter', 'Subiculum CSF',\n",
       "       'Subiculum Total', 'Disease', 'Standardized Age',\n",
       "       'Standardized Percent Improvement',\n",
       "       'Standardized Subiculum Connectivity',\n",
       "       'Standardized Subiculum Grey Matter',\n",
       "       'Standardized Subiculum White Matter', 'Standardized Subiculum CSF',\n",
       "       'Standardized Subiculum Total', 'Cohort'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_col_name = 'Paper Test'\n",
    "group2_col_name = 'RoCA'\n",
    "x_label = 'Test Type'\n",
    "y_label = 'Test Score'\n",
    "test_type = 't-test_paired'\n",
    "#----------------------------------------------------------------\n",
    "plt = plot_with_annotation(dataframe=data_df, \n",
    "                           col1=group1_col_name, \n",
    "                           col2=group2_col_name,\n",
    "                           xlabel=x_label, \n",
    "                           ylabel=y_label, \n",
    "                           test_type=test_type,\n",
    "                           colours='tab10')\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, 'distribution_figures'), exist_ok=True)\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/{group1_col_name}_{test_type}_{group2_col_name}.png'))\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/{group1_col_name}_{test_type}_{group2_col_name}.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, f'distribution_figures/{group1_col_name}_{test_type}_{group2_col_name}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Multiple Distribution Tests and Correct for Multiple Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a detailed description of the `plot_distribution_tests` function.\n",
    "\n",
    "### `plot_distribution_tests` Function\n",
    "\n",
    "This function creates a plot of distribution tests with optional annotations for multiple key-value pair comparisons.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- `dataframe`: A pandas DataFrame containing the data for comparison.\n",
    "- `comparisons_dict`: A dictionary mapping comparisons with keys and values representing column names in the DataFrame.\n",
    "- `test_type`: Specifies the statistical method used for testing. Available options are:\n",
    "  - `'t-test_ind'`: Independent t-test\n",
    "  - `'t-test_paired'`: Paired t-test\n",
    "  - `'Mann-Whitney'`: Mann-Whitney U test\n",
    "  - `'Wilcoxon'`: Wilcoxon signed-rank test\n",
    "- `correction_method`: Specifies the method used to correct for multiple comparisons. Available options are:\n",
    "  - `'bonferroni'`: Bonferroni correction\n",
    "  - `'holm'`: Holm's correction\n",
    "  - `'fdr_bh'`: Benjamini-Hochberg false discovery rate correction\n",
    "- `key_label`: A string label for the keys in the plot.\n",
    "- `value_label`: A string label for the values in the plot.\n",
    "- `x_label`: Label for the x-axis.\n",
    "- `y_label`: Label for the y-axis.\n",
    "- `display`: Controls how the keys and values are displayed. Available options are:\n",
    "  - `'split_pairs'`: Displays keys and values side by side, with keys on the left and values on the right.\n",
    "  - `'group_pairs'`: Groups the key-value pairs together.\n",
    "- `full_legend_patches`: A boolean that controls the appearance of the legend. If `True`, full key-value pairs are shown in the legend; if `False`, only keys are shown.\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- A matplotlib plot object.\n",
    "\n",
    "#### Example Usage\n",
    "\n",
    "```python\n",
    "comparisons_dict = {\n",
    "    'Attention': 'Attention.1',\n",
    "    'Memory': 'Memory.1',\n",
    "    'Language': 'Language.1',\n",
    "    'Fluency': 'Fluency.1',\n",
    "    'Visuospatial': 'Visuospatial.1',\n",
    "}\n",
    "test_type = 'Mann-Whitney'\n",
    "correction_method = 'bonferroni'\n",
    "key_label = 'Keys'\n",
    "value_label = 'Values'\n",
    "x_label = 'Metrics'\n",
    "y_label = 'Values'\n",
    "\n",
    "plt = plot_distribution_tests(dataframe=data_df,\n",
    "                              comparisons_dict=comparisons_dict, \n",
    "                              test_type=test_type, \n",
    "                              correction_method=correction_method,\n",
    "                              key_label=key_label,\n",
    "                              value_label=value_label,\n",
    "                              x_label=x_label,\n",
    "                              y_label=y_label)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- The `test_type` and `correction_method` must be chosen from the available options; otherwise, a `ValueError` will be raised.\n",
    "- The function supports customization of the plot appearance, including color mapping, annotations, and more, to suit various use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_distribution_tests(dataframe, comparisons_dict, test_type, correction_method, key_label, value_label, x_label, y_label, display='split_pairs', full_legend_patches=False):\n",
    "    valid_tests = ['t-test_ind', 't-test_paired', 'Mann-Whitney', 'Wilcoxon']\n",
    "    valid_corrections = ['bonferroni', 'holm', 'fdr_bh']\n",
    "    if test_type not in valid_tests:\n",
    "        raise ValueError(f\"Invalid test type. Choose from: {', '.join(valid_tests)}\")\n",
    "    if correction_method not in valid_corrections:\n",
    "        raise ValueError(f\"Invalid correction method. Choose from: {', '.join(valid_corrections)}\")\n",
    "\n",
    "    # Create a color palette with enough unique colors\n",
    "    colors = sns.color_palette(\"tab10\", len(comparisons_dict))\n",
    "\n",
    "    # Create a new DataFrame to hold the data for plotting\n",
    "    data = pd.DataFrame(columns=['GroupType', 'Metric', 'Value'])\n",
    "    pairs = []\n",
    "    # Create legend patches\n",
    "    legend_patches = []\n",
    "\n",
    "    # Iterate through comparisons_dict\n",
    "    for idx, (key, value) in enumerate(comparisons_dict.items()):\n",
    "        key_series = dataframe[key]\n",
    "        value_series = dataframe[value]\n",
    "        color = colors[idx]\n",
    "        temp_data = pd.DataFrame({\n",
    "            'GroupType': [f'Key'] * len(key_series) + [f'Value'] * len(value_series),\n",
    "            'Metric': [key] * len(key_series) + [value] * len(value_series),\n",
    "            'Value': key_series.tolist() + value_series.tolist(),\n",
    "            'Color': [color] * (len(key_series) + len(value_series))\n",
    "        })\n",
    "        data = pd.concat([data, temp_data], axis=0)\n",
    "        pairs.append(((key, 'Key'), (value, 'Value')))\n",
    "        \n",
    "        if full_legend_patches:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{key} vs {value}'))\n",
    "        else:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{value}'))\n",
    "\n",
    "    # Map colour\n",
    "    palette_mapping = {row['Metric']: row['Color'] for _, row in data.iterrows()}\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(len(comparisons_dict)*1.3, 5))\n",
    "    # Add annotations\n",
    "    if display=='group_pairs':\n",
    "        # Plot with seaborn (split image)\n",
    "        sns.set_style('white')\n",
    "        palette = sns.color_palette('tab10', 2, desat=1)  # Define palette with 2 colors\n",
    "        sns.set_palette(palette)\n",
    "        ax = sns.boxplot(x='Metric', y='Value', hue='GroupType', data=data, ax=ax, palette=palette)\n",
    "        \n",
    "        # Define the Legend\n",
    "        key_color = palette[0]  # Color for the 'Key' group\n",
    "        value_color = palette[1]  # Color for the 'Value' group\n",
    "        legend_patches = [mpatches.Patch(color=key_color, label=key_label),\n",
    "                        mpatches.Patch(color=value_color, label=value_label)]\n",
    "        \n",
    "        # Add annotations\n",
    "        annotator = Annotator(ax=ax,\n",
    "                              data=data,\n",
    "                              x='Metric',\n",
    "                              y='Value',\n",
    "                              hue='GroupType',\n",
    "                              pairs=pairs,\n",
    "                              test=test_type,\n",
    "                              text_format='full',\n",
    "                              loc='inside',\n",
    "                              verbose=2)\n",
    "        x_labels = ['Question ' + pair[0][0].split('_')[2] for pair in pairs]\n",
    "        result = [' '] * (len(x_labels) * 2)\n",
    "        result[0::2] = x_labels\n",
    "        x_labels = result\n",
    "        x_ticks = [i for i in range(0, len(pairs)*2)]\n",
    "        plt.xticks(ticks=x_ticks, labels=x_labels)\n",
    "    elif display=='split_pairs':\n",
    "        # Plot with seaborn (side-by-side)\n",
    "        ax = sns.boxplot(x='GroupType', y='Value', hue='Metric', data=data, ax=ax, palette={row['Metric']: row['Color'] for _, row in data.iterrows()})\n",
    "        # Adjust pairs for side-by-side\n",
    "        pairs = [(('Key', col1), ('Value', col2)) for col1, col2 in comparisons_dict.items()]\n",
    "        # Add annotations\n",
    "        annotator = Annotator(ax=ax,\n",
    "                              data=data,\n",
    "                              x='GroupType',\n",
    "                              y='Value',\n",
    "                              hue='Metric',\n",
    "                              pairs=pairs,\n",
    "                              test=test_type,\n",
    "                              text_format='full',\n",
    "                              loc='outside',\n",
    "                              verbose=1)\n",
    "        x_labels = [key_label] + [value_label]\n",
    "        plt.xticks(ticks=range(len(x_labels)), labels=x_labels)\n",
    "    else:\n",
    "        raise ValueError(f'display {display} not supported please choose \"split_pairs\" or \"group_pairs\"')\n",
    "\n",
    "    # Configure and annotate\n",
    "    _, corrected_results = annotator.configure(test=test_type, comparisons_correction=correction_method).apply_and_annotate()\n",
    "\n",
    "    # Label and show plot\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.title(f'Distribution Test: {test_type} with {correction_method} correction')\n",
    "    plt.legend(handles=legend_patches, frameon=False, loc=(0.025, 0.05))\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_dict = {'ACE3_Question_2': 'Question_2', 'ACE3_Question_3': 'Question_3', 'ACE3_Question_4': 'Question_4', 'ACE3_Question_5': 'Question_5', 'ACE3_Question_6': 'Question_6', 'ACE3_Question_7': 'Question_7', 'ACE3_Question_8': 'Question_8', 'ACE3_Question_9': 'Question_9', 'ACE3_Question_10': 'Question_10', 'ACE3_Question_11': 'Question_11', 'ACE3_Question_12': 'Question_12', 'ACE3_Question_13': 'Question_13', 'ACE3_Question_14': 'Question_14', 'ACE3_Question_15': 'Question_15', 'ACE3_Question_16': 'Question_16', 'ACE3_Question_17': 'Question_17', 'ACE3_Question_18': 'Question_18', 'ACE3_Question_19': 'Question_19', 'ACE3_Question_20': 'Question_20'}\n",
    "test_type = 'Wilcoxon'\n",
    "correction_method = 'bonferroni'\n",
    "key_label = 'Paper'\n",
    "value_label = 'Autonomous'\n",
    "x_label = 'Question'\n",
    "y_label = 'Score'\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "plt = plot_distribution_tests(dataframe=data_df,\n",
    "                        comparisons_dict=comparisons_dict, \n",
    "                        test_type=test_type, \n",
    "                        correction_method=correction_method,\n",
    "                        key_label=key_label, \n",
    "                        value_label=value_label, \n",
    "                        x_label=x_label, \n",
    "                        y_label=y_label,\n",
    "                        display='group_pairs')\n",
    "plt\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, 'distribution_figures'), exist_ok=True)\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/{test_type}_{correction_method}_multiple_comparison_barplot.png'))\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/{test_type}_{correction_method}_multiple_comparison_barplot_barplot.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, f'icc_figures/{test_type}_{correction_method}_multiple_comparison_barplot')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman/Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau\n",
    "from natsort import index_natsorted\n",
    "\n",
    "# Correcting the function to remove natural sorting and ensure DataFrame is passed\n",
    "\n",
    "def generate_scatterplot(dataframe, data_dict, columns_per_row=4, x_label='xlabel', y_label='ylabel', correlation='pearson', palette='Greys'):\n",
    "    '''\n",
    "    Generate scatterplots with specified correlation coefficient annotated.\n",
    "\n",
    "    :param dataframe: DataFrame containing the data\n",
    "    :param data_dict: Dictionary where key is the dependent variable name, and value is a list of independent variable names\n",
    "    :param columns_per_row: Number of columns per row in the facet plot\n",
    "    :param x_label: Label for the x-axis\n",
    "    :param y_label: Label for the y-axis\n",
    "    :param correlation: method of correlation ('pearson', 'spearman', 'kendall')\n",
    "    :return: Facet plot\n",
    "    '''\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette(palette, 1, desat=1)\n",
    "    \n",
    "    for dependent_var, independent_vars in data_dict.items():\n",
    "        # Melt the DataFrame for each dependent variable\n",
    "        melted_df = pd.melt(dataframe, id_vars=[dependent_var], value_vars=independent_vars,\n",
    "                            var_name='independent_variable_name', value_name='independent_variable_units')\n",
    "\n",
    "        # Sort the DataFrame\n",
    "        melted_df = melted_df.sort_values(by='independent_variable_name')\n",
    "\n",
    "        # Begin plotting\n",
    "        facet_plot = sns.lmplot(y=dependent_var, x='independent_variable_units', data=melted_df,\n",
    "                                col='independent_variable_name', truncate=False, col_wrap=columns_per_row,\n",
    "                                facet_kws=dict(sharex=False, sharey=True))\n",
    "\n",
    "        # Calculate correlation for each cluster\n",
    "        grouped_df = melted_df.groupby('independent_variable_name')\n",
    "        \n",
    "        if correlation == 'pearson':\n",
    "            result = grouped_df.apply(lambda x: pearsonr(x['independent_variable_units'], x[dependent_var]))\n",
    "        elif correlation == 'spearman':\n",
    "            result = grouped_df.apply(lambda x: spearmanr(x['independent_variable_units'], x[dependent_var]))\n",
    "        elif correlation == 'kendall':\n",
    "            result = grouped_df.apply(lambda x: kendalltau(x['independent_variable_units'], x[dependent_var]))\n",
    "        else:\n",
    "            raise ValueError(f'Correlation {correlation} not specified, please select \"pearson\", \"kendall\" or \"spearman\"')\n",
    "\n",
    "        # Annotate with correlation\n",
    "        for ax in facet_plot.axes:\n",
    "            # Get the title of the current subplot\n",
    "            region = ax.get_title().split(\"=\")[-1].strip()\n",
    "            # Get the corresponding r, p values from the result\n",
    "            r, p = result[region]\n",
    "            ax.set_title(region)\n",
    "            ax.annotate(f\"r = {r:.2f}, p = {p:.5f}\", xy=(.5, 1.0), xycoords='axes fraction',\n",
    "                        xytext=(0, 0), textcoords='offset points', ha='center', va='top',\n",
    "                        bbox=dict(boxstyle='round,pad=0.0', alpha=0.0),\n",
    "                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "            \n",
    "        facet_plot.set_xlabels(x_label)\n",
    "        facet_plot.set_ylabels(y_label)\n",
    "        return facet_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient # CDR, ADAS', 'Age', 'Percent Cognitive Improvement',\n",
       "       'Z-Scored Cognitive Improvement By Group', 'Subiculum Connectivity',\n",
       "       'Subiculum Grey Matter', 'Subiculum White Matter', 'Subiculum CSF',\n",
       "       'Subiculum Total', 'Disease', 'Standardized Age',\n",
       "       'Standardized Percent Improvement',\n",
       "       'Standardized Subiculum Connectivity',\n",
       "       'Standardized Subiculum Grey Matter',\n",
       "       'Standardized Subiculum White Matter', 'Standardized Subiculum CSF',\n",
       "       'Standardized Subiculum Total', 'Cohort'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to:  /Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/scatterplot_analysis/scatterplot_figures/Connectivity_to_Z-Scored Percent Cognitive Improvement\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_correlate_to = 'Z-Scored Cognitive Improvement By Group'\n",
    "columns_to_correlate_list = [\n",
    " 'Subiculum Connectivity',\n",
    "]\n",
    "x_label = 'Connectivity'\n",
    "y_label = 'Z-Scored Percent Cognitive Improvement'\n",
    "correlation = 'spearman'\n",
    "\n",
    "#---------\n",
    "plot = generate_scatterplot(dataframe=data_df, \n",
    "                     data_dict={columns_to_correlate_to:columns_to_correlate_list}, \n",
    "                     x_label=x_label, \n",
    "                     y_label=y_label,\n",
    "                     correlation=correlation,\n",
    "                     palette='Greys')\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, 'scatterplot_figures'), exist_ok=True)\n",
    "plot.savefig(os.path.join(out_dir, f'scatterplot_figures/{x_label}_to_{y_label}.png'))\n",
    "plot.savefig(os.path.join(out_dir, f'scatterplot_figures/{x_label}_to_{y_label}.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, f'scatterplot_figures/{x_label}_to_{y_label}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intraclass Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "def calculate_icc(series1, series2):\n",
    "    # Combine the series into a DataFrame\n",
    "    df = series1.to_frame(name='rating1')\n",
    "    df['rating2'] = series2\n",
    "\n",
    "    # Melt the DataFrame to long format\n",
    "    df_melted = df.melt(value_vars=['rating1', 'rating2'], var_name='rater', value_name='rating')\n",
    "\n",
    "    # Add a subject column\n",
    "    df_melted['subject'] = df_melted.groupby('rater').cumcount()\n",
    "\n",
    "    # Calculate ICC\n",
    "    icc_result = pg.intraclass_corr(data=df_melted, targets='subject', raters='rater', ratings='rating')\n",
    "    \n",
    "    # You can choose the ICC type you want, here I'm returning ICC(3,1)\n",
    "    return icc_result.set_index('Type').loc['ICC3', 'ICC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.loc[:34, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8069099630517919"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc = calculate_icc(data_df['Total'], data_df['ACE_Total'])\n",
    "icc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped ICC 95% Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pingouin import intraclass_corr\n",
    "from calvin_utils.statistical_utils.distribution_statistics import BootstrappedDistributionStatistics\n",
    "from calvin_utils.statistical_utils.resampling_functions import Bootstrap\n",
    "\n",
    "def calculate_icc(df, col1, col2):\n",
    "    # Select only the specified columns and rename them for compatibility with pingouin\n",
    "    data = df[[col1, col2]].rename(columns={col1: 'rating1', col2: 'rating2'})\n",
    "\n",
    "    # Reshape data for pingouin's intraclass_corr function\n",
    "    df_melted = data.melt(value_vars=['rating1', 'rating2'], var_name='rater', value_name='rating')\n",
    "    df_melted['subject'] = df_melted.groupby('rater').cumcount()\n",
    "\n",
    "    # Calculate ICC\n",
    "    icc_result = intraclass_corr(data=df_melted, targets='subject', raters='rater', ratings='rating')\n",
    "    \n",
    "    # Return ICC(3,1)\n",
    "    return icc_result.set_index('Type').loc['ICC3', 'ICC']\n",
    "\n",
    "def bootstrap_icc(data, col1, col2, bootstrap_samples=2500):\n",
    "    # Perform the bootstrap resampling using the Bootstrap class\n",
    "    bootstrap = Bootstrap(data=data, func=calculate_icc, func_args={'col1': col1, 'col2': col2}, bootstrap_samples=bootstrap_samples)\n",
    "    bootstrap_results = bootstrap.bootstrap_function()\n",
    "\n",
    "    # Calculate the confidence intervals using the BootstrappedDistributionStatistics class\n",
    "    distribution_statistics = BootstrappedDistributionStatistics(bootstrap_results)\n",
    "    lower_bound, upper_bound = distribution_statistics.percentile_ci(alpha=0.05)\n",
    "\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [07:03<00:00, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6774809892510312 0.9085213429356002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lower_bound, upper_bound = bootstrap_icc(data=data_df, col1='Total', col2='ACE_Total', bootstrap_samples=10000)\n",
    "print(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Split Between Correlation of Variables\n",
    "\n",
    "The ScatterWithConfidence class is designed to generate scatter plots with associated confidence intervals and permutation-based p-values. It creates plots of two variables and segregates them by a specified criterion, such as age. These plots are further enhanced by overlaying regression lines with their associated confidence intervals. The class can also perform permutation tests to compute a p-value, which is then prominently displayed in the plot title.\n",
    "\n",
    "Attributes:\n",
    "data_df (pandas.DataFrame): The main dataframe containing the data intended for plotting.\n",
    "Key Methods:\n",
    "1. compute_analytic_confidence_interval(x, y, x_vals)\n",
    "Purpose: Computes the regression line and its 95% confidence intervals using analytic methods.\n",
    "Parameters:\n",
    "x (pandas.Series): The x-values of the data.\n",
    "y (pandas.Series): The y-values of the data.\n",
    "x_vals (numpy.ndarray): The x-values where the regression line and confidence intervals should be computed.\n",
    "Returns:\n",
    "y_fit: Regression line values.\n",
    "lower_bound: Lower 95% confidence interval.\n",
    "upper_bound: Upper 95% confidence interval.\n",
    "2. permute_data_and_difference_in_pearson_r(...)\n",
    "Purpose: Computes the difference in Pearson R between two groups using permutation tests.\n",
    "Parameters:\n",
    "x_one, x_two (str): Column names of the two variables to be correlated.\n",
    "split_by (str): Column name used to segregate the data.\n",
    "split_value (float): The criterion value for data segregation.\n",
    "n_permutations (int, optional): Number of permutations to perform (default is 1000).\n",
    "permute_columns (list of str, optional): List of column names to be permuted.\n",
    "Returns:\n",
    "original_diff: Difference in Pearson R of the original data between two groups.\n",
    "p_value: Permutation-based p-value.\n",
    "3. plot_with_analytic_ci_manual_pvalue(...)\n",
    "Purpose: Generates a scatter plot with regression lines, confidence intervals, and the permutation-based p-value in the title.\n",
    "Parameters:\n",
    "x_one, x_two (str): Column names of the two variables for plotting.\n",
    "split_by (str): Column name for data segregation.\n",
    "... (Other parameters for customization, saving, etc.)\n",
    "Returns:\n",
    "A matplotlib scatter plot.\n",
    "To utilize this class:\n",
    "\n",
    "Initialize the class with your dataset.\n",
    "Use the methods described above to compute confidence intervals or perform permutation tests.\n",
    "Generate and visualize your enhanced scatter plot using the provided methods.\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "scatter_plotter = ScatterWithConfidence(data_df)\n",
    "scatter_plotter.plot_with_analytic_ci_manual_pvalue(...)\n",
    "Remember to replace ... with appropriate arguments as your situation demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the class and its methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "import seaborn as sns\n",
    "class ScatterWithConfidence:\n",
    "    def __init__(self, data_df):\n",
    "        self.data_df = data_df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_analytic_confidence_interval(x, y, x_vals):\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        y_fit = slope * x_vals + intercept\n",
    "        \n",
    "        residuals = y - (slope * x + intercept)\n",
    "        stderr = np.sqrt(np.sum(residuals**2) / (len(y) - 2))\n",
    "        \n",
    "        t_value = t.ppf(0.975, df=len(x)-2)\n",
    "        ci = t_value * stderr * np.sqrt(1/len(x) + (x_vals - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "        \n",
    "        upper_bound = y_fit + ci\n",
    "        lower_bound = y_fit - ci\n",
    "        \n",
    "        return y_fit, lower_bound, upper_bound\n",
    "\n",
    "    def permute_data_and_difference_in_pearson_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, permute_columns=[]):\n",
    "        original_diff = self.data_df[self.data_df[split_by] < split_value][x_one].corr(self.data_df[self.data_df[split_by] < split_value][x_two]) - \\\n",
    "                       self.data_df[self.data_df[split_by] >= split_value][x_one].corr(self.data_df[self.data_df[split_by] >= split_value][x_two])\n",
    "\n",
    "        permuted_diffs = []\n",
    "\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "            \n",
    "            diff = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                   permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            \n",
    "            permuted_diffs.append(diff)\n",
    "\n",
    "        p_value = np.mean([diff <= original_diff for diff in permuted_diffs])\n",
    "        return original_diff, p_value\n",
    "\n",
    "    def plot_with_analytic_ci_manual_pvalue(self, x_one, x_two, \n",
    "                                            split_by, split_value, \n",
    "                                            x_label='X1', y_label='X2', \n",
    "                                            upper_split_legend='Above Split', lower_split_legend='Below Split',\n",
    "                                            alpha=0.3, manual_p_value=None, permute_column=None, \n",
    "                                            save=False, out_dir=None):\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        \n",
    "        group1 = self.data_df[self.data_df[split_by] < split_value]\n",
    "        group2 = self.data_df[self.data_df[split_by] >= split_value]\n",
    "        \n",
    "        ax.scatter(group1[x_one], group1[x_two], color='blue', label=lower_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        ax.scatter(group2[x_one], group2[x_two], color='red', label=upper_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        \n",
    "        x_vals = np.linspace(self.data_df[x_one].min(), self.data_df[x_one].max(), 400)\n",
    "        \n",
    "        for group, color in [(group1, 'blue'), (group2, 'red')]:\n",
    "            y_fit, lower_bound, upper_bound = self.compute_analytic_confidence_interval(group[x_one], group[x_two], x_vals)\n",
    "            ax.plot(x_vals, y_fit, color=color)\n",
    "            ax.fill_between(x_vals, lower_bound, upper_bound, color=color, alpha=alpha/7)\n",
    "        \n",
    "        if manual_p_value is None:\n",
    "            if permute_column:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[permute_column])\n",
    "            else:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[x_one, x_two, split_by])\n",
    "        \n",
    "        ax.set_title(f\"\\u0394 r = {rho:.2f} , p = {manual_p_value:.4f}\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc='best', frameon=False)\n",
    "        ax.grid(False)\n",
    "        sns.despine(ax=ax)\n",
    "        \n",
    "        if save and out_dir is not None:\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.png\", bbox_inches='tight')\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.svg\", bbox_inches='tight')\n",
    "            print(f'Saved to {out_dir}/scatter_with_polyfit_and_analytic_ci.svg')\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient # CDR, ADAS', 'Age', 'Percent Cognitive Improvement',\n",
       "       'Z-Scored Cognitive Improvement By Group', 'Subiculum Connectivity',\n",
       "       'Subiculum Grey Matter', 'Subiculum White Matter', 'Subiculum CSF',\n",
       "       'Subiculum Total', 'Disease', 'Standardized Age',\n",
       "       'Standardized Percent Improvement',\n",
       "       'Standardized Subiculum Connectivity',\n",
       "       'Standardized Subiculum Grey Matter',\n",
       "       'Standardized Subiculum White Matter', 'Standardized Subiculum CSF',\n",
       "       'Standardized Subiculum Total', 'Cohort'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/scatterplot_analysis/scatter_with_polyfit_and_analytic_ci.svg\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of the class\n",
    "scatter_plotter = ScatterWithConfidence(data_df)\n",
    "\n",
    "# Generate and display the plot\n",
    "fig = scatter_plotter.plot_with_analytic_ci_manual_pvalue(x_one=\"Subiculum Connectivity\",\n",
    "                                                         x_two=\"Z-Scored Cognitive Improvement By Group\",\n",
    "                                                         split_by=\"Cohort\",\n",
    "                                                         split_value=0.5,\n",
    "                                                         x_label=\"Subiculum Connectivity\",\n",
    "                                                         y_label=\"Z-Scored Percent Cognitive Improvement\",\n",
    "                                                         upper_split_legend='AD', lower_split_legend='PD',\n",
    "                                                         manual_p_value=None,\n",
    "                                                         alpha=0.7,\n",
    "                                                         save=True, \n",
    "                                                         out_dir=out_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_icc_with_ci(icc, ci_lower, ci_upper):\n",
    "    plt.figure(figsize=(6.5, 2))\n",
    "    plt.errorbar(x=icc, y=0, xerr=[[icc - ci_lower], [ci_upper - icc]], fmt='o', color='#1f77b4', capsize=5)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.yticks([])\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.xlabel('ICC')\n",
    "    plt.title('Intraclass Correlation Coefficient (ICC) with 95% Confidence Interval')\n",
    "    plt.grid(axis='x', linestyle='--')\n",
    "    return plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plot_icc_with_ci(icc=icc, ci_lower=lower_bound, ci_upper=upper_bound)\n",
    "os.makedirs(os.path.join(out_dir, 'icc_figures'), exist_ok=True)\n",
    "figure.savefig(os.path.join(out_dir, 'icc_figures/icc_barplot.png'))\n",
    "figure.savefig(os.path.join(out_dir, 'icc_figures/icc_barplot.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, 'icc_figures/icc_barplot')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a Bunch of ICCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_icc_forest(comparisons_dict, dataframe, bootstrap_samples=2500, full_legend_patches=False):\n",
    "    # figure = plt.figure(figsize=(4, len(comparisons_dict)*1.2))\n",
    "    figure = plt.figure(figsize=(4, 5))\n",
    "    \n",
    "    # Create a color palette with enough unique colors\n",
    "    colors = sns.color_palette(\"tab10\", len(comparisons_dict))\n",
    "    \n",
    "    # Create legend patches\n",
    "    legend_patches = []\n",
    "    \n",
    "    # Iterate through the dictionary and plot ICC for each comparison\n",
    "    for idx, (col1_name, col2_name) in enumerate(comparisons_dict.items()):\n",
    "        # Calculate ICC\n",
    "        icc_value = calculate_icc(dataframe, col1_name, col2_name)\n",
    "\n",
    "        # Bootstrap 95% confidence interval\n",
    "        ci_lower, ci_upper = bootstrap_icc(dataframe, col1_name, col2_name, bootstrap_samples=bootstrap_samples)\n",
    "\n",
    "        # Plot ICC with confidence interval\n",
    "        plt.errorbar(x=icc_value, y=idx, xerr=[[icc_value - ci_lower], [ci_upper - icc_value]], fmt='o', color=colors[idx], capsize=5)\n",
    "        \n",
    "        # Add legend patch\n",
    "        if full_legend_patches:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{col1_name} vs {col2_name}'))\n",
    "        else:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{col1_name}'))\n",
    "\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-1, len(comparisons_dict))\n",
    "    plt.yticks([])\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.xlabel('ICC')\n",
    "    plt.title('Intraclass Correlation Coefficients (ICC) with 95% Confidence Intervals')\n",
    "    plt.grid(axis='x', linestyle='--')\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(handles=legend_patches, frameon=False, loc=(0.05, 0.1))\n",
    "    return figure\n",
    "\n",
    "# Example usage\n",
    "# comparisons_dict = {\n",
    "#     'Total': 'Total.1',\n",
    "#     'Score1': 'Score2'\n",
    "# }\n",
    "\n",
    "# plot_icc_forest(comparisons_dict, dataframe=data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_dict = {'Attention': 'Attention.1', \n",
    "                    'Memory': 'Memory.1', \n",
    "                    'Fluency': 'Fluency.1', \n",
    "                    'Language': 'Language.1', \n",
    "                    'Visuospatial': 'Visuospatial.1', \n",
    "}  \n",
    "bootstrap_samples = 10000\n",
    "#-----------------------------------------------------------------------------\n",
    "multi_icc_fig = plot_icc_forest(comparisons_dict, dataframe=data_df, bootstrap_samples=bootstrap_samples)\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, 'icc_figures'), exist_ok=True)\n",
    "multi_icc_fig.savefig(os.path.join(out_dir, 'icc_figures/icc_multipl_comparison_barplot.png'))\n",
    "multi_icc_fig.savefig(os.path.join(out_dir, 'icc_figures/icc_multipl_comparison_barplot_barplot.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, 'icc_figures/icc_multipl_comparison_barplot')))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_var_column = 'Total'\n",
    "dependent_var_column = 'Cognitive Status'\n",
    "positive_outcome = 'MCI'\n",
    "negative_outcome = 'Intact'\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "data_df = df_1.loc[:, [independent_var_column, dependent_var_column]].copy()\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 0, 1)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "# assuming 'one_hot_status' is the target with MCI encoded as 1 and intact as 0, and 'Question_16' is the score\n",
    "y_true = data_df['one_hot_status']\n",
    "scores = data_df[independent_var_column]\n",
    "\n",
    "# calculate the false positive rate and true positive rate for all thresholds of the classification\n",
    "fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "# calculate the AUC (Area Under Curve)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create a DataFrame to store FPR, TPR, and corresponding thresholds\n",
    "df_roc = pd.DataFrame({\n",
    "    \"FPR\": fpr,\n",
    "    \"TPR\": tpr,\n",
    "    \"Threshold\": thresholds\n",
    "})\n",
    "\n",
    "# Plot\n",
    "sns.set_style(\"white\")\n",
    "roc = plt.figure(figsize=(7, 6))\n",
    "sns.lineplot(x=\"FPR\", y=\"TPR\", data=df_roc, marker='o', color=\"#1f77b4\")\n",
    "\n",
    "\n",
    "plt.title(f'AUC = {roc_auc:.2f}', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "if not os.path.exists(out_dir + '/roc'):\n",
    "    os.makedirs(out_dir + '/roc')\n",
    "    \n",
    "roc.savefig(out_dir + '/roc/roc.png')\n",
    "roc.savefig(out_dir + '/roc/roc.svg')\n",
    "print('saved to: ', out_dir + '/roc/roc.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap Confidence Intervals for the AUC Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.distribution_statistics import bootstrap_distribution_statistics\n",
    "from calvin_utils.statistical_utils.classification_statistics import compute_auc\n",
    "# Use the bootstrap function\n",
    "roc_func_args = {'y_true_variable': 'one_hot_status', 'independent_variable': f'{independent_var_column}'}\n",
    "result_df = bootstrap_distribution_statistics(data_df, compute_auc, roc_func_args, bootstrap_samples=10000)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped ROC Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_bootstrapped_roc(data, y_true_variable, independent_variable, n_bootstraps=2000):\n",
    "    \"\"\"\n",
    "    Plot ROC curve with bootstrapped confidence intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame with the data.\n",
    "    - y_true_variable: string with the name of the column containing the true binary labels.\n",
    "    - independent_variable: string with the name of the column containing the independent variable (classifier scores).\n",
    "    - n_bootstraps: number of bootstrap samples to use for generating confidence intervals.\n",
    "    \"\"\"\n",
    "    \n",
    "    #real valutes\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "    # calculate the AUC (Area Under Curve)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Create a DataFrame to store FPR, TPR, and corresponding thresholds\n",
    "    df_roc = pd.DataFrame({\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr,\n",
    "        \"Threshold\": thresholds\n",
    "    })\n",
    "\n",
    "    #empiric values\n",
    "    roc_auc_bootstraps = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    # Generate bootstrap samples and calculate ROC curve for each\n",
    "    for i in tqdm(range(n_bootstraps)):\n",
    "        sample = data.sample(frac=1, replace=True)\n",
    "        y_true = sample[y_true_variable]\n",
    "        scores = sample[independent_variable]\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        roc_auc_bootstraps.append(tpr)\n",
    "\n",
    "    roc_auc_bootstraps = np.array(roc_auc_bootstraps)\n",
    "\n",
    "    # Calculate mean and confidence intervals\n",
    "    roc_auc_mean = roc_auc_bootstraps.mean(axis=0)\n",
    "    ci_lower = np.percentile(roc_auc_bootstraps, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(roc_auc_bootstraps, 97.5, axis=0)\n",
    "\n",
    "    # Compute AUC using mean ROC curve\n",
    "    roc_auc = auc(base_fpr, roc_auc_mean)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.set_style(\"white\")\n",
    "    sns.lineplot(x=\"FPR\", y=\"TPR\", data=df_roc, marker='o', color=\"darkblue\")\n",
    "\n",
    "    # ax.plot(base_fpr, roc_auc_mean, 'b')\n",
    "    ax.fill_between(base_fpr, ci_lower, ci_upper, color='blue', alpha=0.15)\n",
    "    ax.plot(base_fpr, ci_lower, 'b-', alpha=0.05)\n",
    "    ax.plot(base_fpr, ci_upper, 'b-', alpha=0.05)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    ax.set_title('AUC = %0.2f' % roc_auc, fontsize=16)\n",
    "    ax.plot([0, 1], [0, 1],'--', color='#ADD8E6')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=13)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=13)\n",
    "    \n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    if not os.path.exists(out_dir + '/roc'):\n",
    "        os.makedirs(out_dir + '/roc')\n",
    "    plt.savefig(out_dir + f'/roc/bootstrapped_roc.png')\n",
    "    plt.savefig(out_dir + f'/roc/bootstrapped_roc.svg')\n",
    "    print('Saved to: ', out_dir + f'/roc/bootstrapped_roc.svg')\n",
    "    \n",
    "\n",
    "# fig = plot_bootstrap_auc(data_df, f'one_hot_status', f'{independent_var_column}')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bootstrapped_roc(data_df, \n",
    "                      y_true_variable='one_hot_status', \n",
    "                      independent_variable=f'{independent_var_column}', \n",
    "                      n_bootstraps=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot CIs with Observed Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_bootstrapped_roc(data, y_true_variable, independent_variable, n_bootstraps=2000):\n",
    "    \"\"\"\n",
    "    Plot ROC curve with bootstrapped confidence intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame with the data.\n",
    "    - y_true_variable: string with the name of the column containing the true binary labels.\n",
    "    - independent_variable: string with the name of the column containing the independent variable (classifier scores).\n",
    "    - n_bootstraps: number of bootstrap samples to use for generating confidence intervals.\n",
    "    \"\"\"\n",
    "    # Real values\n",
    "    y_true = data[y_true_variable]\n",
    "    scores = data[independent_variable]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "    # Calculate the AUC (Area Under Curve)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Create a DataFrame to store FPR, TPR, and corresponding thresholds\n",
    "    df_roc = pd.DataFrame({\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr,\n",
    "        \"Threshold\": thresholds\n",
    "    })\n",
    "\n",
    "    # Empirical values\n",
    "    roc_auc_bootstraps = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    # Generate bootstrap samples and calculate ROC curve for each\n",
    "    for i in tqdm(range(n_bootstraps)):\n",
    "        sample = data.sample(frac=1, replace=True)\n",
    "        y_true_sample = sample[y_true_variable]\n",
    "        scores_sample = sample[independent_variable]\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_sample, scores_sample)\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        roc_auc_bootstraps.append(tpr)\n",
    "\n",
    "    roc_auc_bootstraps = np.array(roc_auc_bootstraps)\n",
    "\n",
    "    # Calculate mean and confidence intervals\n",
    "    roc_auc_mean = roc_auc_bootstraps.mean(axis=0)\n",
    "    ci_lower = np.percentile(roc_auc_bootstraps, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(roc_auc_bootstraps, 97.5, axis=0)\n",
    "\n",
    "    # Compute AUC using mean ROC curve\n",
    "    roc_auc = auc(base_fpr, roc_auc_mean)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.set_style(\"white\")\n",
    "    sns.lineplot(x=\"FPR\", y=\"TPR\", data=df_roc, marker='o', color=\"darkblue\", ci=None)\n",
    "    ax.fill_between(base_fpr, ci_lower, ci_upper, color='blue', alpha=0.15)\n",
    "    ax.plot(base_fpr, ci_lower, 'b-', alpha=0.05)\n",
    "    ax.plot(base_fpr, ci_upper, 'b-', alpha=0.05)\n",
    "\n",
    "    ax.set_title('AUC = %0.2f' % roc_auc, fontsize=16)\n",
    "    ax.plot([0, 1], [0, 1],'--', color='#ADD8E6')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=13)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=13)\n",
    "    \n",
    "    sns.despine()\n",
    "    if not os.path.exists(out_dir + '/roc'):\n",
    "        os.makedirs(out_dir + '/roc')\n",
    "    fig.savefig(out_dir + f'/roc/bootstrapped_roc_observed_plotted.png')\n",
    "    fig.savefig(out_dir + f'/roc/bootstrapped_roc_observed_plotted.svg')\n",
    "    print('Saved to: ', out_dir + f'/roc/bootstrapped_roc_observed_plotted.svg')\n",
    "    \n",
    "plot_bootstrapped_roc(data_df, 'one_hot_status', f'{independent_var_column}', 10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped Presenting Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_bootstrapped_roc(data, y_true_variable, independent_variable, n_bootstraps=2000):\n",
    "    \"\"\"\n",
    "    Plot ROC curve with bootstrapped confidence intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame with the data.\n",
    "    - y_true_variable: string with the name of the column containing the true binary labels.\n",
    "    - independent_variable: string with the name of the column containing the independent variable (classifier scores).\n",
    "    - n_bootstraps: number of bootstrap samples to use for generating confidence intervals.\n",
    "    \"\"\"\n",
    "    roc_auc_bootstraps = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    # Convert the labels in the 'Cognitive Status' column to lowercase\n",
    "    data['Cognitive Status'] = data['Cognitive Status'].str.lower()\n",
    "\n",
    "    # Convert 'Cognitive Status' to 'one_hot_status' based on positive_outcome and negative_outcome\n",
    "    data['one_hot_status'] = np.where(data['Cognitive Status'] == positive_outcome.lower(), 0, 1)\n",
    "\n",
    "    # Generate bootstrap samples and calculate ROC curve for each\n",
    "    for i in tqdm(range(n_bootstraps)):\n",
    "        sample = data.sample(frac=1, replace=True)\n",
    "        y_true = sample[y_true_variable]\n",
    "        scores = sample[independent_variable]\n",
    "\n",
    "        # Exclude rows with NaN values\n",
    "        mask = ~(y_true.isna() | scores.isna())\n",
    "        y_true = y_true[mask]\n",
    "        scores = scores[mask]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "        # Interpolate the ROC curve to ensure it starts from (0,0)\n",
    "        tpr = np.interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "\n",
    "        roc_auc_bootstraps.append(tpr)\n",
    "\n",
    "    roc_auc_bootstraps = np.array(roc_auc_bootstraps)\n",
    "\n",
    "    # Calculate mean and confidence intervals, ignoring NaN values\n",
    "    roc_auc_mean = np.nanmean(roc_auc_bootstraps, axis=0)\n",
    "    ci_lower = np.percentile(roc_auc_bootstraps, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(roc_auc_bootstraps, 97.5, axis=0)\n",
    "\n",
    "    # Compute AUC using mean ROC curve\n",
    "    roc_auc = auc(base_fpr, roc_auc_mean)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    ax.plot(base_fpr, roc_auc_mean, '#1f77b4')\n",
    "    ax.fill_between(base_fpr, ci_lower, ci_upper, color='#1f77b4', alpha=0.25)\n",
    "    ax.plot(base_fpr, ci_lower, 'b-', alpha=0.05)\n",
    "    ax.plot(base_fpr, ci_upper, 'b-', alpha=0.05)\n",
    "\n",
    "    ax.set_title('AUC = %0.2f' % roc_auc, fontsize=16)\n",
    "    ax.plot([0, 1], [0, 1],'--', color='#ff7f0e')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=13)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=13)\n",
    "\n",
    "    sns.despine()\n",
    "    if not os.path.exists(out_dir + '/roc'):\n",
    "        os.makedirs(out_dir + '/roc')\n",
    "    plt.savefig(out_dir + f'/roc/bootstrapped_roc_mean_plotted.png')\n",
    "    plt.savefig(out_dir + f'/roc/bootstrapped_roc_mean_plotted.svg')\n",
    "    print('Saved to: ', out_dir + f'/roc/bootstrapped_roc_mean_plotted.svg')\n",
    "\n",
    "# Assuming 'MCI' is the positive outcome and 'Intact' is the negative outcome\n",
    "positive_outcome = 'MCI'\n",
    "negative_outcome = 'Intact'\n",
    "\n",
    "plot_bootstrapped_roc(data_df, 'one_hot_status', f'{independent_var_column}', 10000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Accuracy Curves Across Thresolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_outcome = 'mci'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "data_df = data_df.loc[:, [independent_var_column, dependent_var_column]]\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 0, 1)\n",
    "\n",
    "scores = data_df[independent_var_column]\n",
    "y_true = data_df['one_hot_status']\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from calvin_utils.statistical_utils.distribution_statistics import bootstrap_distribution_statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_accuracy(sample, threshold, y_true_variable, independent_variable):\n",
    "    \"\"\"\n",
    "    Computes the accuracy for a given threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - sample: DataFrame with the data.\n",
    "    - threshold: float with the threshold to use for classifying the scores.\n",
    "    - y_true_variable: string with the name of the column containing the true binary labels.\n",
    "    - independent_variable: string with the name of the column containing the independent variable (classifier scores).\n",
    "\n",
    "    Returns:\n",
    "    - Scalar with the accuracy.\n",
    "    \"\"\"\n",
    "    y_true = sample[y_true_variable]\n",
    "    scores = sample[independent_variable]\n",
    "    \n",
    "    predictions = [0 if score <= threshold else 1 for score in scores]\n",
    "    return accuracy_score(y_true, predictions)\n",
    "\n",
    "def point_accuracy_and_distribution(data, scores_var, y_true_var, bootstrap_samples=1000):\n",
    "    # Extract the scores and true labels\n",
    "    scores = data[scores_var]\n",
    "    y_true = data[y_true_var]\n",
    "\n",
    "    # Calculate accuracies for all thresholds\n",
    "    thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "    accuracies = []\n",
    "\n",
    "    bootstrap_results = {}\n",
    "    for threshold in thresholds_unique:\n",
    "        predictions = [0 if score <= threshold else 1 for score in scores]\n",
    "        accuracy = accuracy_score(y_true, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Bootstrap Distribution\n",
    "        func_args = {'threshold': threshold, 'y_true_variable': y_true_var, 'independent_variable': scores_var}\n",
    "        bootstrap_results[f'{threshold}'] = bootstrap_distribution_statistics(data, compute_accuracy, func_args, bootstrap_samples)\n",
    "    # Create a DataFrame to store thresholds and corresponding accuracies\n",
    "    df_accuracies = pd.DataFrame({\n",
    "        \"Threshold\": thresholds_unique,\n",
    "        \"Accuracy\": accuracies\n",
    "    })\n",
    "    \n",
    "    return df_accuracies, bootstrap_results\n",
    "\n",
    "def plot_accuracy_with_ci(df_accuracies, bootstrap_results, output_dir):\n",
    "    \"\"\"\n",
    "    Plots accuracy as a function of threshold with 95% confidence intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - df_accuracies: DataFrame with 'Threshold' and 'Accuracy' columns.\n",
    "    - bootstrap_results: Dictionary with keys as thresholds and values as DataFrames containing bootstrapped statistics.\n",
    "    - output_dir: String with the path to the output directory.\n",
    "\n",
    "    Returns:\n",
    "    - No return value. The plot is saved to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the lower and upper bounds of the 95% confidence interval for each threshold\n",
    "    lower_bounds = [bootstrap_results[str(threshold)].loc['Bootstrapped 95-CIs', '2.5th Percentile'] for threshold in df_accuracies[\"Threshold\"]]\n",
    "    upper_bounds = [bootstrap_results[str(threshold)].loc['Bootstrapped 95-CIs', '97.5th Percentile'] for threshold in df_accuracies[\"Threshold\"]]\n",
    "\n",
    "    # Plot accuracy as a function of threshold\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the accuracies \n",
    "    ax.plot(df_accuracies[\"Threshold\"], df_accuracies[\"Accuracy\"], '-o', color=\"darkblue\")\n",
    "\n",
    "    # Plot the 95% confidence intervals with lighter shade\n",
    "    ax.fill_between(df_accuracies[\"Threshold\"], lower_bounds, upper_bounds, color='blue', alpha=0.05)\n",
    "\n",
    "    # Labels\n",
    "    ax.set_ylabel('Accuracy', fontsize=13)\n",
    "    ax.set_xlabel('Threshold', fontsize=13)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    # Check if the directory exists and create it if it doesn't\n",
    "    if not os.path.exists(output_dir + '/accuracy_curves'):\n",
    "        os.makedirs(output_dir + '/accuracy_curves')\n",
    "\n",
    "    # Save the figure before calling show()\n",
    "    fig.savefig(output_dir + f'/accuracy_curves/accuracy_curves_rct_group.svg')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracies, bootstrap_results = point_accuracy_and_distribution(data_df, scores_var=f'{independent_var_column}', y_true_var='one_hot_status', bootstrap_samples=10000)\n",
    "display(bootstrap_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "# df_accuracies, bootstrap_results = point_accuracy_and_distribution(data_df, scores_var=f'{independent_var_column}', y_true_var='one_hot_status', bootstrap_samples=1000)\n",
    "plot_accuracy_with_ci(df_accuracies, bootstrap_results, output_dir=out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Displaying bootstrap results of threshold with highest accuracy')\n",
    "bootstrap_results[str(df_accuracies.loc[df_accuracies['Accuracy'].idxmax(), 'Threshold'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sensitivity and Specificity Across Different Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_outcome = 'MCI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "data_df = df_1.copy().loc[:, [independent_var_column, dependent_var_column]]\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 1, 0)\n",
    "\n",
    "scores = data_df[independent_var_column]\n",
    "y_true = data_df['one_hot_status']\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "# Unique thresholds\n",
    "thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "\n",
    "for threshold in thresholds_unique:\n",
    "    # Compute predictions based on threshold\n",
    "    predictions = [1 if score <= threshold else 0 for score in scores]\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, predictions).ravel()\n",
    "    \n",
    "    # Compute sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Append to lists\n",
    "    sensitivities.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "\n",
    "# Create a DataFrame to store thresholds, sensitivities, and specificities\n",
    "df_threshold_metrics = pd.DataFrame({\n",
    "    \"Threshold\": thresholds_unique,\n",
    "    \"Sensitivity\": sensitivities,\n",
    "    \"Specificity\": specificities\n",
    "})\n",
    "\n",
    "# Plot sensitivity and specificity as functions of threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Sensitivity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Sensitivity\", data=df_threshold_metrics, marker='o', color=\"lightblue\", label=\"Sensitivity\")\n",
    "\n",
    "# Specificity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Specificity\", data=df_threshold_metrics, marker='o', color=\"darkblue\", label=\"Specificity\")\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Metric Value', fontsize=13)\n",
    "plt.xlabel('Threshold', fontsize=13)\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/sensitivity_specificity_curves'):\n",
    "    os.makedirs(out_dir + '/sensitivity_specificity_curves')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.png')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.svg')\n",
    "df_threshold_metrics.to_csv(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves_values.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "bootstrap_iterations = 10000\n",
    "\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "lower_sensitivity_bounds = []\n",
    "upper_sensitivity_bounds = []\n",
    "lower_specificity_bounds = []\n",
    "upper_specificity_bounds = []\n",
    "\n",
    "for threshold in thresholds_unique:\n",
    "    bootstrap_sensitivities = []\n",
    "    bootstrap_specificities = []\n",
    "\n",
    "    for i in range(bootstrap_iterations):\n",
    "        # Resample data with replacement\n",
    "        resampled_scores, resampled_y_true = resample(scores, y_true)\n",
    "        \n",
    "        # Compute predictions based on threshold\n",
    "        predictions = [1 if score <= threshold else 0 for score in resampled_scores]\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(resampled_y_true, predictions).ravel()\n",
    "        except:\n",
    "            continue \n",
    "        if tp + fn != 0:\n",
    "            sensitivity = tp / (tp + fn)\n",
    "        else:\n",
    "            sensitivity = np.nan\n",
    "\n",
    "        if tn + fp != 0:\n",
    "            specificity = tn / (tn + fp)\n",
    "        else:\n",
    "            specificity = np.nan\n",
    "        # # Compute sensitivity and specificity\n",
    "        # sensitivity = tp / (tp + fn)\n",
    "        # specificity = tn / (tn + fp)\n",
    "\n",
    "        # Append to lists\n",
    "        bootstrap_sensitivities.append(sensitivity)\n",
    "        bootstrap_specificities.append(specificity)\n",
    "\n",
    "    # Append mean values to lists\n",
    "    # sensitivities.append(np.mean(bootstrap_sensitivities))\n",
    "    # specificities.append(np.mean(bootstrap_specificities))\n",
    "    sensitivities.append(np.nanmean(bootstrap_sensitivities))\n",
    "    specificities.append(np.nanmean(bootstrap_specificities))\n",
    "    \n",
    "    # Compute 95% confidence intervals for sensitivity and specificity\n",
    "    # lower_sensitivity, upper_sensitivity = np.percentile(bootstrap_sensitivities, [2.5, 97.5])\n",
    "    # lower_specificity, upper_specificity = np.percentile(bootstrap_specificities, [2.5, 97.5])\n",
    "    # Compute 95% confidence intervals for sensitivity and specificity\n",
    "    lower_sensitivity, upper_sensitivity = np.nanpercentile(bootstrap_sensitivities, [2.5, 97.5])\n",
    "    lower_specificity, upper_specificity = np.nanpercentile(bootstrap_specificities, [2.5, 97.5])\n",
    "    \n",
    "    lower_sensitivity_bounds.append(lower_sensitivity)\n",
    "    upper_sensitivity_bounds.append(upper_sensitivity)\n",
    "    lower_specificity_bounds.append(lower_specificity)\n",
    "    upper_specificity_bounds.append(upper_specificity)\n",
    "    \n",
    "confidence_interval_df = pd.DataFrame({\n",
    "    'threshold': thresholds_unique,\n",
    "    'sensitivity': sensitivities,\n",
    "    'lower_sensitivity_bound': lower_sensitivity_bounds,\n",
    "    'upper_sensitivity_bound': upper_sensitivity_bounds,\n",
    "    'specificity': specificities,\n",
    "    'lower_specificity_bound': lower_specificity_bounds,\n",
    "    'upper_specificity_bound': upper_specificity_bounds,\n",
    "})\n",
    "confidence_interval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Merge the two dataframes on the 'Threshold' column\n",
    "df_threshold_metrics = df_threshold_metrics.merge(confidence_interval_df, how='inner', left_on='Threshold', right_on='threshold')\n",
    "\n",
    "# Plot sensitivity and specificity as functions of threshold\n",
    "plt.figure(figsize=(15.5, 6))\n",
    "\n",
    "# Sensitivity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Sensitivity\", data=df_threshold_metrics, marker='o', color=\"#1f77b4\", label=\"Sensitivity\")\n",
    "plt.fill_between(df_threshold_metrics['Threshold'], df_threshold_metrics['lower_sensitivity_bound'], df_threshold_metrics['upper_sensitivity_bound'], color='#1f77b4', alpha=0.25)\n",
    "\n",
    "# Specificity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Specificity\", data=df_threshold_metrics, marker='o', color=\"#ff7f0e\", label=\"Specificity\")\n",
    "plt.fill_between(df_threshold_metrics['Threshold'], df_threshold_metrics['lower_specificity_bound'], df_threshold_metrics['upper_specificity_bound'], color='#ff7f0e', alpha=0.25)\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Metric Value', fontsize=13)\n",
    "plt.xlabel('Threshold', fontsize=13)\n",
    "plt.legend(loc=(0.9, 0.5), frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/sensitivity_specificity_curves'):\n",
    "    os.makedirs(out_dir + '/sensitivity_specificity_curves')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.png')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.svg')\n",
    "df_threshold_metrics.to_csv(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves_values.csv')\n",
    "print('Saved to: ', out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.svg')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate PPV and NPV Across All Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "data_df = data_df.loc[:, [independent_var_column, dependent_var_column]]\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 1, 0)\n",
    "\n",
    "scores = data_df[independent_var_column]\n",
    "y_true = data_df['one_hot_status']\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Unique thresholds\n",
    "thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "\n",
    "ppv_list = []\n",
    "npv_list = []\n",
    "\n",
    "for threshold in thresholds_unique:\n",
    "    # Compute predictions based on threshold\n",
    "    predictions = [1 if score <= threshold else 0 for score in scores]\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, predictions).ravel()\n",
    "    \n",
    "    # Compute Positive Predictive Value (PPV) and Negative Predictive Value (NPV)\n",
    "    ppv = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "    npv = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "    \n",
    "    # Append to lists\n",
    "    ppv_list.append(ppv)\n",
    "    npv_list.append(npv)\n",
    "\n",
    "# Create a DataFrame to store thresholds, PPVs, and NPVs\n",
    "df_ppv_npv = pd.DataFrame({\n",
    "    \"Threshold\": thresholds_unique,\n",
    "    \"Positive Predictive Value\": ppv_list,\n",
    "    \"Negative Predictive Value\": npv_list\n",
    "})\n",
    "\n",
    "# Plot PPV and NPV as functions of threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# PPV\n",
    "sns.lineplot(x=\"Threshold\", y=\"Positive Predictive Value\", data=df_ppv_npv, marker='o', color=\"lightblue\", label=\"PPV\")\n",
    "\n",
    "# NPV\n",
    "sns.lineplot(x=\"Threshold\", y=\"Negative Predictive Value\", data=df_ppv_npv, marker='o', color=\"darkblue\", label=\"NPV\")\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Metric Value', fontsize=13)\n",
    "plt.xlabel('Threshold', fontsize=13)\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/ppv_npv_curves'):\n",
    "    os.makedirs(out_dir + '/ppv_npv_curves')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.png')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.svg')\n",
    "df_ppv_npv.to_csv(out_dir + f'/ppv_npv_curves/ppv_npv_curves.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "bootstrap_samples = 10000  # number of bootstrap samples to generate\n",
    "\n",
    "# Unique thresholds\n",
    "thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "\n",
    "ppv_list = []\n",
    "npv_list = []\n",
    "ppv_lower = []\n",
    "ppv_upper = []\n",
    "npv_lower = []\n",
    "npv_upper = []\n",
    "\n",
    "y_true_array = y_true.to_numpy()\n",
    "scores_array = scores.to_numpy()\n",
    "for threshold in thresholds_unique:\n",
    "    # Compute predictions based on threshold\n",
    "    predictions = [1 if score <= threshold else 0 for score in scores_array]\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, predictions).ravel()\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Compute Positive Predictive Value (PPV) and Negative Predictive Value (NPV)\n",
    "    ppv = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "    npv = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "    # Bootstrap samples\n",
    "    ppv_bootstrap = []\n",
    "    npv_bootstrap = []\n",
    "\n",
    "    # Generate bootstrap samples\n",
    "    for _ in range(bootstrap_samples):\n",
    "        # Create bootstrap sample\n",
    "        bootstrap_indices = np.random.choice(np.arange(len(predictions)), size=len(predictions), replace=True)\n",
    "        bootstrap_predictions = [predictions[i] for i in bootstrap_indices]\n",
    "        bootstrap_y_true = [y_true_array[i] for i in bootstrap_indices]\n",
    "\n",
    "        \n",
    "        # Compute confusion matrix for bootstrap sample\n",
    "        tn, fp, fn, tp = confusion_matrix(bootstrap_y_true, bootstrap_predictions).ravel()\n",
    "        \n",
    "        # Compute PPV and NPV for bootstrap sample\n",
    "        ppv_bootstrap_sample = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "        npv_bootstrap_sample = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "        # Append to lists\n",
    "        ppv_bootstrap.append(ppv_bootstrap_sample)\n",
    "        npv_bootstrap.append(npv_bootstrap_sample)\n",
    "\n",
    "    # Compute 95% confidence intervals\n",
    "    ppv_lower.append(np.percentile(ppv_bootstrap, 2.5))\n",
    "    ppv_upper.append(np.percentile(ppv_bootstrap, 97.5))\n",
    "    npv_lower.append(np.percentile(npv_bootstrap, 2.5))\n",
    "    npv_upper.append(np.percentile(npv_bootstrap, 97.5))\n",
    "    \n",
    "    # Append to lists\n",
    "    ppv_list.append(ppv)\n",
    "    npv_list.append(npv)\n",
    "\n",
    "# Create a DataFrame to store thresholds, PPVs, and NPVs\n",
    "df_ppv_npv = pd.DataFrame({\n",
    "    \"Threshold\": thresholds_unique,\n",
    "    \"Positive Predictive Value\": ppv_list,\n",
    "    \"PPV Lower\": ppv_lower,\n",
    "    \"PPV Upper\": ppv_upper,\n",
    "    \"Negative Predictive Value\": npv_list,\n",
    "    \"NPV Lower\": npv_lower,\n",
    "    \"NPV Upper\": npv_upper\n",
    "})\n",
    "\n",
    "# Plot PPV and NPV as functions of threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# PPV\n",
    "plt.plot(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"Positive Predictive Value\"], '-o', color=\"lightblue\", label=\"PPV\")\n",
    "plt.fill_between(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"PPV Lower\"], df_ppv_npv[\"PPV Upper\"], color='lightblue', alpha=0.25)\n",
    "\n",
    "# NPV\n",
    "plt.plot(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"Negative Predictive Value\"], '-o', color=\"darkblue\", label=\"NPV\")\n",
    "plt.fill_between(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"NPV Lower\"], df_ppv_npv[\"NPV Upper\"], color='darkblue', alpha=0.05)\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Metric Value', fontsize=13)\n",
    "plt.xlabel('Threshold', fontsize=13)\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/ppv_npv_curves'):\n",
    "    os.makedirs(out_dir + '/ppv_npv_curves')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.png')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.svg')\n",
    "df_ppv_npv.to_csv(out_dir + f'/ppv_npv_curves/ppv_npv_curves.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "bootstrap_samples = 10000  # number of bootstrap samples to generate\n",
    "\n",
    "# Unique thresholds\n",
    "thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "\n",
    "ppv_list = []\n",
    "npv_list = []\n",
    "ppv_lower = []\n",
    "ppv_upper = []\n",
    "npv_lower = []\n",
    "npv_upper = []\n",
    "\n",
    "y_true_array = y_true.to_numpy()\n",
    "scores_array = scores.to_numpy()\n",
    "for threshold in thresholds_unique:\n",
    "    # Compute predictions based on threshold\n",
    "    predictions = [1 if score <= threshold else 0 for score in scores_array]\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_array, predictions).ravel()\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Compute Positive Predictive Value (PPV) and Negative Predictive Value (NPV)\n",
    "    ppv = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "    npv = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "    # Bootstrap samples\n",
    "    ppv_bootstrap = []\n",
    "    npv_bootstrap = []\n",
    "\n",
    "    # Generate bootstrap samples\n",
    "    for _ in range(bootstrap_samples):\n",
    "        # Create bootstrap sample\n",
    "        bootstrap_indices = np.random.choice(np.arange(len(predictions)), size=len(predictions), replace=True)\n",
    "        bootstrap_predictions = [predictions[i] for i in bootstrap_indices]\n",
    "        bootstrap_y_true = [y_true_array[i] for i in bootstrap_indices]\n",
    "\n",
    "        \n",
    "        # Compute confusion matrix for bootstrap sample\n",
    "        tn, fp, fn, tp = confusion_matrix(bootstrap_y_true, bootstrap_predictions).ravel()\n",
    "        \n",
    "        # Compute PPV and NPV for bootstrap sample\n",
    "        ppv_bootstrap_sample = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "        npv_bootstrap_sample = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "        # Append to lists\n",
    "        ppv_bootstrap.append(ppv_bootstrap_sample)\n",
    "        npv_bootstrap.append(npv_bootstrap_sample)\n",
    "\n",
    "    # Compute 95% confidence intervals\n",
    "    ppv_lower.append(np.percentile(ppv_bootstrap, 2.5))\n",
    "    ppv_upper.append(np.percentile(ppv_bootstrap, 97.5))\n",
    "    npv_lower.append(np.percentile(npv_bootstrap, 2.5))\n",
    "    npv_upper.append(np.percentile(npv_bootstrap, 97.5))\n",
    "    \n",
    "    # Append to lists\n",
    "    ppv_list.append(ppv)\n",
    "    npv_list.append(npv)\n",
    "\n",
    "# Create a DataFrame to store thresholds, PPVs, and NPVs\n",
    "df_ppv_npv = pd.DataFrame({\n",
    "    \"Threshold\": thresholds_unique,\n",
    "    \"Positive Predictive Value\": ppv_list,\n",
    "    \"PPV Lower\": ppv_lower,\n",
    "    \"PPV Upper\": ppv_upper,\n",
    "    \"Negative Predictive Value\": npv_list,\n",
    "    \"NPV Lower\": npv_lower,\n",
    "    \"NPV Upper\": npv_upper\n",
    "})\n",
    "\n",
    "# Plot PPV and NPV as functions of threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# PPV\n",
    "plt.plot(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"Positive Predictive Value\"], '-o', color=\"lightblue\", label=\"PPV\")\n",
    "plt.fill_between(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"PPV Lower\"], df_ppv_npv[\"PPV Upper\"], color='lightblue', alpha=0.25)\n",
    "\n",
    "# NPV\n",
    "plt.plot(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"Negative Predictive Value\"], '-o', color=\"darkblue\", label=\"NPV\")\n",
    "plt.fill_between(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"NPV Lower\"], df_ppv_npv[\"NPV Upper\"], color='darkblue', alpha=0.05)\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Metric Value', fontsize=13)\n",
    "plt.xlabel('Threshold', fontsize=13)\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/ppv_npv_curves'):\n",
    "    os.makedirs(out_dir + '/ppv_npv_curves')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.png')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.svg')\n",
    "df_ppv_npv.to_csv(out_dir + f'/ppv_npv_curves/ppv_npv_curves.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ppv_npv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Other Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num positive cases: ', np.count_nonzero(data_df['one_hot_status']))\n",
    "print('Num total cases: ', np.count_nonzero(data_df.index))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62880161f19d28ddb8a8f59c63374d84ace356c39e36cc839cb3fb3bb03fb010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
