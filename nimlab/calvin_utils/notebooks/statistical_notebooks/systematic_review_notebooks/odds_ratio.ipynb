{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run An Odds Ratio\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: July 6, 2023\n",
    "\n",
    "Use this to run/test a statistical model on a spreadsheet.\n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with GLM design and Contrast Matrix design. See this webpage to get started:\n",
    "[FSL's GLM page](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Output Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/odds_ratios'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/metadata/master_list_proper_subjects.xlsx'\n",
    "sheet = 'master_list_proper_subjects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['City', 'StimMatch', 'Cognitive_Improve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'City'  # The column you'd like to evaluate\n",
    "condition = 'equal'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'BWH' # The value to drop if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = None # ['Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group', 'Z_Scored_Subiculum_T_By_Origin_Group_'] #['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in data_df.columns:\n",
    "#     if 'CSF' and 'eh' not in col:\n",
    "#         data_df[col] = data_df[col] * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Simple Odds Ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_contingency_values(df, condition_column, outcome_column, condition_success, outcome_success):\n",
    "    \"\"\"\n",
    "    Calculates the values of a, b, c, and d for a 2x2 contingency table from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input data frame.\n",
    "    condition_column (str): The name of the column that contains the condition.\n",
    "    outcome_column (str): The name of the column that contains the outcome.\n",
    "    condition_success (any): The value in the condition column that indicates success.\n",
    "    outcome_success (any): The value in the outcome column that indicates success.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the values of a, b, c, and d.\n",
    "    \"\"\"\n",
    "    # Patients who meet the condition\n",
    "    condition_positive = df[condition_column] == condition_success\n",
    "\n",
    "    # Patients who don't meet the condition\n",
    "    condition_negative = ~condition_positive\n",
    "\n",
    "    # Patients who improved\n",
    "    outcome_positive = df[outcome_column] == outcome_success\n",
    "\n",
    "    # Patients who did not improve\n",
    "    outcome_negative = ~outcome_positive\n",
    "\n",
    "    # Count values for a, b, c, d\n",
    "    a = df[condition_positive & outcome_positive].shape[0]\n",
    "    b = df[condition_positive & outcome_negative].shape[0]\n",
    "    c = df[condition_negative & outcome_positive].shape[0]\n",
    "    d = df[condition_negative & outcome_negative].shape[0]\n",
    "\n",
    "    return a, b, c, d\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.DataFrame({'Condition': [...], 'Outcome': [...]})\n",
    "# a, b, c, d = calculate_contingency_values(df, 'Condition', 'Outcome', 'ConditionSuccessValue', 'OutcomeSuccessValue')\n",
    "# print(a, b, c, d)\n",
    "\n",
    "def calculate_odds_ratio(a, b, c, d):\n",
    "    \"\"\"\n",
    "    Calculates the odds ratio from a 2x2 contingency table.\n",
    "    \n",
    "    Parameters:\n",
    "    a (int): Number of patients who meet the condition and improved.\n",
    "    b (int): Number of patients who meet the condition and did not improve.\n",
    "    c (int): Number of patients who do not meet the condition but improved.\n",
    "    d (int): Number of patients who do not meet the condition and did not improve.\n",
    "    \n",
    "    Returns:\n",
    "    float: The odds ratio.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        odds_ratio = (a * d) / (b * c)\n",
    "        return odds_ratio\n",
    "    except ZeroDivisionError:\n",
    "        return \"Cannot calculate odds ratio due to division by zero.\"\n",
    "\n",
    "# Example usage:\n",
    "# a, b, c, d = 10, 20, 30, 40\n",
    "# print(calculate_odds_ratio(a, b, c, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = calculate_contingency_values(data_df, condition_column='StimMatch', outcome_column='Cognitive_Outcome', condition_success='Match', outcome_success='improve')\n",
    "calculate_odds_ratio(a, b, c, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Forest Plot\n",
    "- This code allows you to adjust for covariates.\n",
    "- Instead of a normal ad/cb odds ratio calculation, this uses logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Cognitive_Improve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'Cognitive_Improve'\n",
    "predictor = 'StimMatch'\n",
    "cohorts = 'City'\n",
    "covariate_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.forest_plots import OddsRatioForestPlot\n",
    "# Create an instance of the LogisticOddsRatioPlot class with covariates\n",
    "plot = OddsRatioForestPlot(data_df, outcome_col=outcome, predictor_col=predictor,\n",
    "                             category_col=cohorts, covariates=None, table=False, log_odds=True, out_dir=out_dir)\n",
    "\n",
    "# Run the plotting process\n",
    "plot.run()\n",
    "plot.data_for_plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
