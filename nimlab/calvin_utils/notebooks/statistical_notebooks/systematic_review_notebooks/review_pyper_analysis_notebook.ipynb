{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Dropbox (Partners HealthCare)/studies/review_pyper/analyses/enrollment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the uploaded CSV files\n",
    "csv_paths = [\n",
    "    '/Users/cu135/Dropbox (Partners HealthCare)/studies/review_pyper/memory_extraction_data/calvin/calvin_enrollment_master_list.csv',\n",
    "    '/Users/cu135/Dropbox (Partners HealthCare)/studies/review_pyper/memory_extraction_data/gpt_4/gpt_4_enrollment_master_list.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify Columns of Spreadhseet to Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = [\"Inclusion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class CSVAligner:\n",
    "    def __init__(self, csv_paths, align_on='Title', nanhandle='zero'):\n",
    "        self.csv_paths = csv_paths\n",
    "        self.align_on = align_on\n",
    "        self.nanhandle = nanhandle\n",
    "        self.dataframes = [pd.read_csv(path, encoding='ISO-8859-1') for path in csv_paths]\n",
    "        self.aligned_data = self.align_csvs()\n",
    "\n",
    "    def align_csvs(self):\n",
    "        # Find the intersection of titles across all CSVs\n",
    "        common_titles = set.intersection(*(set(df[self.align_on].unique()) for df in self.dataframes))\n",
    "        print(f\"Common titles count: {len(common_titles)}\")\n",
    "\n",
    "        # Create new dataframes with only the rows that have the common titles\n",
    "        aligned_data = []\n",
    "        for df in self.dataframes:\n",
    "            # Filter rows by the common titles and remove duplicates\n",
    "            aligned_df = df[df[self.align_on].isin(common_titles)].drop_duplicates(subset=[self.align_on])\n",
    "            # Backfill NaNs if the option is set\n",
    "            if self.nanhandle=='bfill':\n",
    "                aligned_df = aligned_df.bfill(axis='rows')\n",
    "            elif self.nanhandle=='zero':\n",
    "                aligned_df = aligned_df.fillna(0)\n",
    "            # Sort by title to ensure order is consistent\n",
    "            aligned_df.sort_values(by=self.align_on, inplace=True)\n",
    "            # Reset index for consistency\n",
    "            aligned_df.reset_index(drop=True, inplace=True)\n",
    "            aligned_data.append(aligned_df)\n",
    "            print(f\"Aligned dataframe rows: {aligned_df.shape[0]}\")\n",
    "\n",
    "        # Verify that all dataframes have the same order of titles\n",
    "        for i in range(len(aligned_data) - 1):\n",
    "            assert (aligned_data[i][self.align_on].values == aligned_data[i + 1][self.align_on].values).all(), \"Row mismatch\"\n",
    "\n",
    "        return aligned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = CSVAligner(csv_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Class for computing and plotting Cohen's Kappa\n",
    "class CohensKappaPlotter:\n",
    "    def __init__(self, aligned_data, gold_standard_index=0):\n",
    "        self.aligned_data = aligned_data\n",
    "        self.gold_standard_df = self.aligned_data[gold_standard_index]\n",
    "        self.comparator_dfs = self.aligned_data[1:]\n",
    "\n",
    "    def compute_kappa(self, columns):\n",
    "        kappa_scores = []\n",
    "        for idx, df in enumerate(self.comparator_dfs):\n",
    "            for column in columns:\n",
    "                if column not in self.gold_standard_df.columns:\n",
    "                    print(f\"Column {column} not found in gold standard dataframe.\")\n",
    "                    continue\n",
    "                if column not in df.columns:\n",
    "                    print(f\"Column {column} not found in comparator dataframe for GPT {4-idx}.\")\n",
    "                    continue\n",
    "\n",
    "                # Check if the column is binary\n",
    "                if set(self.gold_standard_df[column].unique()).issubset({0, 1}) and set(df[column].unique()).issubset({0, 1}):\n",
    "                    kappa = cohen_kappa_score(self.gold_standard_df[column], df[column])\n",
    "                    kappa_scores.append((column, kappa, f'GPT {4-idx}'))\n",
    "                else:\n",
    "                    print(f\"Column {column} is not binary in one or both dataframes for GPT {4-idx}.\")\n",
    "        return kappa_scores\n",
    "\n",
    "\n",
    "\n",
    "    def kappa_confidence_interval(self, kappa, n):\n",
    "        # Standard error\n",
    "        se = np.sqrt((2 * (1 - kappa)) / n)\n",
    "        return kappa - 1.96 * se, kappa + 1.96 * se\n",
    "\n",
    "    def plot_kappa(self, kappa_scores, save_dir):\n",
    "        # Define the color map for the comparators\n",
    "        color_map = ['purple', 'green']\n",
    "\n",
    "        # Create a DataFrame for plotting\n",
    "        kappa_df = pd.DataFrame(kappa_scores, columns=['Column', 'Kappa', 'Comparator'])\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        \n",
    "        # Use Seaborn to plot the kappa scores with the 'Comparator' column defining the hue\n",
    "        ax = sns.barplot(x='Column', y='Kappa', hue='Comparator', data=kappa_df, palette=color_map)\n",
    "        ax.set(ylim=(0, 1))\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Define the directory path for saving\n",
    "        cohens_kappa_dir = os.path.join(save_dir, \"cohens_kappa\")\n",
    "        os.makedirs(cohens_kappa_dir, exist_ok=True)  # Ensure the directory exists\n",
    "        \n",
    "        # Iterate over each comparator to save individual plots\n",
    "        for comparator in kappa_df['Comparator'].unique():\n",
    "            comparator_scores = kappa_df[kappa_df['Comparator'] == comparator]\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.barplot(x='Column', y='Kappa', data=comparator_scores, color=color_map[int(comparator[-1])-3])\n",
    "            plt.ylim(0, 1)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.title(f'Cohen\\'s Kappa Scores - {comparator}')\n",
    "            \n",
    "            # Define the file names\n",
    "            file_name_png = f\"{comparator}_cohens_kappa.png\"\n",
    "            file_name_svg = f\"{comparator}_cohens_kappa.svg\"\n",
    "\n",
    "            # Construct the full file paths\n",
    "            path_png = os.path.join(cohens_kappa_dir, file_name_png)\n",
    "            path_svg = os.path.join(cohens_kappa_dir, file_name_svg)\n",
    "\n",
    "            # Save the plots as PNG and SVG\n",
    "            plt.savefig(path_png, format='png', bbox_inches='tight')\n",
    "            plt.savefig(path_svg, format='svg', bbox_inches='tight')\n",
    "\n",
    "            # Close the plot to avoid overlapping figures\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plotter with your aligned data\n",
    "kappa_plotter = CohensKappaPlotter(aligner.aligned_data)\n",
    "\n",
    "# Compute kappa scores for these columns\n",
    "kappa_scores = kappa_plotter.compute_kappa(binary_columns)\n",
    "print(kappa_scores)\n",
    "\n",
    "# Plot and save the kappa scores\n",
    "kappa_plotter.plot_kappa(kappa_scores, save_dir=out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z Proportion Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "class ZProportionPlotter:\n",
    "    def __init__(self, aligned_data, gold_standard_index=0):\n",
    "        self.aligned_data = aligned_data\n",
    "        self.gold_standard_df = self.aligned_data[gold_standard_index]\n",
    "        self.comparator_dfs = self.aligned_data[1:]\n",
    "\n",
    "    def compute_z_proportions(self, columns):\n",
    "        z_scores = []\n",
    "        for column in columns:\n",
    "            for idx, df in enumerate(self.comparator_dfs):\n",
    "                count = np.array([\n",
    "                    (self.gold_standard_df[column] == df[column]).sum(),\n",
    "                    (self.gold_standard_df[column] != df[column]).sum()\n",
    "                ])\n",
    "                nobs = np.array([len(self.gold_standard_df[column]), len(df[column])])\n",
    "                stat, pval = proportions_ztest(count=count, nobs=nobs, value=0)\n",
    "                z_scores.append((column, stat, idx))\n",
    "        return z_scores, pval\n",
    "\n",
    "    def plot_z_scores(self, z_scores, save_dir):\n",
    "        # Convert z_scores to a DataFrame for easier plotting\n",
    "        z_scores_df = pd.DataFrame(z_scores, columns=['Column', 'Z-score', 'Comparator Index'])\n",
    "\n",
    "        # Define a color map for the comparators\n",
    "        color_map = {0: 'purple', 1: 'green'}\n",
    "\n",
    "        # Plot and save a bar plot for each column\n",
    "        for column in z_scores_df['Column'].unique():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            column_data = z_scores_df[z_scores_df['Column'] == column]\n",
    "            ax = sns.barplot(\n",
    "                x='Comparator Index', \n",
    "                y='Z-score', \n",
    "                data=column_data, \n",
    "                palette=[color_map.get(x) for x in column_data['Comparator Index']]\n",
    "            )\n",
    "            ax.set(ylim=(-3, 3))  # Z-scores typically range from -3 to 3\n",
    "            ax.set_title(f'Z-scores for \"{column}\"')\n",
    "            plt.xticks(ticks=ax.get_xticks(), labels=['GPT-4', 'GPT-3'])  # Set ticks and labels\n",
    "            plt.tight_layout()  # Adjust the plot\n",
    "\n",
    "            # Define the directory path for saving\n",
    "            z_proportion_test_dir = os.path.join(save_dir, \"z_proportion_test\", column)\n",
    "            os.makedirs(z_proportion_test_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "            # Define the file names\n",
    "            file_name_png = f\"{column}_z_scores.png\"\n",
    "            file_name_svg = f\"{column}_z_scores.svg\"\n",
    "\n",
    "            # Construct the full file paths\n",
    "            path_png = os.path.join(z_proportion_test_dir, file_name_png)\n",
    "            path_svg = os.path.join(z_proportion_test_dir, file_name_svg)\n",
    "\n",
    "            # Save the plots as PNG and SVG\n",
    "            plt.savefig(path_png, format='png', bbox_inches='tight')\n",
    "            plt.savefig(path_svg, format='svg', bbox_inches='tight')\n",
    "\n",
    "            # Close the plot to avoid overlapping figures\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_plotter = ZProportionPlotter(aligner.aligned_data)\n",
    "z_scores, pvals = z_plotter.compute_z_proportions(binary_columns)\n",
    "z_plotter.plot_z_scores(z_scores, save_dir=out_dir)\n",
    "\n",
    "pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "import os\n",
    "\n",
    "class PerformanceMetricsPlotter:\n",
    "    def __init__(self, aligned_data, gold_standard_index=0):\n",
    "        self.aligned_data = aligned_data\n",
    "        self.gold_standard_df = self.aligned_data[gold_standard_index]\n",
    "        self.comparator_dfs = self.aligned_data[1:]\n",
    "\n",
    "    def calculate_metrics(self, column):\n",
    "        # Calculate metrics for a single column\n",
    "        metrics = []\n",
    "        for df in self.comparator_dfs:\n",
    "            tn, fp, fn, tp = confusion_matrix(self.gold_standard_df[column], df[column], labels=[0, 1]).ravel()\n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "            specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "            ppv = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "            npv = tn / (tn + fn) if (tn + fn) != 0 else 0\n",
    "            acc = accuracy_score(self.gold_standard_df[column], df[column])\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(self.gold_standard_df[column], df[column], average='binary')\n",
    "            metrics.append({\n",
    "                'Sensitivity': sensitivity,\n",
    "                'Specificity': specificity,\n",
    "                'Ppv': ppv,\n",
    "                'Npv': npv,\n",
    "                'Accuracy': acc\n",
    "            })\n",
    "        return metrics\n",
    "    \n",
    "    def plot_confusion_matrix(self, column, save_dir):\n",
    "        # Iterate over each comparator dataframe\n",
    "        for idx, df in enumerate(self.comparator_dfs):\n",
    "            # Compute the confusion matrix\n",
    "            cm = confusion_matrix(self.gold_standard_df[column], df[column], labels=[0, 1])\n",
    "            # Normalize the confusion matrix\n",
    "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] #<------ISSUE IS THAT I AM NOT ENTIRELY COMFORTABLE THIS IS NORMALIZING PROPOERLY\n",
    "\n",
    "            # Plot the normalized confusion matrix as a heatmap\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', cbar=False,\n",
    "                        xticklabels=['False', 'True'], yticklabels=['False', 'True'])\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix for \"{column}\" - GPT {4-idx}')\n",
    "\n",
    "            # Define the file names\n",
    "            file_name_png = f\"{column}_confusion_matrix_GPT{4-idx}.png\"\n",
    "            file_name_svg = f\"{column}_confusion_matrix_GPT{4-idx}.svg\"\n",
    "\n",
    "            # Construct the directory path for confusion matrices\n",
    "            confusion_matrix_dir = os.path.join(save_dir, \"confusion_matrix\")\n",
    "            os.makedirs(confusion_matrix_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "            # Construct the full file paths\n",
    "            path_png = os.path.join(confusion_matrix_dir, file_name_png)\n",
    "            path_svg = os.path.join(confusion_matrix_dir, file_name_svg)\n",
    "\n",
    "            # Save the plots as PNG and SVG\n",
    "            plt.savefig(path_png, format='png', bbox_inches='tight')\n",
    "            plt.savefig(path_svg, format='svg', bbox_inches='tight')\n",
    "\n",
    "            # Close the plot to avoid overlapping figures\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    def plot_radar(self, metrics_data, column, save_dir):\n",
    "        # Number of variables we're plotting.\n",
    "        categories = list(metrics_data[0].keys())\n",
    "        N = len(categories)\n",
    "\n",
    "        # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "        angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "        angles += angles[:1]\n",
    "\n",
    "        # Initialise the radar plot\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "\n",
    "        # If you want the first axis to be on top:\n",
    "        ax.set_theta_offset(pi / 2)\n",
    "        ax.set_theta_direction(-1)\n",
    "\n",
    "        # Draw one axe per variable + add labels\n",
    "        plt.xticks(angles[:-1], categories)\n",
    "\n",
    "        # Draw ylabels\n",
    "        ax.set_rlabel_position(0)\n",
    "        plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\",\"0.4\",\"0.6\",\"0.8\"], color=\"grey\", size=7)\n",
    "        plt.ylim(0,1)\n",
    "\n",
    "        # Plot each individual = each line of the data\n",
    "        color_map = ['purple', 'green']  # Define your colors\n",
    "        for idx, data in enumerate(metrics_data):\n",
    "            values = list(data.values())\n",
    "            values += values[:1]\n",
    "            ax.plot(angles, values, linewidth=1, linestyle='solid', label=f'GPT {4-idx}', color=color_map[idx])\n",
    "\n",
    "\n",
    "        # Add a legend\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "\n",
    "        # Add a title\n",
    "        plt.title(f'Metrics for \"{column}\"', size=20, color='black', y=1.1)\n",
    "        \n",
    "        # Define the subdirectory for radar plots within the main save directory\n",
    "        radar_plots_subdir = \"radar_plots\"\n",
    "        os.makedirs(os.path.join(save_dir, radar_plots_subdir), exist_ok=True)\n",
    "        \n",
    "        # Construct the file paths\n",
    "        file_name_png = f\"{column}.png\"\n",
    "        file_name_svg = f\"{column}.svg\"\n",
    "        path_png = os.path.join(save_dir, radar_plots_subdir, file_name_png)\n",
    "        path_svg = os.path.join(save_dir, radar_plots_subdir, file_name_svg)\n",
    "\n",
    "        # Save the files\n",
    "        plt.savefig(path_png, format='png')\n",
    "        plt.savefig(path_svg, format='svg')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of binary columns to compare\n",
    "binary_columns = [\"Inclusion\"]\n",
    "metrics_plotter = PerformanceMetricsPlotter(aligner.aligned_data)\n",
    "\n",
    "for column in binary_columns:\n",
    "    metrics_data = metrics_plotter.calculate_metrics(column)\n",
    "    metrics_plotter.plot_radar(metrics_data, column, save_dir=out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_plotter = PerformanceMetricsPlotter(aligner.aligned_data)\n",
    "\n",
    "for column in binary_columns:  # Assuming binary_columns is a list of your binary column names\n",
    "    metrics_plotter.plot_confusion_matrix(column, save_dir=out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Benefit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "class CostBenefitPlotter:\n",
    "    def __init__(self, aligned_data, gold_standard_index=0):\n",
    "        self.aligned_data = aligned_data\n",
    "        self.gold_standard_df = self.aligned_data[gold_standard_index]\n",
    "        self.comparator_dfs = self.aligned_data[1:]\n",
    "\n",
    "    def plot_cost_benefit(self, costs, save_dir, labels):\n",
    "        # Ensure the directory exists\n",
    "        cost_benefit_dir = os.path.join(save_dir, \"cost_benefit\")\n",
    "        os.makedirs(cost_benefit_dir, exist_ok=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        \n",
    "        # Plotting each comparator's cost-benefit\n",
    "        for idx, (label, cost) in enumerate(zip(labels, costs)):\n",
    "            plt.plot(cost, label=f'{label} (GPT {4-idx})', marker='o')\n",
    "\n",
    "        plt.title('Cost-Benefit Analysis')\n",
    "        plt.xlabel('Cases Reviewed')\n",
    "        plt.ylabel('Net Benefit ($)')\n",
    "        plt.legend()\n",
    "\n",
    "        # Define the file names\n",
    "        file_name_png = \"cost_benefit_analysis.png\"\n",
    "        file_name_svg = \"cost_benefit_analysis.svg\"\n",
    "\n",
    "        # Construct the full file paths\n",
    "        path_png = os.path.join(cost_benefit_dir, file_name_png)\n",
    "        path_svg = os.path.join(cost_benefit_dir, file_name_svg)\n",
    "\n",
    "        # Save the plots as PNG and SVG\n",
    "        plt.savefig(path_png, format='png', bbox_inches='tight')\n",
    "        plt.savefig(path_svg, format='svg', bbox_inches='tight')\n",
    "\n",
    "        # Close the plot to avoid overlapping figures\n",
    "        plt.close()\n",
    "\n",
    "    # Call this method to generate the plot\n",
    "    def generate_and_save_plot(self, costs, labels, save_dir):\n",
    "        self.plot_cost_benefit(costs, save_dir, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CostBenefitPlotter with your data\n",
    "plotter = CostBenefitPlotter(aligner.aligned_data)\n",
    "\n",
    "# Define the costs for each comparator\n",
    "costs = [100, 50, 25]  # replace with actual costs for human, GPT-4, GPT-3 respectively\n",
    "\n",
    "# Define the labels for the plot\n",
    "labels = [\"Human Review\", \"GPT-4\", \"GPT-3\"]\n",
    "\n",
    "# Define the directory where you want to save the plots\n",
    "save_directory = \"/Users/cu135/Dropbox (Partners HealthCare)/studies/review_pyper/analyses\"\n",
    "\n",
    "# Generate and save the cost-benefit plot\n",
    "plotter.generate_and_save_plot(costs, labels, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
