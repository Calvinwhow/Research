{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Instructions\n",
    "This is a program which will create R-Maps. These are used to correlate a voxel to a continuous outcome measure.\n",
    "As it stands, this software employs Pearson Correlation Coefficients, which imply it will be best to have a continuous outcome on a percent scale. If you would like to do otherwise, a Spearman Correlation is possible. \n",
    "\n",
    "The software will walk you through everything. \n",
    "\n",
    "_____\n",
    "# Nifti Configuration\n",
    "\n",
    "**Files are expected to follow a BIDS naming convention.**\n",
    "\n",
    "**Files are expected to have subject ID in them which is identical to subject ID in the CSV**\n",
    "\n",
    "**Files are expected to be in 2x2x2 resolution**\n",
    "_____\n",
    "# CSV configuration:\n",
    "**Subject IDs expected to be in the nifti names**\n",
    "\n",
    "**Subject IDs expected to be in a column of your target CSV labelled \"subject\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Information\n",
    "\n",
    "-Enter the directory you would like to save to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/SANTE_DBS/derivatives/network_maps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Instructions**: Please fill out the `path` and `file_pattern` variables. \n",
    "\n",
    "The file_path is the shared base directory holding all files. ie) blah/blah/blah/BIDS\n",
    "\n",
    "The file_pattern is the shared naming architectur in all files ie)  * / * / * subT1 * .nii\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shared path to the folder/csv containing the nifti files/files paths for the neuroimaging files?\n",
    "path_1 = '/data/nimlab/dl_archive/sante_vtas_2year_outcome_superconservative_mask'\n",
    "\n",
    "#What is the shared file architecture of your neuroimaging files after the base path?\n",
    "file_pattern = '*/connectivity/*stat-t*.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search:  /data/nimlab/dl_archive/sante_vtas_2year_outcome_superconservative_mask/*/connectivity/*stat-t*.nii.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------------DO NOT TOUCH--------------------------------------------------------\n",
    "import os\n",
    "from calvin_utils.file_utils.import_matrices import import_matrices_from_folder\n",
    "df_1 = import_matrices_from_folder(path_1, file_pattern=file_pattern)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract Subject ID From File Names**\n",
    "Using the example filenames that have been printed above, please define a general string:\n",
    "1) Preceding the subject ID. For example in 04-mwp1glanat_resampled.nii, this is \" \"\n",
    "2) Proceeding the subject ID. For example in 04-mwp1glanat_resampled.nii, this is \"-mwp1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.dataframe_utilities import extract_and_rename_subject_id\n",
    "\n",
    "def preprocess_names(df, string_preceding_id, string_proceeding_id, cols=True):\n",
    "    \"\"\"\n",
    "    Preprocess the given dataframe by extracting and renaming the subject ID, \n",
    "    then transposing the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The dataframe to preprocess.\n",
    "    - string_preceding_id: String preceding the subject ID.\n",
    "    - string_proceeding_id: String proceeding the subject ID.\n",
    "\n",
    "    Returns:\n",
    "    - The preprocessed dataframe.\n",
    "    \"\"\"\n",
    "    split_command_dict = {string_preceding_id: 1, string_proceeding_id: 0}\n",
    "    if cols:\n",
    "        df = extract_and_rename_subject_id(dataframe=df, split_command_dict=split_command_dict).transpose()\n",
    "    else:\n",
    "        df = extract_and_rename_subject_id(dataframe=df, split_command_dict=split_command_dict)\n",
    "    df.index.name = 'subject'\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_preceding_id = 'sub-'\n",
    "string_proceeding_id = '_grey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = preprocess_names(df_1, string_preceding_id, string_proceeding_id)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the CSV which has your clinical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = '/PHShome/cu135/github_repository/Research/nimlab/notebooks/sante_memoryScore_twoYearOutcome.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a CSV with the clinical data of interest\n",
    "df_2 = pd.read_csv(path_2)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.loc[:, ['subject', 'Age', '% Change from baseline (ADAS-Cog11)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_column = 'subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_preceding_id = ''\n",
    "string_proceeding_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is expected there is a columnc called which has subject information in it. The information in this column must correspond in the dataframe above. If it does not exist, add it to your CSV before proceeding. \n",
    "\n",
    "Define the column below using:\n",
    "\n",
    "subject_colum = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from calvin_utils.statistical_utils.voxelwise_statistical_testing import generate_r_map\n",
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "\n",
    "def reset_index_if_subject_is_index(df, subject_column):\n",
    "    if subject_column in df.index.names:\n",
    "        df.reset_index(inplace=True)\n",
    "        # Reorder columns to make 'subject' the first column\n",
    "        cols = [subject_column] + [col for col in df.columns if col != subject_column]\n",
    "        df = df[cols]\n",
    "    return df\n",
    "\n",
    "def process_and_generate_maps(df_1, df_2, subject_column, out_dir, string_preceding_id, string_proceeding_id, mask_path=None, method='pearson'):\n",
    "    \"\"\"\n",
    "    Process the given dataframes, and generate maps based on the columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df_1: First dataframe.\n",
    "    - df_2: Second dataframe.\n",
    "    - subject_column: The column name referring to the subject.\n",
    "    - out_dir: The output directory to save the generated maps.\n",
    "    \"\"\"\n",
    "    # Check if 'subject' is in the index or columns for df_1\n",
    "    if subject_column in df_1.index.names:\n",
    "        df_1 = reset_index_if_subject_is_index(df_1, subject_column)\n",
    "    if subject_column in df_2.index.names:\n",
    "        df_2 = reset_index_if_subject_is_index(df_2, subject_column)\n",
    "        \n",
    "    df_1[subject_column] = df_1[subject_column].astype(str)\n",
    "    if all(df_2[subject_column].apply(lambda x: type(x) is str)):\n",
    "        if string_proceeding_id != '':\n",
    "            df_2[subject_column] = [name.split(string_proceeding_id)[0] for name in df_2[subject_column]]\n",
    "        if string_preceding_id != '':\n",
    "            df_2[subject_column] = [name.split(string_preceding_id)[1] for name in df_2[subject_column]]\n",
    "        print('extracting subject ID')\n",
    "    else:\n",
    "        df_2[subject_column] = df_2[subject_column].astype(str)\n",
    "\n",
    "    # Iterate over column, avoiding the one with subject id in it\n",
    "    for colname in [col for col in df_2.columns if col != subject_column]:\n",
    "        print(f'Working on {colname}')\n",
    "        merged_df = df_2[[colname, subject_column]].merge(df_1, on=subject_column, how='inner').set_index(subject_column)\n",
    "        \n",
    "        # Remove any rows with NaN values\n",
    "        copy_df = merged_df.copy()\n",
    "        try:\n",
    "            merged_df.dropna(inplace=True)\n",
    "            r_df, p_df, r_squared_df = generate_r_map(merged_df, mask_path=mask_path, method=method)\n",
    "\n",
    "            view_and_save_nifti(p_df, os.path.join(out_dir, 'p_map', colname))\n",
    "            view_and_save_nifti(r_df, os.path.join(out_dir, 'r_map', colname))\n",
    "            view_and_save_nifti(r_squared_df, os.path.join(out_dir, 'r_squared_map', colname))\n",
    "        except Exception as e:\n",
    "            if \"x and y must have length at least 2\" in str(e):\n",
    "                print('Caught exception: NaNs or Infs suspected in input data. Trying workaround.')\n",
    "                copy_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "                copy_df.fillna(0, inplace=True)\n",
    "                r_df, p_df, r_squared_df = generate_r_map(copy_df, mask_path=mask_path)\n",
    "\n",
    "                view_and_save_nifti(p_df, os.path.join(out_dir, 'p_map', colname))\n",
    "                view_and_save_nifti(r_df, os.path.join(out_dir, 'r_map', colname))\n",
    "                view_and_save_nifti(r_squared_df, os.path.join(out_dir, 'r_squared_map', colname))\n",
    "            else:\n",
    "                print(f'Error {e}')\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the name of the column that contains your subject labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mask_path = None\n",
    "merged_df = process_and_generate_maps(df_1.copy(), df_2.copy(), subject_column, out_dir, string_preceding_id, string_proceeding_id, mask_path=mask_path, method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your R-Maps have all been generated. Consider adding Calvin as a collaborator if this was useful!\n",
    "\n",
    "-- Calvin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Perform Delta R-Map and Permute it for Significance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the Observed Delta-R Map Between 2 Populations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.voxelwise_statistical_testing import generate_delta_r_map\n",
    "delta_matrix = merged_df.copy()\n",
    "observed_delta_r_map = generate_delta_r_map(delta_matrix, threshold_of_interest=65, column_of_interest='Age at DOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "view_and_save_nifti(observed_delta_r_map, (out_dir+'/over_vs_under_65_delta_r_map'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Empiric Delta-R Map Distribution \n",
    "### Note, this permutes the label of the population without permuting the neuroimaging data.\n",
    "### Therefore, we are testing if the separation of the r-maps is significantly due to the variable of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.voxelwise_statistical_testing import permuted_patient_label_delta_r_map\n",
    "from calvin_utils.file_utils.print_suppression import HiddenPrints\n",
    "n_permutations = 2\n",
    "column_of_interest = 'Age at DOS'\n",
    "threshold_of_interest = 65\n",
    "with HiddenPrints():\n",
    "    p_count_df = permuted_patient_label_delta_r_map(dataframe_to_permute=merged_df, \n",
    "                                                observed_delta_r_map=observed_delta_r_map, \n",
    "                                                column_of_interest=column_of_interest, \n",
    "                                                threshold_of_interest=threshold_of_interest, \n",
    "                                                n_permutations=n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "view_and_save_nifti(p_values_df, (out_dir+'/over_vs_under_65_delta_r_map_p_values_df'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy\n",
    "\n",
    "--Calvin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
