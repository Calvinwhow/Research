{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Any Kind of OLS Regression (ANOVA, GLM, Logit, etc.)\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: May 5, 2024\n",
    "\n",
    "Use this to run/test a statistical model (e.g., regression or T-tests) on a spreadsheet containing covariates and brain image (nii/gii) paths. \n",
    "\n",
    "Notes:\n",
    "- For this to work, it must be installed onto wherever you want to run it. You must run:\n",
    "```\n",
    "> git clone https://github.com/Calvinwhow/Research.git\n",
    "> cd nimlab/calvin_utils\n",
    "> pip install -e .\n",
    "```\n",
    "- To best use this notebook, you should be familar with GLM design and Contrast Matrix design. See this webpage to get started:\n",
    "[FSL's GLM page](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Output Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Dropbox (Partners HealthCare)/studies/voxelwise_lin_reg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Dropbox (Partners HealthCare)/studies/voxelwise_lin_reg/experimental_group_master_list.csv'\n",
    "sheet = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Age', 'Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'City'  # The column you'd like to evaluate\n",
    "# condition = 'not'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "# value = 'Toronto' # The value to drop if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "# display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove anything you don't want to standardize\n",
    "# cols_not_to_standardize = None # ['Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group', 'Z_Scored_Subiculum_T_By_Origin_Group_'] #['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Define Your Formula\n",
    "\n",
    "This is the formula relating outcome to predictors, and takes the form:\n",
    "- y = B0 + B1 + B2 + B3 + . . . BN\n",
    "\n",
    "It is defined using the columns of your dataframe instead of the variables above:\n",
    "- 'Apples_Picked ~ hours_worked + owns_apple_picking_machine'\n",
    "\n",
    "____\n",
    "**ANOVA**\n",
    "- Tests differences in means for one categorical variable.\n",
    "- formula = 'Outcome ~ C(Group1)'\n",
    "\n",
    "**2-Way ANOVA**\n",
    "- Tests differences in means for two categorical variables without interaction.\n",
    "- formula = 'Outcome ~ C(Group1) + C(Group2)'\n",
    "\n",
    "**2-Way ANOVA with Interaction**\n",
    "- Tests for interaction effects between two categorical variables.\n",
    "- formula = 'Outcome ~ C(Group1) * C(Group2)'\n",
    "\n",
    "**ANCOVA**\n",
    "- Similar to ANOVA, but includes a covariate to control for its effect.\n",
    "- formula = 'Outcome ~ C(Group1) + Covariate'\n",
    "\n",
    "**2-Way ANCOVA**\n",
    "- Extends ANCOVA with two categorical variables and their interaction, controlling for a covariate.\n",
    "- formula = 'Outcome ~ C(Group1) * C(Group2) + Covariate'\n",
    "\n",
    "**Multiple Regression**\n",
    "- Assesses the impact of multiple predictors on an outcome.\n",
    "- formula = 'Outcome ~ Predictor1 + Predictor2'\n",
    "\n",
    "**Simple Linear Regression**\n",
    "- Assesses the impact of a single predictor on an outcome.\n",
    "- formula = 'Outcome ~ Predictor'\n",
    "\n",
    "**MANOVA**\n",
    "- Assesses multiple dependent variables across groups.\n",
    "- Note: Not typically set up with a formula in statsmodels. Requires specialized functions.\n",
    "\n",
    "____\n",
    "Use the printout below to design your formula. \n",
    "- Left of the \"~\" symbol is the thing to be predicted. \n",
    "- Right of the \"~\" symbol are the predictors. \n",
    "- \":\" indicates an interaction between two things. \n",
    "- \"*\" indicates and interactions AND it accounts for the simple effects too. \n",
    "- \"+\" indicates that you want to add another predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"Q4 ~ CSF_Z6_PATH + Age + Sex\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Visualize Your Design Matrix\n",
    "\n",
    "This is the explanatory variable half of your regression formula\n",
    "_______________________________________________________\n",
    "Create Design Matrix: Use the create_design_matrix method. You can provide a list of formula variables which correspond to column names in your dataframe.\n",
    "\n",
    "- voxelwise_variable = name of the variable in your formula which contains nifti paths.\n",
    "- By default, an intercept will be added unless you set intercept=False\n",
    "- **don't explicitly add the 'intercept' column. I'll do it for you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelwise_variable='CSF_Z6_PATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the design matrix\n",
    "outcome_df, design_matrix_df = cal_palm.define_design_matrix(formula, data_df, voxelwise_variable=voxelwise_variable)\n",
    "design_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Visualize Your Dependent Variable\n",
    "\n",
    "I have generated this for you based on the formula you provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Generate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.dataframe_utilities import save_design_matrix_to_csv\n",
    "design_matrix_path = save_design_matrix_to_csv(design_matrix_df, out_dir = (out_dir+\"/server_prep\"))\n",
    "print(design_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.import_functions import GiiNiiFileImport\n",
    "GiiNii = GiiNiiFileImport(import_path=design_matrix_path, file_column=voxelwise_variable, file_pattern=None)\n",
    "voxelwise_df = GiiNii.run()\n",
    "voxelwise_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, mask_ind, voxelwise_df = GiiNii.mask_dataframe(voxelwise_df)\n",
    "voxelwise_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Save Data For Access by Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.dataframe_utilities import save_dataframes_to_csv\n",
    "\n",
    "where_to_save = f\"{out_dir}/server_prep\"\n",
    "#----------------------------------------------------------------\n",
    "df_paths_dict = save_dataframes_to_csv(outcome_dfs = [outcome_df], \n",
    "                                       covariate_dfs = [design_matrix_df.drop(voxelwise_variable, axis=1)],\n",
    "                                       voxelwise_dfs = [voxelwise_df], \n",
    "                                       path_to_dataframes = where_to_save)\n",
    "print(\"CSVs saved to: \", df_paths_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Choose the Python Script you Want to Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script: launch_f_test_palm.py\n",
      "Method: F-Test\n",
      "README: This script performs voxelwise interaction F-statistic permutation tests on provided outcomes, clinical covariates, and voxelwise neuroimaging data. User input is required to define the number of permutations, the output directory, job name, and paths to the outcome, clinical covariate, and neuroimaging data. The script uses multiprocessing for efficient computation of the permutation tests. It generates permuted versions of the patient labels in the input data and calculates the F-statistic for each permutation. The results are saved to the output directory, with each permutation result stored in a separate csv file.\n",
      "Inputs:\n",
      "    n_cores: The number of cores per job submission cpu (4 is a good default).\n",
      "    out_dir: The output directory where the result csv files will be saved.\n",
      "    job_name: The job name for identification.\n",
      "    memory_per_job: The memory (in gigabytes) per job submission cpu. General max is 40 up to 498 Gb.\n",
      "    outcome_data_path: The path to the outcome data csv file.\n",
      "    clinical_covariate_paths: The paths to the clinical covariate data csv files.\n",
      "---\n",
      "Script: launch_voxelwise_fit_test_palm.py\n",
      "Method: Voxelwise_Fit_Test\n",
      "README: This script extracts voxelwise r-squared of provided outcomes on clinical covariates and voxelwise neuroimaging data. User input is required to define the number of permutations, the output directory, job name, and paths to the outcome, clinical covariate, and neuroimaging data. The script uses multiprocessing for efficient computation of the permutation tests. It generates permuted versions of the patient labels in the input data and calculates the t-statistic for each permutation. The results are saved to the output directory, with each permutation result stored in a separate csv file.\n",
      "Inputs:\n",
      "    n_cores: The number of cores per job submission cpu (4 is a good default).\n",
      "    out_dir: The output directory where the result csv files will be saved.\n",
      "    job_name: The job name for identification. Can be anything.\n",
      "    memory_per_job: The memory (in gigabytes) per job submission cpu. General max is 40 up to 498 Gb.\n",
      "    outcome_data_path: remote_df_paths_dict['outcomes']\n",
      "    clinical_covariate_paths: remote_df_paths_dict['covariates']\n",
      "    neuroimaging_df_paths: remote_df_paths_dict['voxelwise']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.file_utils.script_printer import ScriptInfo\n",
    "from calvin_utils.permutation_analysis_utils.scripts_for_submission.script_descriptions import script_dict\n",
    "info = ScriptInfo(script_dict)\n",
    "info.print_all_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a script, copy the value of the 'Method' field that you want to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_choice = 'Voxelwise_Fit_Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Transfer Files to Server\n",
    "- Make sure remote_path_to_save_to exists on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_path_to_save_to = '/PHShome/cu135/server_inputs/test'\n",
    "server = \"erisone.partners.org\"\n",
    "username=\"cu135\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from calvin_utils.server_utils.file_transfer_helper import ScpTransfer\n",
    "df_paths_dict['python_script'] = [importlib.import_module(info.get_module_by_method(method_choice)).__file__]\n",
    "scp_transfer = ScpTransfer(hostname=server,\n",
    "                           username=username, \n",
    "                           ssh_key=None\n",
    "                        )\n",
    "remote_df_paths_dict = scp_transfer.transfer_files_in_dict(dict_files=df_paths_dict, \n",
    "                                    base_remote_path=remote_path_to_save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Prepare Script Inputs\n",
    "- below argument will output require arguments for your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43minfo\u001b[49m\u001b[38;5;241m.\u001b[39mget_inputs_by_method(method_choice)\n\u001b[1;32m      2\u001b[0m inputs\n",
      "\u001b[0;31mNameError\u001b[0m: name 'info' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = info.get_inputs_by_method(method_choice)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter Arguments for a Script**\n",
    "\n",
    "Copy the dictionary printed above into the cell below and fill it out. \n",
    "- You do not need to edit that keys with _paths/_path in them.\n",
    "\n",
    "Example:\n",
    "```\n",
    " script_inputs_dict =\n",
    "  {\n",
    " 'n_cores': 16,\n",
    " 'out_dir': \"/PHShome/cu135/permutation_tests/f_test/age_by_stim_ad_dbs_redone/results/tmp\",\n",
    " 'job_name': 'ftest_bm',\n",
    " 'memory_per_job': 8,\n",
    " 'outcome_data_path': remote_df_paths_dict['outcomes'],\n",
    " 'clinical_covariate_paths': remote_df_paths_dict['covariates'],\n",
    " 'voxelwise_data_paths': remote_df_paths_dict['voxelwise']\n",
    " }\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_inputs_dict = {\n",
    " 'n_cores': 5,\n",
    " 'out_dir': f\"{remote_path_to_save_to}/results/raw_results\",\n",
    " 'job_name': 't_test_coef',\n",
    " 'memory_per_job': 8,\n",
    " 'outcome_data_path': remote_df_paths_dict['outcomes'],\n",
    " 'clinical_covariate_paths': remote_df_paths_dict['covariates'],\n",
    " 'neuroimaging_df_paths': remote_df_paths_dict['voxelwise']\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Submit Jobs to Server\n",
    "- user_email = You need to enter the email associated with the server\n",
    "- num_permutations = You need to enter the amount of times this will be permuted\n",
    "- queue_name = you need to enter the LSF queue to use\n",
    "- server_env_activation_string = the string that engages your environment in the server. \n",
    "```\n",
    "Example:\n",
    "user_email = \"choward12@bwh.harvard.edu\"\n",
    "num_permutations = 10000\n",
    "queue_name = \"big-multi\"\n",
    "server_env_activation_string = \"conda activate nimlab\"\n",
    "```\n",
    "Want more information on server submission?\n",
    "- https://rc.partners.org/kb/article/1462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_email = \"choward12@bwh.harvard.edu\"\n",
    "num_permutations = 10000\n",
    "queue_name = \"short\"\n",
    "server_env_activation_string = \"conda activate nimlab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from calvin_utils.server_utils.job_submission_helper import LSFServer, LSFJob, JobSubmitter\n",
    "lsf_job = LSFJob(job_name=script_inputs_dict['job_name'],\n",
    "                 user_email=user_email,\n",
    "                 output_dir=\"~/terminal_outputs\",\n",
    "                 error_dir=\"~/terminal_outputs\",\n",
    "                 queue=queue_name,\n",
    "                 n_jobs=int(np.round(num_permutations/script_inputs_dict['n_cores'])),\n",
    "                 cpus=script_inputs_dict['n_cores'],\n",
    "                 gb_requested=script_inputs_dict['memory_per_job'],\n",
    "                 wait_time=None,\n",
    "                 script_path=remote_df_paths_dict['python_script'][0],\n",
    "                 environment_activation_string=server_env_activation_string,\n",
    "                 options=script_inputs_dict\n",
    "                 )\n",
    "\n",
    "lsf_server = LSFServer(server_name=server, \n",
    "                       username=username)\n",
    "\n",
    "job_submitter = JobSubmitter(lsf_server, lsf_job)\n",
    "job_command = job_submitter.submit_jobs(print_job=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Get the Observed Data\n",
    "- Call the function of interest the docstring which will be printed below. \n",
    "- The function will be the final part of the import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from calvin_utils.statistical_utils.voxelwise_statistical_testing import voxelwise_r_squared\n",
      "print(voxelwise_r_squared.__doc__)\n",
      "\n",
      "    Perform voxelwise regression using numpy arrays and Statsmodels, calculating R-squared for each voxel.\n",
      "    \n",
      "    Parameters:\n",
      "        outcome_df (pd.DataFrame): DataFrame containing the outcome variable with observations in rows.\n",
      "        predictor_neuroimaging_dfs (list of pd.DataFrame): List of DataFrames with neuroimaging data, observations in rows, voxels in columns.\n",
      "        predictor_covariate_dfs (list of pd.DataFrame): List of DataFrames with covariate data, observations in rows.\n",
      "\n",
      "    Returns:\n",
      "        results_df (pd.DataFrame): DataFrame containing R-squared for each voxel.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import_statement = info.get_script_import(method_choice)\n",
    "docstring_statement = info.get_docstring(method_choice)\n",
    "print(import_statement)\n",
    "print(docstring_statement)\n",
    "exec(import_statement)\n",
    "exec(docstring_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the paths to the local CSVs to enter your arguments\n",
    "\n",
    "Example\n",
    "```\n",
    "results = voxelwise_r_squared(outcome_df, [voxelwise_df], [design_matrix_df.drop(voxelwise_variable, axis=1)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "voxelwise_r_squared() got an unexpected keyword argument 'get_coefficients'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvoxelwise_r_squared\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutcome_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvoxelwise_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdesign_matrix_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxelwise_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_coefficients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: voxelwise_r_squared() got an unexpected keyword argument 'get_coefficients'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "results = voxelwise_r_squared(outcome_df, [voxelwise_df], [design_matrix_df.drop(voxelwise_variable, axis=1)], get_coefficients=True)\n",
    "results.to_csv(os.path.join(out_dir, 'results/results.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unmask, Save, and Visualize Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "view_and_save_nifti(GiiNii.unmask_dataframe(results['R_squared']), os.path.join(out_dir, 'results'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Get the permutation data\n",
    "- This code uses a file-staging approach to large-scale computation. The resultant files have been saved to your output directory. You must now recompose them. \n",
    "- From this point forward, you will want to upload this notebook to the server and run it from there. Could also download the remote files to local via SCP if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_csvs(directory, output_filename):\n",
    "    \"\"\"\n",
    "    Combine all CSV files in a directory into a single CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): The path to the directory containing the CSV files.\n",
    "    - output_filename (str): The path to the output CSV file.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Get a list of all CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith(\".csv\")]\n",
    "\n",
    "    # Loop through the CSV files and append each one to the combined DataFrame\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(directory, csv_file))\n",
    "        combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "    # Save the combined DataFrame as a new CSV file\n",
    "    combined_df.to_csv(output_filename, index=False)\n",
    "    return output_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomposed_csv_path = combine_csvs(\"/path/to/your/directory\", \"combined.csv\")\n",
    "recomposed_csv_df = pd.read_csv(recomposed_csv_path)\n",
    "recomposed_csv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 -  Calculate FWE-Corrected P-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statistical_utils.p_value_statistics import PermutationPValueCalculator\n",
    "\n",
    "first_stage_dir = 'permutation_tests/f_test/age_by_stim_pd_dbs_redone/inputs/results/raw_results'\n",
    "job_name = 'f_test_pd'\n",
    "observed_nifti_path = '/PHShome/cu135/permutation_tests/f_test/age_by_stim_pd_dbs_redone/inputs/observed/f_statistic_generated_nifti.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = PermutationPValueCalculator(None, None)\n",
    "fwe_p_values = calculator.fwe_calculate(directory=first_stage_dir, basename=job_name, nifti_path=None, use_nifti=True, multiprocess=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
