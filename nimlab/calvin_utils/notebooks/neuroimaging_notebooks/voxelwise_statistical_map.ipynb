{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import glob as glob\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Calculate Correlation\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform\n",
    "\n",
    "from calvin_utils.generate_nifti import view_and_save_nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have set pathnames in the Mac style\n",
      "I will save to : /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/response_topology/voxelwise_mediated_moderation/age_mediated_by_grey_matter\n"
     ]
    }
   ],
   "source": [
    "analysis = 'response_topology/voxelwise_mixed_effects/age_mediated_by_grey_matter'\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    conn_path = r'/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/grey_matter_damage_score_and_outcomes.csv'\n",
    "    clin_path = r'/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/grey_matter_damage_score_and_outcomes.csv'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = os.path.join(os.path.dirname(conn_path), f'{analysis}')\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/analyses/roi-roi_correl/addbs_vta_to_memory_net_maxima/matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    \n",
    "    print('I have set pathnames in the Mac style')\n",
    "    print('I will save to :', out_dir)\n",
    "else: #----------------------------------------------------------------Windows----------------------------------------------------------------\n",
    "    conn_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_AvgR.csv'\n",
    "    clin_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\patient_data\\AD_Clinical_Data_CDR_ADAS_COG_13.xlsx'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\AD_to_memory_net'\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    print('I have set pathnames in the Windows style')\n",
    "    \n",
    "save = True\n",
    "if os.path.exists(out_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient # CDR, ADAS</th>\n",
       "      <th>Age</th>\n",
       "      <th>% Change from baseline (ADAS-Cog11)</th>\n",
       "      <th>Subiculum Connectivity</th>\n",
       "      <th>Subiculum Damage Score</th>\n",
       "      <th>Hippocampus Damage Score</th>\n",
       "      <th>Temporal Damage Score</th>\n",
       "      <th>Frontal Damage Score</th>\n",
       "      <th>Parietal Damage Score</th>\n",
       "      <th>Cerebellum Damage Score</th>\n",
       "      <th>Insula Damage Score</th>\n",
       "      <th>Occipital Damage Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>56.864683</td>\n",
       "      <td>-22.341183</td>\n",
       "      <td>-19032.589510</td>\n",
       "      <td>-6811.832831</td>\n",
       "      <td>-3390.513012</td>\n",
       "      <td>-6514.359274</td>\n",
       "      <td>-1733.125937</td>\n",
       "      <td>-133.189922</td>\n",
       "      <td>-4146.074230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>52.970984</td>\n",
       "      <td>-40.309051</td>\n",
       "      <td>-184720.025100</td>\n",
       "      <td>-12864.565970</td>\n",
       "      <td>-6136.065565</td>\n",
       "      <td>-4548.582996</td>\n",
       "      <td>-5422.573735</td>\n",
       "      <td>-622.591915</td>\n",
       "      <td>-3965.251674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>62.459631</td>\n",
       "      <td>-19.785287</td>\n",
       "      <td>-45387.958520</td>\n",
       "      <td>-6591.622671</td>\n",
       "      <td>-8075.228864</td>\n",
       "      <td>-4447.485410</td>\n",
       "      <td>-3607.025644</td>\n",
       "      <td>-624.924211</td>\n",
       "      <td>-2512.288860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>59.611631</td>\n",
       "      <td>-42.332132</td>\n",
       "      <td>-60471.819480</td>\n",
       "      <td>-11699.796100</td>\n",
       "      <td>-6244.075797</td>\n",
       "      <td>-5212.034938</td>\n",
       "      <td>-3227.497127</td>\n",
       "      <td>-570.463181</td>\n",
       "      <td>-2934.581194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>57.928350</td>\n",
       "      <td>-2.136441</td>\n",
       "      <td>-5968.011901</td>\n",
       "      <td>-4662.284230</td>\n",
       "      <td>-6429.216510</td>\n",
       "      <td>-4540.145985</td>\n",
       "      <td>-1893.423398</td>\n",
       "      <td>-299.251771</td>\n",
       "      <td>-2070.284124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>66</td>\n",
       "      <td>-38.461538</td>\n",
       "      <td>63.323903</td>\n",
       "      <td>-26.237501</td>\n",
       "      <td>-29471.040290</td>\n",
       "      <td>-2479.701861</td>\n",
       "      <td>-2121.181555</td>\n",
       "      <td>-2841.442623</td>\n",
       "      <td>-1631.143552</td>\n",
       "      <td>-120.128438</td>\n",
       "      <td>-2222.047928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>64</td>\n",
       "      <td>-15.384615</td>\n",
       "      <td>53.317851</td>\n",
       "      <td>-43.667344</td>\n",
       "      <td>-118201.273400</td>\n",
       "      <td>-11646.437390</td>\n",
       "      <td>-7046.077001</td>\n",
       "      <td>-8392.540599</td>\n",
       "      <td>-2361.515431</td>\n",
       "      <td>-614.793778</td>\n",
       "      <td>-6163.741802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>60</td>\n",
       "      <td>-29.166667</td>\n",
       "      <td>57.979468</td>\n",
       "      <td>-62.535677</td>\n",
       "      <td>-66947.522780</td>\n",
       "      <td>-10926.588590</td>\n",
       "      <td>-4526.665072</td>\n",
       "      <td>-5782.261434</td>\n",
       "      <td>-3820.805562</td>\n",
       "      <td>-263.752339</td>\n",
       "      <td>-3537.170972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>72</td>\n",
       "      <td>-30.434783</td>\n",
       "      <td>66.950749</td>\n",
       "      <td>-22.137900</td>\n",
       "      <td>-75270.490460</td>\n",
       "      <td>-11252.394020</td>\n",
       "      <td>-5240.470247</td>\n",
       "      <td>-4707.095249</td>\n",
       "      <td>-1171.115413</td>\n",
       "      <td>-261.459686</td>\n",
       "      <td>-3628.614588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>72</td>\n",
       "      <td>-84.615385</td>\n",
       "      <td>69.267271</td>\n",
       "      <td>-6.545406</td>\n",
       "      <td>-40392.854920</td>\n",
       "      <td>-7111.854909</td>\n",
       "      <td>-9629.498968</td>\n",
       "      <td>-5124.972435</td>\n",
       "      <td>-1647.853988</td>\n",
       "      <td>-1035.648091</td>\n",
       "      <td>-2358.679568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "      <td>62</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>83.621480</td>\n",
       "      <td>-12.031371</td>\n",
       "      <td>-13754.352350</td>\n",
       "      <td>-3693.768595</td>\n",
       "      <td>-3585.812811</td>\n",
       "      <td>-2881.090806</td>\n",
       "      <td>-1377.749893</td>\n",
       "      <td>-188.327720</td>\n",
       "      <td>-2034.825096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112</td>\n",
       "      <td>69</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>77.334117</td>\n",
       "      <td>-95.005208</td>\n",
       "      <td>-238543.225100</td>\n",
       "      <td>-9523.372702</td>\n",
       "      <td>-5231.188795</td>\n",
       "      <td>-3341.870796</td>\n",
       "      <td>-3867.663215</td>\n",
       "      <td>-403.955119</td>\n",
       "      <td>-2157.941629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>69</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>69.758721</td>\n",
       "      <td>-28.902412</td>\n",
       "      <td>-20892.641060</td>\n",
       "      <td>-8944.256581</td>\n",
       "      <td>-6250.756779</td>\n",
       "      <td>-7337.594881</td>\n",
       "      <td>-3992.983769</td>\n",
       "      <td>-345.287600</td>\n",
       "      <td>-5010.695407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114</td>\n",
       "      <td>67</td>\n",
       "      <td>-16.129032</td>\n",
       "      <td>67.432125</td>\n",
       "      <td>-73.956802</td>\n",
       "      <td>-138175.964700</td>\n",
       "      <td>-20303.315100</td>\n",
       "      <td>-7626.091153</td>\n",
       "      <td>-4493.410344</td>\n",
       "      <td>-9078.765183</td>\n",
       "      <td>-534.608502</td>\n",
       "      <td>-3921.427002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>-48.275862</td>\n",
       "      <td>71.155530</td>\n",
       "      <td>-55.794428</td>\n",
       "      <td>-77705.598780</td>\n",
       "      <td>-12366.613620</td>\n",
       "      <td>-7079.020043</td>\n",
       "      <td>-6185.281536</td>\n",
       "      <td>-4449.870736</td>\n",
       "      <td>-344.366289</td>\n",
       "      <td>-4375.606746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>116</td>\n",
       "      <td>67</td>\n",
       "      <td>-36.842105</td>\n",
       "      <td>61.952527</td>\n",
       "      <td>-6.821094</td>\n",
       "      <td>-17218.510150</td>\n",
       "      <td>-5963.165041</td>\n",
       "      <td>-4304.940185</td>\n",
       "      <td>-4418.202940</td>\n",
       "      <td>-1553.586900</td>\n",
       "      <td>-180.264656</td>\n",
       "      <td>-3008.989926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>118</td>\n",
       "      <td>52</td>\n",
       "      <td>-3.125000</td>\n",
       "      <td>72.547473</td>\n",
       "      <td>-22.352065</td>\n",
       "      <td>-114358.150900</td>\n",
       "      <td>-14600.125320</td>\n",
       "      <td>-8886.139697</td>\n",
       "      <td>-12491.789050</td>\n",
       "      <td>-7235.494986</td>\n",
       "      <td>-663.292110</td>\n",
       "      <td>-7237.065212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>119</td>\n",
       "      <td>75</td>\n",
       "      <td>-81.250000</td>\n",
       "      <td>62.118622</td>\n",
       "      <td>-80.977992</td>\n",
       "      <td>-80659.902680</td>\n",
       "      <td>-11727.167460</td>\n",
       "      <td>-6611.196011</td>\n",
       "      <td>-3294.535386</td>\n",
       "      <td>-3543.337851</td>\n",
       "      <td>-305.225658</td>\n",
       "      <td>-3419.852691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>68</td>\n",
       "      <td>-27.777778</td>\n",
       "      <td>60.940570</td>\n",
       "      <td>-26.846372</td>\n",
       "      <td>-11517.494530</td>\n",
       "      <td>-4609.255396</td>\n",
       "      <td>-4921.028744</td>\n",
       "      <td>-7256.070788</td>\n",
       "      <td>-813.292149</td>\n",
       "      <td>-99.219263</td>\n",
       "      <td>-3763.409731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>-4.347826</td>\n",
       "      <td>71.223601</td>\n",
       "      <td>-184.169968</td>\n",
       "      <td>-369157.398200</td>\n",
       "      <td>-18978.105100</td>\n",
       "      <td>-6794.609698</td>\n",
       "      <td>-5127.901253</td>\n",
       "      <td>-4454.601461</td>\n",
       "      <td>-704.129882</td>\n",
       "      <td>-3015.647349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>122</td>\n",
       "      <td>58</td>\n",
       "      <td>-140.000000</td>\n",
       "      <td>68.856418</td>\n",
       "      <td>-47.902605</td>\n",
       "      <td>-55394.394800</td>\n",
       "      <td>-10489.824720</td>\n",
       "      <td>-7463.500501</td>\n",
       "      <td>-6603.433336</td>\n",
       "      <td>-4492.723196</td>\n",
       "      <td>-479.387821</td>\n",
       "      <td>-4013.620186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>123</td>\n",
       "      <td>47</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>64.525483</td>\n",
       "      <td>-4.567961</td>\n",
       "      <td>-1923.146865</td>\n",
       "      <td>-3381.584935</td>\n",
       "      <td>-4489.507707</td>\n",
       "      <td>-3867.214918</td>\n",
       "      <td>-4560.337124</td>\n",
       "      <td>-288.228900</td>\n",
       "      <td>-2532.803295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>124</td>\n",
       "      <td>61</td>\n",
       "      <td>-18.750000</td>\n",
       "      <td>60.270662</td>\n",
       "      <td>-81.799781</td>\n",
       "      <td>-50587.278130</td>\n",
       "      <td>-5624.134019</td>\n",
       "      <td>-6845.636117</td>\n",
       "      <td>-5610.080427</td>\n",
       "      <td>-4167.216482</td>\n",
       "      <td>-314.517213</td>\n",
       "      <td>-2770.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>125</td>\n",
       "      <td>73</td>\n",
       "      <td>-37.500000</td>\n",
       "      <td>71.676110</td>\n",
       "      <td>-85.122956</td>\n",
       "      <td>-144614.746500</td>\n",
       "      <td>-15075.909790</td>\n",
       "      <td>-10748.591850</td>\n",
       "      <td>-7451.648700</td>\n",
       "      <td>-2671.257200</td>\n",
       "      <td>-921.641769</td>\n",
       "      <td>-3832.411856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>126</td>\n",
       "      <td>69</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>76.111573</td>\n",
       "      <td>-23.751946</td>\n",
       "      <td>-10242.398380</td>\n",
       "      <td>-3500.827181</td>\n",
       "      <td>-4844.584373</td>\n",
       "      <td>-3467.456477</td>\n",
       "      <td>-4047.535956</td>\n",
       "      <td>-184.064613</td>\n",
       "      <td>-2312.979624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>127</td>\n",
       "      <td>74</td>\n",
       "      <td>-76.470588</td>\n",
       "      <td>67.387791</td>\n",
       "      <td>-76.812351</td>\n",
       "      <td>-64351.946610</td>\n",
       "      <td>-8245.176231</td>\n",
       "      <td>-7644.884365</td>\n",
       "      <td>-6040.602962</td>\n",
       "      <td>-2015.988509</td>\n",
       "      <td>-284.263616</td>\n",
       "      <td>-4346.323336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>128</td>\n",
       "      <td>72</td>\n",
       "      <td>-20.833333</td>\n",
       "      <td>75.530777</td>\n",
       "      <td>-29.973764</td>\n",
       "      <td>-44817.434530</td>\n",
       "      <td>-3306.320133</td>\n",
       "      <td>-4980.904424</td>\n",
       "      <td>-3681.150660</td>\n",
       "      <td>-3146.217962</td>\n",
       "      <td>-486.817516</td>\n",
       "      <td>-2247.277587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>129</td>\n",
       "      <td>69</td>\n",
       "      <td>-35.714286</td>\n",
       "      <td>77.657909</td>\n",
       "      <td>-28.137744</td>\n",
       "      <td>-26351.409550</td>\n",
       "      <td>-4411.689549</td>\n",
       "      <td>-5746.775045</td>\n",
       "      <td>-2270.854148</td>\n",
       "      <td>-6398.033519</td>\n",
       "      <td>-155.356805</td>\n",
       "      <td>-1721.492551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>-7.142857</td>\n",
       "      <td>65.993904</td>\n",
       "      <td>-44.005146</td>\n",
       "      <td>-93191.241950</td>\n",
       "      <td>-5214.340386</td>\n",
       "      <td>-4257.545930</td>\n",
       "      <td>-4766.378101</td>\n",
       "      <td>-456.086505</td>\n",
       "      <td>-281.212952</td>\n",
       "      <td>-2504.662255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>131</td>\n",
       "      <td>68</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>71.997755</td>\n",
       "      <td>-44.815724</td>\n",
       "      <td>-171675.718000</td>\n",
       "      <td>-7237.769982</td>\n",
       "      <td>-3947.998068</td>\n",
       "      <td>-2482.752741</td>\n",
       "      <td>-341.971196</td>\n",
       "      <td>-389.386114</td>\n",
       "      <td>-1175.914302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>133</td>\n",
       "      <td>74</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>74.948112</td>\n",
       "      <td>-16.910131</td>\n",
       "      <td>-8658.442261</td>\n",
       "      <td>-2079.519127</td>\n",
       "      <td>-1936.904785</td>\n",
       "      <td>-2391.334029</td>\n",
       "      <td>-1352.709505</td>\n",
       "      <td>-92.142653</td>\n",
       "      <td>-1312.357225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>134</td>\n",
       "      <td>66</td>\n",
       "      <td>29.411765</td>\n",
       "      <td>72.265483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-25820.100230</td>\n",
       "      <td>-7365.386021</td>\n",
       "      <td>-4637.062081</td>\n",
       "      <td>-3256.034550</td>\n",
       "      <td>-8106.699579</td>\n",
       "      <td>-240.710562</td>\n",
       "      <td>-3622.008690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>135</td>\n",
       "      <td>57</td>\n",
       "      <td>-45.714286</td>\n",
       "      <td>63.361510</td>\n",
       "      <td>-107.847728</td>\n",
       "      <td>-28689.173250</td>\n",
       "      <td>-8597.692107</td>\n",
       "      <td>-26571.216700</td>\n",
       "      <td>-23014.222320</td>\n",
       "      <td>-2793.000014</td>\n",
       "      <td>-574.808714</td>\n",
       "      <td>-6970.681570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>137</td>\n",
       "      <td>57</td>\n",
       "      <td>-77.272727</td>\n",
       "      <td>65.596015</td>\n",
       "      <td>-90.498595</td>\n",
       "      <td>-51721.325030</td>\n",
       "      <td>-13259.247540</td>\n",
       "      <td>-23115.678970</td>\n",
       "      <td>-18364.252020</td>\n",
       "      <td>-1694.974868</td>\n",
       "      <td>-1074.569077</td>\n",
       "      <td>-7437.703600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>138</td>\n",
       "      <td>72</td>\n",
       "      <td>-9.523810</td>\n",
       "      <td>80.611188</td>\n",
       "      <td>-110.281101</td>\n",
       "      <td>-158350.400300</td>\n",
       "      <td>-13516.414110</td>\n",
       "      <td>-16741.707800</td>\n",
       "      <td>-7529.170754</td>\n",
       "      <td>-5872.060528</td>\n",
       "      <td>-406.795302</td>\n",
       "      <td>-4661.716394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>139</td>\n",
       "      <td>58</td>\n",
       "      <td>-105.882353</td>\n",
       "      <td>61.050691</td>\n",
       "      <td>-52.659681</td>\n",
       "      <td>-4939.292040</td>\n",
       "      <td>-5003.799265</td>\n",
       "      <td>-9410.595931</td>\n",
       "      <td>-6628.105057</td>\n",
       "      <td>-3012.111321</td>\n",
       "      <td>-67.471980</td>\n",
       "      <td>-5906.793172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>140</td>\n",
       "      <td>73</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>72.686647</td>\n",
       "      <td>-183.755533</td>\n",
       "      <td>-139589.841700</td>\n",
       "      <td>-16907.478320</td>\n",
       "      <td>-12569.795820</td>\n",
       "      <td>-11001.985840</td>\n",
       "      <td>-9366.484488</td>\n",
       "      <td>-320.939000</td>\n",
       "      <td>-16475.540660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>141</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.829337</td>\n",
       "      <td>-40.475229</td>\n",
       "      <td>-77408.191470</td>\n",
       "      <td>-5278.497697</td>\n",
       "      <td>-8987.320434</td>\n",
       "      <td>-2990.976958</td>\n",
       "      <td>-2374.593897</td>\n",
       "      <td>-84.896518</td>\n",
       "      <td>-1982.402247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>142</td>\n",
       "      <td>77</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>69.979040</td>\n",
       "      <td>-20.287737</td>\n",
       "      <td>-35966.511840</td>\n",
       "      <td>-4016.577659</td>\n",
       "      <td>-3321.383587</td>\n",
       "      <td>-3206.440006</td>\n",
       "      <td>-2173.416102</td>\n",
       "      <td>-292.265096</td>\n",
       "      <td>-2935.410909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>143</td>\n",
       "      <td>71</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>66.339918</td>\n",
       "      <td>-36.619337</td>\n",
       "      <td>-111306.638300</td>\n",
       "      <td>-9443.699760</td>\n",
       "      <td>-7654.818729</td>\n",
       "      <td>-5476.623021</td>\n",
       "      <td>-3205.121809</td>\n",
       "      <td>-522.603952</td>\n",
       "      <td>-3779.483718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>144</td>\n",
       "      <td>79</td>\n",
       "      <td>-61.538462</td>\n",
       "      <td>58.899731</td>\n",
       "      <td>-28.905741</td>\n",
       "      <td>-33943.357340</td>\n",
       "      <td>-6676.287306</td>\n",
       "      <td>-7090.957552</td>\n",
       "      <td>-5277.358171</td>\n",
       "      <td>-2165.602016</td>\n",
       "      <td>-342.307461</td>\n",
       "      <td>-6778.443009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>145</td>\n",
       "      <td>74</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>85.082502</td>\n",
       "      <td>-28.473972</td>\n",
       "      <td>-52431.152750</td>\n",
       "      <td>-5408.594473</td>\n",
       "      <td>-5079.303298</td>\n",
       "      <td>-4058.764662</td>\n",
       "      <td>-1833.465319</td>\n",
       "      <td>-607.551004</td>\n",
       "      <td>-1884.365687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>146</td>\n",
       "      <td>76</td>\n",
       "      <td>-54.545455</td>\n",
       "      <td>46.331586</td>\n",
       "      <td>-115.324195</td>\n",
       "      <td>-34145.266960</td>\n",
       "      <td>-2530.412018</td>\n",
       "      <td>-5073.016229</td>\n",
       "      <td>-2969.007466</td>\n",
       "      <td>-1237.649715</td>\n",
       "      <td>-118.564650</td>\n",
       "      <td>-1644.997441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>147</td>\n",
       "      <td>59</td>\n",
       "      <td>-4.761905</td>\n",
       "      <td>69.447270</td>\n",
       "      <td>-9.676442</td>\n",
       "      <td>-6635.389485</td>\n",
       "      <td>-2962.580868</td>\n",
       "      <td>-2542.158350</td>\n",
       "      <td>-5855.663926</td>\n",
       "      <td>-1309.073069</td>\n",
       "      <td>-74.262521</td>\n",
       "      <td>-4461.079977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>148</td>\n",
       "      <td>51</td>\n",
       "      <td>-207.692308</td>\n",
       "      <td>75.739873</td>\n",
       "      <td>-31.927017</td>\n",
       "      <td>-13991.830270</td>\n",
       "      <td>-7254.651064</td>\n",
       "      <td>-5815.416218</td>\n",
       "      <td>-7016.555890</td>\n",
       "      <td>-1726.425854</td>\n",
       "      <td>-492.895681</td>\n",
       "      <td>-2473.379366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>149</td>\n",
       "      <td>77</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>62.007555</td>\n",
       "      <td>-60.835087</td>\n",
       "      <td>-116327.052000</td>\n",
       "      <td>-7311.480948</td>\n",
       "      <td>-3190.853065</td>\n",
       "      <td>-4681.965101</td>\n",
       "      <td>-1085.370112</td>\n",
       "      <td>-388.793134</td>\n",
       "      <td>-2632.793213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>150</td>\n",
       "      <td>71</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>73.488381</td>\n",
       "      <td>-130.137248</td>\n",
       "      <td>-159405.182200</td>\n",
       "      <td>-9487.880512</td>\n",
       "      <td>-6254.937499</td>\n",
       "      <td>-3997.816099</td>\n",
       "      <td>-4587.975626</td>\n",
       "      <td>-839.853455</td>\n",
       "      <td>-2614.915993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1201</td>\n",
       "      <td>78</td>\n",
       "      <td>-7.142857</td>\n",
       "      <td>52.243723</td>\n",
       "      <td>-70.760573</td>\n",
       "      <td>-159722.955300</td>\n",
       "      <td>-13569.138290</td>\n",
       "      <td>-15148.399040</td>\n",
       "      <td>-7409.860348</td>\n",
       "      <td>-1977.996779</td>\n",
       "      <td>-553.460732</td>\n",
       "      <td>-3739.569765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1202</td>\n",
       "      <td>74</td>\n",
       "      <td>-2.255639</td>\n",
       "      <td>51.103184</td>\n",
       "      <td>-23.307774</td>\n",
       "      <td>-7903.235567</td>\n",
       "      <td>-4918.186113</td>\n",
       "      <td>-8175.831152</td>\n",
       "      <td>-4905.682846</td>\n",
       "      <td>-10219.709100</td>\n",
       "      <td>-190.808692</td>\n",
       "      <td>-4412.224697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1203</td>\n",
       "      <td>76</td>\n",
       "      <td>-73.333333</td>\n",
       "      <td>70.124471</td>\n",
       "      <td>-27.672105</td>\n",
       "      <td>-46433.538490</td>\n",
       "      <td>-8604.372217</td>\n",
       "      <td>-6225.999619</td>\n",
       "      <td>-3913.011234</td>\n",
       "      <td>-20016.716670</td>\n",
       "      <td>-497.146458</td>\n",
       "      <td>-3211.641382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient # CDR, ADAS  Age  % Change from baseline (ADAS-Cog11)  \\\n",
       "0                   101   62                           -21.428571   \n",
       "1                   102   77                           -36.363636   \n",
       "2                   103   76                           -78.947368   \n",
       "3                   104   65                          -129.411765   \n",
       "4                   105   50                           -10.526316   \n",
       "5                   106   66                           -38.461538   \n",
       "6                   107   64                           -15.384615   \n",
       "7                   108   60                           -29.166667   \n",
       "8                   109   72                           -30.434783   \n",
       "9                   110   72                           -84.615385   \n",
       "10                  111   62                            41.666667   \n",
       "11                  112   69                             9.333333   \n",
       "12                  113   69                           -60.000000   \n",
       "13                  114   67                           -16.129032   \n",
       "14                  115   60                           -48.275862   \n",
       "15                  116   67                           -36.842105   \n",
       "16                  118   52                            -3.125000   \n",
       "17                  119   75                           -81.250000   \n",
       "18                  120   68                           -27.777778   \n",
       "19                  121   72                            -4.347826   \n",
       "20                  122   58                          -140.000000   \n",
       "21                  123   47                            54.545455   \n",
       "22                  124   61                           -18.750000   \n",
       "23                  125   73                           -37.500000   \n",
       "24                  126   69                          -100.000000   \n",
       "25                  127   74                           -76.470588   \n",
       "26                  128   72                           -20.833333   \n",
       "27                  129   69                           -35.714286   \n",
       "28                  130   66                            -7.142857   \n",
       "29                  131   68                           -40.000000   \n",
       "30                  133   74                             6.250000   \n",
       "31                  134   66                            29.411765   \n",
       "32                  135   57                           -45.714286   \n",
       "33                  137   57                           -77.272727   \n",
       "34                  138   72                            -9.523810   \n",
       "35                  139   58                          -105.882353   \n",
       "36                  140   73                            18.181818   \n",
       "37                  141   72                             0.000000   \n",
       "38                  142   77                             5.555556   \n",
       "39                  143   71                             6.250000   \n",
       "40                  144   79                           -61.538462   \n",
       "41                  145   74                             5.555556   \n",
       "42                  146   76                           -54.545455   \n",
       "43                  147   59                            -4.761905   \n",
       "44                  148   51                          -207.692308   \n",
       "45                  149   77                           -90.000000   \n",
       "46                  150   71                            13.636364   \n",
       "47                 1201   78                            -7.142857   \n",
       "48                 1202   74                            -2.255639   \n",
       "49                 1203   76                           -73.333333   \n",
       "\n",
       "    Subiculum Connectivity  Subiculum Damage Score  Hippocampus Damage Score  \\\n",
       "0                56.864683              -22.341183             -19032.589510   \n",
       "1                52.970984              -40.309051            -184720.025100   \n",
       "2                62.459631              -19.785287             -45387.958520   \n",
       "3                59.611631              -42.332132             -60471.819480   \n",
       "4                57.928350               -2.136441              -5968.011901   \n",
       "5                63.323903              -26.237501             -29471.040290   \n",
       "6                53.317851              -43.667344            -118201.273400   \n",
       "7                57.979468              -62.535677             -66947.522780   \n",
       "8                66.950749              -22.137900             -75270.490460   \n",
       "9                69.267271               -6.545406             -40392.854920   \n",
       "10               83.621480              -12.031371             -13754.352350   \n",
       "11               77.334117              -95.005208            -238543.225100   \n",
       "12               69.758721              -28.902412             -20892.641060   \n",
       "13               67.432125              -73.956802            -138175.964700   \n",
       "14               71.155530              -55.794428             -77705.598780   \n",
       "15               61.952527               -6.821094             -17218.510150   \n",
       "16               72.547473              -22.352065            -114358.150900   \n",
       "17               62.118622              -80.977992             -80659.902680   \n",
       "18               60.940570              -26.846372             -11517.494530   \n",
       "19               71.223601             -184.169968            -369157.398200   \n",
       "20               68.856418              -47.902605             -55394.394800   \n",
       "21               64.525483               -4.567961              -1923.146865   \n",
       "22               60.270662              -81.799781             -50587.278130   \n",
       "23               71.676110              -85.122956            -144614.746500   \n",
       "24               76.111573              -23.751946             -10242.398380   \n",
       "25               67.387791              -76.812351             -64351.946610   \n",
       "26               75.530777              -29.973764             -44817.434530   \n",
       "27               77.657909              -28.137744             -26351.409550   \n",
       "28               65.993904              -44.005146             -93191.241950   \n",
       "29               71.997755              -44.815724            -171675.718000   \n",
       "30               74.948112              -16.910131              -8658.442261   \n",
       "31               72.265483                0.000000             -25820.100230   \n",
       "32               63.361510             -107.847728             -28689.173250   \n",
       "33               65.596015              -90.498595             -51721.325030   \n",
       "34               80.611188             -110.281101            -158350.400300   \n",
       "35               61.050691              -52.659681              -4939.292040   \n",
       "36               72.686647             -183.755533            -139589.841700   \n",
       "37               76.829337              -40.475229             -77408.191470   \n",
       "38               69.979040              -20.287737             -35966.511840   \n",
       "39               66.339918              -36.619337            -111306.638300   \n",
       "40               58.899731              -28.905741             -33943.357340   \n",
       "41               85.082502              -28.473972             -52431.152750   \n",
       "42               46.331586             -115.324195             -34145.266960   \n",
       "43               69.447270               -9.676442              -6635.389485   \n",
       "44               75.739873              -31.927017             -13991.830270   \n",
       "45               62.007555              -60.835087            -116327.052000   \n",
       "46               73.488381             -130.137248            -159405.182200   \n",
       "47               52.243723              -70.760573            -159722.955300   \n",
       "48               51.103184              -23.307774              -7903.235567   \n",
       "49               70.124471              -27.672105             -46433.538490   \n",
       "\n",
       "    Temporal Damage Score  Frontal Damage Score  Parietal Damage Score  \\\n",
       "0            -6811.832831          -3390.513012           -6514.359274   \n",
       "1           -12864.565970          -6136.065565           -4548.582996   \n",
       "2            -6591.622671          -8075.228864           -4447.485410   \n",
       "3           -11699.796100          -6244.075797           -5212.034938   \n",
       "4            -4662.284230          -6429.216510           -4540.145985   \n",
       "5            -2479.701861          -2121.181555           -2841.442623   \n",
       "6           -11646.437390          -7046.077001           -8392.540599   \n",
       "7           -10926.588590          -4526.665072           -5782.261434   \n",
       "8           -11252.394020          -5240.470247           -4707.095249   \n",
       "9            -7111.854909          -9629.498968           -5124.972435   \n",
       "10           -3693.768595          -3585.812811           -2881.090806   \n",
       "11           -9523.372702          -5231.188795           -3341.870796   \n",
       "12           -8944.256581          -6250.756779           -7337.594881   \n",
       "13          -20303.315100          -7626.091153           -4493.410344   \n",
       "14          -12366.613620          -7079.020043           -6185.281536   \n",
       "15           -5963.165041          -4304.940185           -4418.202940   \n",
       "16          -14600.125320          -8886.139697          -12491.789050   \n",
       "17          -11727.167460          -6611.196011           -3294.535386   \n",
       "18           -4609.255396          -4921.028744           -7256.070788   \n",
       "19          -18978.105100          -6794.609698           -5127.901253   \n",
       "20          -10489.824720          -7463.500501           -6603.433336   \n",
       "21           -3381.584935          -4489.507707           -3867.214918   \n",
       "22           -5624.134019          -6845.636117           -5610.080427   \n",
       "23          -15075.909790         -10748.591850           -7451.648700   \n",
       "24           -3500.827181          -4844.584373           -3467.456477   \n",
       "25           -8245.176231          -7644.884365           -6040.602962   \n",
       "26           -3306.320133          -4980.904424           -3681.150660   \n",
       "27           -4411.689549          -5746.775045           -2270.854148   \n",
       "28           -5214.340386          -4257.545930           -4766.378101   \n",
       "29           -7237.769982          -3947.998068           -2482.752741   \n",
       "30           -2079.519127          -1936.904785           -2391.334029   \n",
       "31           -7365.386021          -4637.062081           -3256.034550   \n",
       "32           -8597.692107         -26571.216700          -23014.222320   \n",
       "33          -13259.247540         -23115.678970          -18364.252020   \n",
       "34          -13516.414110         -16741.707800           -7529.170754   \n",
       "35           -5003.799265          -9410.595931           -6628.105057   \n",
       "36          -16907.478320         -12569.795820          -11001.985840   \n",
       "37           -5278.497697          -8987.320434           -2990.976958   \n",
       "38           -4016.577659          -3321.383587           -3206.440006   \n",
       "39           -9443.699760          -7654.818729           -5476.623021   \n",
       "40           -6676.287306          -7090.957552           -5277.358171   \n",
       "41           -5408.594473          -5079.303298           -4058.764662   \n",
       "42           -2530.412018          -5073.016229           -2969.007466   \n",
       "43           -2962.580868          -2542.158350           -5855.663926   \n",
       "44           -7254.651064          -5815.416218           -7016.555890   \n",
       "45           -7311.480948          -3190.853065           -4681.965101   \n",
       "46           -9487.880512          -6254.937499           -3997.816099   \n",
       "47          -13569.138290         -15148.399040           -7409.860348   \n",
       "48           -4918.186113          -8175.831152           -4905.682846   \n",
       "49           -8604.372217          -6225.999619           -3913.011234   \n",
       "\n",
       "    Cerebellum Damage Score  Insula Damage Score  Occipital Damage Score  \n",
       "0              -1733.125937          -133.189922            -4146.074230  \n",
       "1              -5422.573735          -622.591915            -3965.251674  \n",
       "2              -3607.025644          -624.924211            -2512.288860  \n",
       "3              -3227.497127          -570.463181            -2934.581194  \n",
       "4              -1893.423398          -299.251771            -2070.284124  \n",
       "5              -1631.143552          -120.128438            -2222.047928  \n",
       "6              -2361.515431          -614.793778            -6163.741802  \n",
       "7              -3820.805562          -263.752339            -3537.170972  \n",
       "8              -1171.115413          -261.459686            -3628.614588  \n",
       "9              -1647.853988         -1035.648091            -2358.679568  \n",
       "10             -1377.749893          -188.327720            -2034.825096  \n",
       "11             -3867.663215          -403.955119            -2157.941629  \n",
       "12             -3992.983769          -345.287600            -5010.695407  \n",
       "13             -9078.765183          -534.608502            -3921.427002  \n",
       "14             -4449.870736          -344.366289            -4375.606746  \n",
       "15             -1553.586900          -180.264656            -3008.989926  \n",
       "16             -7235.494986          -663.292110            -7237.065212  \n",
       "17             -3543.337851          -305.225658            -3419.852691  \n",
       "18              -813.292149           -99.219263            -3763.409731  \n",
       "19             -4454.601461          -704.129882            -3015.647349  \n",
       "20             -4492.723196          -479.387821            -4013.620186  \n",
       "21             -4560.337124          -288.228900            -2532.803295  \n",
       "22             -4167.216482          -314.517213            -2770.024539  \n",
       "23             -2671.257200          -921.641769            -3832.411856  \n",
       "24             -4047.535956          -184.064613            -2312.979624  \n",
       "25             -2015.988509          -284.263616            -4346.323336  \n",
       "26             -3146.217962          -486.817516            -2247.277587  \n",
       "27             -6398.033519          -155.356805            -1721.492551  \n",
       "28              -456.086505          -281.212952            -2504.662255  \n",
       "29              -341.971196          -389.386114            -1175.914302  \n",
       "30             -1352.709505           -92.142653            -1312.357225  \n",
       "31             -8106.699579          -240.710562            -3622.008690  \n",
       "32             -2793.000014          -574.808714            -6970.681570  \n",
       "33             -1694.974868         -1074.569077            -7437.703600  \n",
       "34             -5872.060528          -406.795302            -4661.716394  \n",
       "35             -3012.111321           -67.471980            -5906.793172  \n",
       "36             -9366.484488          -320.939000           -16475.540660  \n",
       "37             -2374.593897           -84.896518            -1982.402247  \n",
       "38             -2173.416102          -292.265096            -2935.410909  \n",
       "39             -3205.121809          -522.603952            -3779.483718  \n",
       "40             -2165.602016          -342.307461            -6778.443009  \n",
       "41             -1833.465319          -607.551004            -1884.365687  \n",
       "42             -1237.649715          -118.564650            -1644.997441  \n",
       "43             -1309.073069           -74.262521            -4461.079977  \n",
       "44             -1726.425854          -492.895681            -2473.379366  \n",
       "45             -1085.370112          -388.793134            -2632.793213  \n",
       "46             -4587.975626          -839.853455            -2614.915993  \n",
       "47             -1977.996779          -553.460732            -3739.569765  \n",
       "48            -10219.709100          -190.808692            -4412.224697  \n",
       "49            -20016.716670          -497.146458            -3211.641382  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------------user input above----------------------------------------------------------------\n",
    "data_df = pd.read_csv(clin_path)\n",
    "    \n",
    "# #Remove subjects\n",
    "# outlier_index=[11, 47, 48, 49]\n",
    "# data_df = data_df.drop(index=outlier_index)\n",
    "# data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.292279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.016545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-0.897080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-1.940569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.517713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.059924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.417254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.132272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.106051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-1.014281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.596945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.928365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.505291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.401861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.262862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.026438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.670755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-0.944693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.160991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.645470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-2.159510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.863249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.347665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.040042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-1.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-0.845866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.304587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-0.003118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.587675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>-0.091736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.864609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.343542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>-0.209895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>-0.862452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.538442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-1.454034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.111332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.735373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.850249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.864609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-0.537103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.850249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-0.392503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.636908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-3.559233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-1.125623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.017342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0.587675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0.688731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>-0.780994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             outcome\n",
       "subject_id          \n",
       "101         0.292279\n",
       "102        -0.016545\n",
       "103        -0.897080\n",
       "104        -1.940569\n",
       "105         0.517713\n",
       "106        -0.059924\n",
       "107         0.417254\n",
       "108         0.132272\n",
       "109         0.106051\n",
       "110        -1.014281\n",
       "111         1.596945\n",
       "112         0.928365\n",
       "113        -0.505291\n",
       "114         0.401861\n",
       "115        -0.262862\n",
       "116        -0.026438\n",
       "118         0.670755\n",
       "119        -0.944693\n",
       "120         0.160991\n",
       "121         0.645470\n",
       "122        -2.159510\n",
       "123         1.863249\n",
       "124         0.347665\n",
       "125        -0.040042\n",
       "126        -1.332400\n",
       "127        -0.845866\n",
       "128         0.304587\n",
       "129        -0.003118\n",
       "130         0.587675\n",
       "131        -0.091736\n",
       "133         0.864609\n",
       "134         1.343542\n",
       "135        -0.209895\n",
       "137        -0.862452\n",
       "138         0.538442\n",
       "139        -1.454034\n",
       "140         1.111332\n",
       "141         0.735373\n",
       "142         0.850249\n",
       "143         0.864609\n",
       "144        -0.537103\n",
       "145         0.850249\n",
       "146        -0.392503\n",
       "147         0.636908\n",
       "148        -3.559233\n",
       "149        -1.125623\n",
       "150         1.017342\n",
       "1201        0.587675\n",
       "1202        0.688731\n",
       "1203       -0.780994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject_column = 'Patient # CDR, ADAS'\n",
    "outcome_column = '% Change from baseline (ADAS-Cog11)'\n",
    "#----------------------------------------------------------------DO NOT MODIFY--------------------------------------------------------\n",
    "outcomes_df = pd.DataFrame()\n",
    "outcomes_df['outcome'] = data_df.loc[:, [outcome_column]]\n",
    "\n",
    "#Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "outcomes_df.iloc[:,:] = scaler.fit_transform(outcomes_df.iloc[:,:])\n",
    "\n",
    "\n",
    "outcomes_df['subject_id'] = data_df.loc[:, [subject_column]]\n",
    "# outcomes_df['subject_id'] = [id.split('_')[0] for id in data_df[subject_column].to_list()] #<------------------------problem code. must generalize to extract subject id better\n",
    "outcomes_df.set_index('subject_id', inplace=True)\n",
    "\n",
    "# data_df = data_df.set_index('Patient # CDR, ADAS')\n",
    "# data_df['subject_id'] = data_df.index\n",
    "# data_df['outcome'] = data_df\n",
    "\n",
    "# Convert the 'subject_id' column to strings for each DataFrame\n",
    "outcomes_df.index = outcomes_df.index.astype(str)\n",
    "display(outcomes_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get More Clinical Data As Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clinical_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            clinical_data\n",
       "subject_id               \n",
       "101                    62\n",
       "102                    77\n",
       "103                    76\n",
       "104                    65\n",
       "105                    50\n",
       "106                    66\n",
       "107                    64\n",
       "108                    60\n",
       "109                    72\n",
       "110                    72\n",
       "111                    62\n",
       "112                    69\n",
       "113                    69\n",
       "114                    67\n",
       "115                    60\n",
       "116                    67\n",
       "118                    52\n",
       "119                    75\n",
       "120                    68\n",
       "121                    72\n",
       "122                    58\n",
       "123                    47\n",
       "124                    61\n",
       "125                    73\n",
       "126                    69\n",
       "127                    74\n",
       "128                    72\n",
       "129                    69\n",
       "130                    66\n",
       "131                    68\n",
       "133                    74\n",
       "134                    66\n",
       "135                    57\n",
       "137                    57\n",
       "138                    72\n",
       "139                    58\n",
       "140                    73\n",
       "141                    72\n",
       "142                    77\n",
       "143                    71\n",
       "144                    79\n",
       "145                    74\n",
       "146                    76\n",
       "147                    59\n",
       "148                    51\n",
       "149                    77\n",
       "150                    71\n",
       "1201                   78\n",
       "1202                   74\n",
       "1203                   76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject_column = 'Patient # CDR, ADAS'\n",
    "clinical_information_column = 'Age'\n",
    "#----------------------------------------------------------------DO NOT MODIFY--------------------------------------------------------\n",
    "clinical_df_1 = pd.DataFrame()\n",
    "clinical_df_1['clinical_data'] = data_df.loc[:, [clinical_information_column]]\n",
    "\n",
    "clinical_df_1['subject_id'] = data_df.loc[:, [subject_column]]\n",
    "# clinical_df_1['subject_id'] = [id.split('_')[0] for id in data_df[subject_column].to_list()] \n",
    "clinical_df_1.set_index('subject_id', inplace=True)\n",
    "\n",
    "# Convert the 'subject_id' column to strings for each DataFrame\n",
    "clinical_df_1.index = clinical_df_1.index.astype(str)\n",
    "display(clinical_df_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Imaging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/connectivity_data/vta_published_t_connectivity/*_T*.nii*\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "cannot further split name\n",
      "116_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  195.56159244766604 (902629,)\n",
      "post z score max:  36.16030539421581 (902629,)\n",
      "139_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  193.79302616660425 (902629,)\n",
      "post z score max:  33.171095565585055 (902629,)\n",
      "147_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  209.413354909002 (902629,)\n",
      "post z score max:  37.19546514127929 (902629,)\n",
      "135_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  223.39488147114935 (902629,)\n",
      "post z score max:  46.18236029222014 (902629,)\n",
      "101_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  181.09399048912564 (902629,)\n",
      "post z score max:  35.2479061531166 (902629,)\n",
      "150_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  170.21260197796437 (902629,)\n",
      "post z score max:  26.511011640127226 (902629,)\n",
      "122_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  182.26174484740113 (902629,)\n",
      "post z score max:  28.790493808787684 (902629,)\n",
      "146_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  187.40952395085515 (902629,)\n",
      "post z score max:  35.761941542354855 (902629,)\n",
      "138_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  200.00315214660986 (902629,)\n",
      "post z score max:  37.63190951612277 (902629,)\n",
      "134_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  158.82845608412936 (902629,)\n",
      "post z score max:  25.447797580752727 (902629,)\n",
      "123_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  191.43694453216995 (902629,)\n",
      "post z score max:  30.792601448083413 (902629,)\n",
      "149_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  164.68210226364135 (902629,)\n",
      "post z score max:  29.996501521179955 (902629,)\n",
      "137_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  185.66630999972404 (902629,)\n",
      "post z score max:  35.91854406441139 (902629,)\n",
      "118_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  236.72804708809053 (902629,)\n",
      "post z score max:  45.011080199749614 (902629,)\n",
      "114_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  182.55203285476455 (902629,)\n",
      "post z score max:  37.9361051503445 (902629,)\n",
      "145_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  192.47686493680703 (902629,)\n",
      "post z score max:  34.6214988401643 (902629,)\n",
      "120_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  257.42394291986784 (902629,)\n",
      "post z score max:  77.52124750868143 (902629,)\n",
      "103_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  194.84608995437156 (902629,)\n",
      "post z score max:  36.336562820533565 (902629,)\n",
      "119_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  193.61506966098204 (902629,)\n",
      "post z score max:  34.906873521459424 (902629,)\n",
      "148_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  161.47104202472292 (902629,)\n",
      "post z score max:  29.913684981959165 (902629,)\n",
      "144_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  227.8511470533158 (902629,)\n",
      "post z score max:  48.48258518864254 (902629,)\n",
      "115_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  141.74184355403668 (902629,)\n",
      "post z score max:  30.925949585449374 (902629,)\n",
      "121_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  194.10404027813456 (902629,)\n",
      "post z score max:  31.269969706447814 (902629,)\n",
      "102_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  145.1635042956059 (902629,)\n",
      "post z score max:  25.235740488483888 (902629,)\n",
      "105_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  140.90783615177315 (902629,)\n",
      "post z score max:  34.765951433563664 (902629,)\n",
      "109_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  208.8619915185518 (902629,)\n",
      "post z score max:  35.627550242852834 (902629,)\n",
      "126_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  169.43498244668262 (902629,)\n",
      "post z score max:  30.664044434212805 (902629,)\n",
      "143_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  188.13023477779097 (902629,)\n",
      "post z score max:  26.994466887526535 (902629,)\n",
      "131_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  176.4292230563933 (902629,)\n",
      "post z score max:  33.67985621242475 (902629,)\n",
      "104_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  170.90299723938188 (902629,)\n",
      "post z score max:  36.0089207609186 (902629,)\n",
      "127_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  204.2032902626488 (902629,)\n",
      "post z score max:  40.58945694765481 (902629,)\n",
      "108_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  122.89696652045222 (902629,)\n",
      "post z score max:  29.271072201526675 (902629,)\n",
      "113_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  221.23702288765344 (902629,)\n",
      "post z score max:  44.387425798136434 (902629,)\n",
      "142_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  228.3640147307051 (902629,)\n",
      "post z score max:  46.81147819652305 (902629,)\n",
      "130_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  192.90059351578748 (902629,)\n",
      "post z score max:  33.990501627086154 (902629,)\n",
      "124_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  193.62622162242587 (902629,)\n",
      "post z score max:  38.55724431221884 (902629,)\n",
      "128_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  198.5549749776328 (902629,)\n",
      "post z score max:  41.37698943955033 (902629,)\n",
      "107_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  123.26993682437205 (902629,)\n",
      "post z score max:  29.498623323823622 (902629,)\n",
      "133_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  217.0360269284265 (902629,)\n",
      "post z score max:  43.47150770719217 (902629,)\n",
      "141_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  162.01477673825138 (902629,)\n",
      "post z score max:  32.32294103262727 (902629,)\n",
      "110_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  226.35626338647853 (902629,)\n",
      "post z score max:  46.716333991984904 (902629,)\n",
      "125_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  172.81949551448633 (902629,)\n",
      "post z score max:  28.001661722466086 (902629,)\n",
      "106_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  212.54820497184483 (902629,)\n",
      "post z score max:  39.95637985035293 (902629,)\n",
      "129_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  200.8318593034619 (902629,)\n",
      "post z score max:  36.48186700714098 (902629,)\n",
      "111_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  216.30266291446787 (902629,)\n",
      "post z score max:  53.65114852724588 (902629,)\n",
      "140_vat_seed_compound_fMRI_efield_func_seed_T.nii\n",
      "--------------------------------Performing z_score--------------------------------\n",
      "pre z score max:  185.63519786553115 (902629,)\n",
      "post z score max:  27.709535420217925 (902629,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>902619</th>\n",
       "      <th>902620</th>\n",
       "      <th>902621</th>\n",
       "      <th>902622</th>\n",
       "      <th>902623</th>\n",
       "      <th>902624</th>\n",
       "      <th>902625</th>\n",
       "      <th>902626</th>\n",
       "      <th>902627</th>\n",
       "      <th>902628</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 902629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6       7       \\\n",
       "subject_id                                                                   \n",
       "116            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "139            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "147            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "135            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "101            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "150            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "122            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "146            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "138            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "134            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "123            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "149            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "137            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "118            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "114            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "145            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "120            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "103            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "119            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "148            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "144            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "115            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "121            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "102            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "105            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "109            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "126            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "143            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "131            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "104            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "127            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "108            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "113            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "142            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "130            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "124            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "128            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "107            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "133            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "141            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "110            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "125            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "106            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "129            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "111            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "140            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "            8       9       ...  902619  902620  902621  902622  902623  \\\n",
       "subject_id                  ...                                           \n",
       "116            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "139            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "147            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "135            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "101            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "150            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "122            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "146            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "138            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "134            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "123            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "149            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "137            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "118            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "114            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "145            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "120            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "103            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "119            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "148            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "144            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "115            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "121            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "102            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "105            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "109            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "126            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "143            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "131            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "104            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "127            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "108            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "113            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "142            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "130            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "124            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "128            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "107            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "133            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "141            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "110            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "125            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "106            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "129            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "111            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "140            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "            902624  902625  902626  902627  902628  \n",
       "subject_id                                          \n",
       "116            0.0     0.0     0.0     0.0     0.0  \n",
       "139            0.0     0.0     0.0     0.0     0.0  \n",
       "147            0.0     0.0     0.0     0.0     0.0  \n",
       "135            0.0     0.0     0.0     0.0     0.0  \n",
       "101            0.0     0.0     0.0     0.0     0.0  \n",
       "150            0.0     0.0     0.0     0.0     0.0  \n",
       "122            0.0     0.0     0.0     0.0     0.0  \n",
       "146            0.0     0.0     0.0     0.0     0.0  \n",
       "138            0.0     0.0     0.0     0.0     0.0  \n",
       "134            0.0     0.0     0.0     0.0     0.0  \n",
       "123            0.0     0.0     0.0     0.0     0.0  \n",
       "149            0.0     0.0     0.0     0.0     0.0  \n",
       "137            0.0     0.0     0.0     0.0     0.0  \n",
       "118            0.0     0.0     0.0     0.0     0.0  \n",
       "114            0.0     0.0     0.0     0.0     0.0  \n",
       "145            0.0     0.0     0.0     0.0     0.0  \n",
       "120            0.0     0.0     0.0     0.0     0.0  \n",
       "103            0.0     0.0     0.0     0.0     0.0  \n",
       "119            0.0     0.0     0.0     0.0     0.0  \n",
       "148            0.0     0.0     0.0     0.0     0.0  \n",
       "144            0.0     0.0     0.0     0.0     0.0  \n",
       "115            0.0     0.0     0.0     0.0     0.0  \n",
       "121            0.0     0.0     0.0     0.0     0.0  \n",
       "102            0.0     0.0     0.0     0.0     0.0  \n",
       "105            0.0     0.0     0.0     0.0     0.0  \n",
       "109            0.0     0.0     0.0     0.0     0.0  \n",
       "126            0.0     0.0     0.0     0.0     0.0  \n",
       "143            0.0     0.0     0.0     0.0     0.0  \n",
       "131            0.0     0.0     0.0     0.0     0.0  \n",
       "104            0.0     0.0     0.0     0.0     0.0  \n",
       "127            0.0     0.0     0.0     0.0     0.0  \n",
       "108            0.0     0.0     0.0     0.0     0.0  \n",
       "113            0.0     0.0     0.0     0.0     0.0  \n",
       "142            0.0     0.0     0.0     0.0     0.0  \n",
       "130            0.0     0.0     0.0     0.0     0.0  \n",
       "124            0.0     0.0     0.0     0.0     0.0  \n",
       "128            0.0     0.0     0.0     0.0     0.0  \n",
       "107            0.0     0.0     0.0     0.0     0.0  \n",
       "133            0.0     0.0     0.0     0.0     0.0  \n",
       "141            0.0     0.0     0.0     0.0     0.0  \n",
       "110            0.0     0.0     0.0     0.0     0.0  \n",
       "125            0.0     0.0     0.0     0.0     0.0  \n",
       "106            0.0     0.0     0.0     0.0     0.0  \n",
       "129            0.0     0.0     0.0     0.0     0.0  \n",
       "111            0.0     0.0     0.0     0.0     0.0  \n",
       "140            0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[46 rows x 902629 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from calvin_utils.import_matrices import import_matrices_from_folder\n",
    "from calvin_utils.generate_nifti import nifti_from_matrix\n",
    "from nimlab import datasets as nimds\n",
    "import numpy as np\n",
    "from nilearn import image, plotting, maskers\n",
    "\n",
    "#get conectivity values of interest\n",
    "matrix_path = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/connectivity_data/vta_published_t_connectivity'\n",
    "matrix = import_matrices_from_folder(matrix_path, file_pattern='/*_T*.nii*')\n",
    "\n",
    "#Standardize matrix via z score\n",
    "prepped_matrix = pd.DataFrame()\n",
    "from calvin_utils.z_score_matrix import z_score_matrix\n",
    "for column in matrix.columns:\n",
    "    #Rename while we're at it. Needs to be an integer, as this is the type of patient ID in the clinical data\n",
    "    print(column)\n",
    "    new_name = int(column.split('_')[0]) #.split('T')[1]) #<----------------------------------THIS IS A BUG-CREATOR. MUST BE TAILORED TO PATIENT DATA\n",
    "    #Standardize column by column\n",
    "    prepped_matrix[new_name] = z_score_matrix(matrix[column])\n",
    "    #Set values outside brain back to zero\n",
    "    prepped_matrix[new_name] = np.where(matrix[column] == 0, 0, prepped_matrix[new_name])\n",
    "\n",
    "#Set patients to those in the clinical data dataframe\n",
    "prepped_matrix = prepped_matrix.transpose()\n",
    "prepped_matrix['subject_id'] = [str(col).split('_')[0] for col in prepped_matrix.index]\n",
    "prepped_matrix.set_index('subject_id', inplace=True)\n",
    "neuroimaging_df_1 = prepped_matrix\n",
    "neuroimaging_df_1.index = neuroimaging_df_1.index.astype(str)\n",
    "#Display results\n",
    "display(neuroimaging_df_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import More Imaging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/cat12/cat12_ultrafine-reg/CAT12.8.2_2170/*/*/*/*mwp1*resamp*.nii*\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>902619</th>\n",
       "      <th>902620</th>\n",
       "      <th>902621</th>\n",
       "      <th>902622</th>\n",
       "      <th>902623</th>\n",
       "      <th>902624</th>\n",
       "      <th>902625</th>\n",
       "      <th>902626</th>\n",
       "      <th>902627</th>\n",
       "      <th>902628</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 902629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6       7       \\\n",
       "subject_id                                                                   \n",
       "130            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "137            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "108            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "101            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "106            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "139            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "107            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "138            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "109            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "131            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "149            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "140            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "147            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "113            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "114            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "122            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "125            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "146            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "141            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "148            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "124            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "123            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "115            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "112            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1202           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1203           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "134            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "133            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "105            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "102            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "150            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "103            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "104            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "135            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "128            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "110            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "119            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "126            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "121            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "144            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "143            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "120            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "118            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "127            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "111            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "129            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "116            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "142            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "145            0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1201           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "            8       9       ...  902619  902620  902621  902622  902623  \\\n",
       "subject_id                  ...                                           \n",
       "130            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "137            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "108            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "101            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "106            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "139            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "107            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "138            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "109            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "131            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "149            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "140            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "147            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "113            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "114            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "122            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "125            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "146            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "141            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "148            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "124            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "123            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "115            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "112            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "1202           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "1203           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "134            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "133            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "105            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "102            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "150            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "103            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "104            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "135            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "128            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "110            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "119            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "126            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "121            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "144            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "143            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "120            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "118            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "127            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "111            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "129            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "116            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "142            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "145            0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "1201           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "            902624  902625  902626  902627  902628  \n",
       "subject_id                                          \n",
       "130            0.0     0.0     0.0     0.0     0.0  \n",
       "137            0.0     0.0     0.0     0.0     0.0  \n",
       "108            0.0     0.0     0.0     0.0     0.0  \n",
       "101            0.0     0.0     0.0     0.0     0.0  \n",
       "106            0.0     0.0     0.0     0.0     0.0  \n",
       "139            0.0     0.0     0.0     0.0     0.0  \n",
       "107            0.0     0.0     0.0     0.0     0.0  \n",
       "138            0.0     0.0     0.0     0.0     0.0  \n",
       "109            0.0     0.0     0.0     0.0     0.0  \n",
       "131            0.0     0.0     0.0     0.0     0.0  \n",
       "149            0.0     0.0     0.0     0.0     0.0  \n",
       "140            0.0     0.0     0.0     0.0     0.0  \n",
       "147            0.0     0.0     0.0     0.0     0.0  \n",
       "113            0.0     0.0     0.0     0.0     0.0  \n",
       "114            0.0     0.0     0.0     0.0     0.0  \n",
       "122            0.0     0.0     0.0     0.0     0.0  \n",
       "125            0.0     0.0     0.0     0.0     0.0  \n",
       "146            0.0     0.0     0.0     0.0     0.0  \n",
       "141            0.0     0.0     0.0     0.0     0.0  \n",
       "148            0.0     0.0     0.0     0.0     0.0  \n",
       "124            0.0     0.0     0.0     0.0     0.0  \n",
       "123            0.0     0.0     0.0     0.0     0.0  \n",
       "115            0.0     0.0     0.0     0.0     0.0  \n",
       "112            0.0     0.0     0.0     0.0     0.0  \n",
       "1202           0.0     0.0     0.0     0.0     0.0  \n",
       "1203           0.0     0.0     0.0     0.0     0.0  \n",
       "134            0.0     0.0     0.0     0.0     0.0  \n",
       "133            0.0     0.0     0.0     0.0     0.0  \n",
       "105            0.0     0.0     0.0     0.0     0.0  \n",
       "102            0.0     0.0     0.0     0.0     0.0  \n",
       "150            0.0     0.0     0.0     0.0     0.0  \n",
       "103            0.0     0.0     0.0     0.0     0.0  \n",
       "104            0.0     0.0     0.0     0.0     0.0  \n",
       "135            0.0     0.0     0.0     0.0     0.0  \n",
       "128            0.0     0.0     0.0     0.0     0.0  \n",
       "110            0.0     0.0     0.0     0.0     0.0  \n",
       "119            0.0     0.0     0.0     0.0     0.0  \n",
       "126            0.0     0.0     0.0     0.0     0.0  \n",
       "121            0.0     0.0     0.0     0.0     0.0  \n",
       "144            0.0     0.0     0.0     0.0     0.0  \n",
       "143            0.0     0.0     0.0     0.0     0.0  \n",
       "120            0.0     0.0     0.0     0.0     0.0  \n",
       "118            0.0     0.0     0.0     0.0     0.0  \n",
       "127            0.0     0.0     0.0     0.0     0.0  \n",
       "111            0.0     0.0     0.0     0.0     0.0  \n",
       "129            0.0     0.0     0.0     0.0     0.0  \n",
       "116            0.0     0.0     0.0     0.0     0.0  \n",
       "142            0.0     0.0     0.0     0.0     0.0  \n",
       "145            0.0     0.0     0.0     0.0     0.0  \n",
       "1201           0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[50 rows x 902629 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import Another Dataframe if desired\n",
    "from calvin_utils.import_matrices import import_matrices_from_folder\n",
    "from calvin_utils.generate_nifti import nifti_from_matrix\n",
    "from nimlab import datasets as nimds\n",
    "import numpy as np\n",
    "from nilearn import image, plotting, maskers\n",
    "\n",
    "#get conectivity values of interest\n",
    "matrix_path = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/cat12/cat12_ultrafine-reg/CAT12.8.2_2170'\n",
    "neuroimaging_df_2 = import_matrices_from_folder(matrix_path, file_pattern='/*/*/*/*mwp1*resamp*.nii*')\n",
    "performed_z_score = False \n",
    "#----------------------------------------------------------------DO NOT MODIFY!----------------------------------------------------------------\n",
    "#Standardize matrix via z score\n",
    "# neuroimaging_df_2 = pd.DataFrame()\n",
    "# from calvin_utils.z_score_matrix import z_score_matrix\n",
    "# if performed_z_score:\n",
    "#     for column in matrix.columns:\n",
    "#         #Rename while we're at it. Needs to be an integer, as this is the type of patient ID in the clinical data\n",
    "#         new_name = int(column.split('_')[0])\n",
    "#         #Standardize column by column\n",
    "#         prepped_matrix[new_name] = z_score_matrix(matrix[column])\n",
    "#         #Set values outside brain back to zero\n",
    "#         prepped_matrix[new_name] = np.where(matrix[column] == 0, 0, prepped_matrix[new_name])\n",
    "\n",
    "#Set patients to those in the clinical data dataframe\n",
    "# prepped_matrix = prepped_matrix.loc[:, data_df.index]\n",
    "\n",
    "neuroimaging_df_2 = neuroimaging_df_2.transpose()\n",
    "neuroimaging_df_2['subject_id'] = [col.split('_')[0] for col in neuroimaging_df_2.index]\n",
    "neuroimaging_df_2.set_index('subject_id', inplace=True)\n",
    "\n",
    "neuroimaging_df_2.index = neuroimaging_df_2.index.astype(str)\n",
    "\n",
    "\n",
    "#Display results\n",
    "display(neuroimaging_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.loc[:, ['Age', '% Change from baseline (ADAS-Cog11)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Join Imaging Data to the Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only operate within the brain mask\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "prepped_matrix = prepped_matrix.iloc[brain_indices, :].reset_index()\n",
    "prepped_matrix = prepped_matrix.transpose()\n",
    "\n",
    "#Now, join voxels to the clinical data\n",
    "regression_df = data_df.merge(neuroimaging_df_1, on='Patient # CDR, ADAS', right_index=False)\n",
    "\n",
    "display(regression_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask Dataframes\n",
    "mask_path = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/voxelwise_glm/stim_by_age/palm_results/palm_statistic_topology/generated_nifti.nii' #None #\n",
    "masking_df = None # # \n",
    "#----------------------------------------------------------------DO NOT MODIFY\n",
    "from calvin_utils.matrix_utilities import mask_matrix\n",
    "# def mask_matrix(df_1, mask_path=None, mask_threshold=0.2, mask_by='rows', dataframe_to_mask_by=None):\n",
    "\n",
    "neuroimaging_df_1 = mask_matrix(neuroimaging_df_1, mask_path=mask_path, mask_threshold=0, mask_by='columns', dataframe_to_mask_by=masking_df)\n",
    "neuroimaging_df_2 = mask_matrix(neuroimaging_df_2, mask_path=mask_path, mask_threshold=0, mask_by='columns', dataframe_to_mask_by=masking_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>102956</th>\n",
       "      <th>102957</th>\n",
       "      <th>102958</th>\n",
       "      <th>102959</th>\n",
       "      <th>102960</th>\n",
       "      <th>103046</th>\n",
       "      <th>103047</th>\n",
       "      <th>103048</th>\n",
       "      <th>103049</th>\n",
       "      <th>103050</th>\n",
       "      <th>...</th>\n",
       "      <th>797919</th>\n",
       "      <th>798009</th>\n",
       "      <th>798010</th>\n",
       "      <th>798099</th>\n",
       "      <th>798100</th>\n",
       "      <th>798190</th>\n",
       "      <th>798191</th>\n",
       "      <th>798281</th>\n",
       "      <th>798282</th>\n",
       "      <th>798373</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.229362</td>\n",
       "      <td>0.205727</td>\n",
       "      <td>0.053395</td>\n",
       "      <td>0.074691</td>\n",
       "      <td>0.113833</td>\n",
       "      <td>0.423250</td>\n",
       "      <td>0.513379</td>\n",
       "      <td>0.377440</td>\n",
       "      <td>0.153252</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463366</td>\n",
       "      <td>0.303836</td>\n",
       "      <td>0.372540</td>\n",
       "      <td>0.605460</td>\n",
       "      <td>0.464765</td>\n",
       "      <td>0.746839</td>\n",
       "      <td>0.739713</td>\n",
       "      <td>0.870503</td>\n",
       "      <td>0.752853</td>\n",
       "      <td>0.769740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.109401</td>\n",
       "      <td>0.150143</td>\n",
       "      <td>0.197897</td>\n",
       "      <td>0.425160</td>\n",
       "      <td>0.362449</td>\n",
       "      <td>0.138988</td>\n",
       "      <td>0.176965</td>\n",
       "      <td>0.240504</td>\n",
       "      <td>0.407940</td>\n",
       "      <td>0.543465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>0.405873</td>\n",
       "      <td>0.192811</td>\n",
       "      <td>0.508609</td>\n",
       "      <td>0.499546</td>\n",
       "      <td>0.555987</td>\n",
       "      <td>0.478337</td>\n",
       "      <td>0.583788</td>\n",
       "      <td>0.478562</td>\n",
       "      <td>0.429630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.162510</td>\n",
       "      <td>0.179246</td>\n",
       "      <td>0.263863</td>\n",
       "      <td>0.298417</td>\n",
       "      <td>0.158954</td>\n",
       "      <td>0.351168</td>\n",
       "      <td>0.314347</td>\n",
       "      <td>0.409709</td>\n",
       "      <td>0.518645</td>\n",
       "      <td>0.382331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110859</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>0.583603</td>\n",
       "      <td>0.690095</td>\n",
       "      <td>0.910620</td>\n",
       "      <td>0.837578</td>\n",
       "      <td>0.951557</td>\n",
       "      <td>0.822104</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.739561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.153985</td>\n",
       "      <td>0.113712</td>\n",
       "      <td>0.141172</td>\n",
       "      <td>0.173383</td>\n",
       "      <td>0.114053</td>\n",
       "      <td>0.193699</td>\n",
       "      <td>0.248250</td>\n",
       "      <td>0.240887</td>\n",
       "      <td>0.267419</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068370</td>\n",
       "      <td>0.154941</td>\n",
       "      <td>0.097959</td>\n",
       "      <td>0.284367</td>\n",
       "      <td>0.265228</td>\n",
       "      <td>0.388628</td>\n",
       "      <td>0.386707</td>\n",
       "      <td>0.442965</td>\n",
       "      <td>0.473160</td>\n",
       "      <td>0.499106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.364223</td>\n",
       "      <td>0.145639</td>\n",
       "      <td>0.089289</td>\n",
       "      <td>0.140574</td>\n",
       "      <td>0.196354</td>\n",
       "      <td>0.665556</td>\n",
       "      <td>0.729897</td>\n",
       "      <td>0.594886</td>\n",
       "      <td>0.243001</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227021</td>\n",
       "      <td>0.293693</td>\n",
       "      <td>0.213777</td>\n",
       "      <td>0.688021</td>\n",
       "      <td>0.515107</td>\n",
       "      <td>0.662774</td>\n",
       "      <td>0.660089</td>\n",
       "      <td>0.682468</td>\n",
       "      <td>0.690582</td>\n",
       "      <td>0.717662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.246922</td>\n",
       "      <td>0.405237</td>\n",
       "      <td>0.310447</td>\n",
       "      <td>0.300769</td>\n",
       "      <td>0.206188</td>\n",
       "      <td>0.243030</td>\n",
       "      <td>0.413811</td>\n",
       "      <td>0.660632</td>\n",
       "      <td>0.502521</td>\n",
       "      <td>0.380426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058324</td>\n",
       "      <td>0.354329</td>\n",
       "      <td>0.274899</td>\n",
       "      <td>0.790549</td>\n",
       "      <td>0.449493</td>\n",
       "      <td>0.734528</td>\n",
       "      <td>0.539761</td>\n",
       "      <td>0.682080</td>\n",
       "      <td>0.574928</td>\n",
       "      <td>0.593957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.204949</td>\n",
       "      <td>0.197069</td>\n",
       "      <td>0.196635</td>\n",
       "      <td>0.160092</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.266371</td>\n",
       "      <td>0.292215</td>\n",
       "      <td>0.281765</td>\n",
       "      <td>0.244403</td>\n",
       "      <td>0.121008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118555</td>\n",
       "      <td>0.191085</td>\n",
       "      <td>0.216092</td>\n",
       "      <td>0.368782</td>\n",
       "      <td>0.331164</td>\n",
       "      <td>0.385139</td>\n",
       "      <td>0.412472</td>\n",
       "      <td>0.474175</td>\n",
       "      <td>0.450113</td>\n",
       "      <td>0.474031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.175004</td>\n",
       "      <td>0.321799</td>\n",
       "      <td>0.394048</td>\n",
       "      <td>0.364054</td>\n",
       "      <td>0.238638</td>\n",
       "      <td>0.406729</td>\n",
       "      <td>0.353518</td>\n",
       "      <td>0.489140</td>\n",
       "      <td>0.512552</td>\n",
       "      <td>0.508472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404712</td>\n",
       "      <td>0.447947</td>\n",
       "      <td>0.505782</td>\n",
       "      <td>0.575915</td>\n",
       "      <td>0.614407</td>\n",
       "      <td>0.668394</td>\n",
       "      <td>0.675969</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.682129</td>\n",
       "      <td>0.510989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.188685</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>0.121198</td>\n",
       "      <td>0.156062</td>\n",
       "      <td>0.143464</td>\n",
       "      <td>0.292154</td>\n",
       "      <td>0.373723</td>\n",
       "      <td>0.256809</td>\n",
       "      <td>0.156228</td>\n",
       "      <td>0.161139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211858</td>\n",
       "      <td>0.634101</td>\n",
       "      <td>0.550631</td>\n",
       "      <td>0.687401</td>\n",
       "      <td>0.573499</td>\n",
       "      <td>0.555129</td>\n",
       "      <td>0.571267</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.551988</td>\n",
       "      <td>0.422085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.151877</td>\n",
       "      <td>0.114629</td>\n",
       "      <td>0.086310</td>\n",
       "      <td>0.094285</td>\n",
       "      <td>0.038729</td>\n",
       "      <td>0.235435</td>\n",
       "      <td>0.249673</td>\n",
       "      <td>0.202294</td>\n",
       "      <td>0.165682</td>\n",
       "      <td>0.102519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079227</td>\n",
       "      <td>0.257531</td>\n",
       "      <td>0.202325</td>\n",
       "      <td>0.400190</td>\n",
       "      <td>0.422159</td>\n",
       "      <td>0.460475</td>\n",
       "      <td>0.419332</td>\n",
       "      <td>0.360247</td>\n",
       "      <td>0.399696</td>\n",
       "      <td>0.351100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.226707</td>\n",
       "      <td>0.148323</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.188839</td>\n",
       "      <td>0.132454</td>\n",
       "      <td>0.452179</td>\n",
       "      <td>0.430163</td>\n",
       "      <td>0.223039</td>\n",
       "      <td>0.183372</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296936</td>\n",
       "      <td>0.688628</td>\n",
       "      <td>0.525831</td>\n",
       "      <td>0.544609</td>\n",
       "      <td>0.617222</td>\n",
       "      <td>0.597075</td>\n",
       "      <td>0.581035</td>\n",
       "      <td>0.663114</td>\n",
       "      <td>0.604873</td>\n",
       "      <td>0.565239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.451806</td>\n",
       "      <td>0.641478</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.208954</td>\n",
       "      <td>0.049170</td>\n",
       "      <td>0.332716</td>\n",
       "      <td>0.510054</td>\n",
       "      <td>0.703606</td>\n",
       "      <td>0.744834</td>\n",
       "      <td>0.408025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520716</td>\n",
       "      <td>0.559493</td>\n",
       "      <td>0.642789</td>\n",
       "      <td>0.690123</td>\n",
       "      <td>0.721847</td>\n",
       "      <td>0.603151</td>\n",
       "      <td>0.397261</td>\n",
       "      <td>0.693217</td>\n",
       "      <td>0.640636</td>\n",
       "      <td>0.903773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.303734</td>\n",
       "      <td>0.241337</td>\n",
       "      <td>0.181746</td>\n",
       "      <td>0.083725</td>\n",
       "      <td>0.291007</td>\n",
       "      <td>0.350302</td>\n",
       "      <td>0.347274</td>\n",
       "      <td>0.297372</td>\n",
       "      <td>0.188994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243303</td>\n",
       "      <td>0.275874</td>\n",
       "      <td>0.253299</td>\n",
       "      <td>0.362273</td>\n",
       "      <td>0.330227</td>\n",
       "      <td>0.376047</td>\n",
       "      <td>0.304584</td>\n",
       "      <td>0.330178</td>\n",
       "      <td>0.217936</td>\n",
       "      <td>0.257098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.166736</td>\n",
       "      <td>0.232807</td>\n",
       "      <td>0.228855</td>\n",
       "      <td>0.098563</td>\n",
       "      <td>0.142126</td>\n",
       "      <td>0.288010</td>\n",
       "      <td>0.312017</td>\n",
       "      <td>0.371248</td>\n",
       "      <td>0.411138</td>\n",
       "      <td>0.236513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.454105</td>\n",
       "      <td>0.360408</td>\n",
       "      <td>0.503277</td>\n",
       "      <td>0.446513</td>\n",
       "      <td>0.449002</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.391057</td>\n",
       "      <td>0.408817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.212221</td>\n",
       "      <td>0.314303</td>\n",
       "      <td>0.273530</td>\n",
       "      <td>0.283591</td>\n",
       "      <td>0.244580</td>\n",
       "      <td>0.407417</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.388381</td>\n",
       "      <td>0.417070</td>\n",
       "      <td>0.453184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328261</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.164348</td>\n",
       "      <td>0.424535</td>\n",
       "      <td>0.220090</td>\n",
       "      <td>0.611743</td>\n",
       "      <td>0.583080</td>\n",
       "      <td>0.643023</td>\n",
       "      <td>0.664146</td>\n",
       "      <td>0.650163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.294817</td>\n",
       "      <td>0.313914</td>\n",
       "      <td>0.148785</td>\n",
       "      <td>0.139622</td>\n",
       "      <td>0.229949</td>\n",
       "      <td>0.402298</td>\n",
       "      <td>0.477617</td>\n",
       "      <td>0.482576</td>\n",
       "      <td>0.334480</td>\n",
       "      <td>0.110366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337665</td>\n",
       "      <td>0.366860</td>\n",
       "      <td>0.341879</td>\n",
       "      <td>0.514223</td>\n",
       "      <td>0.546273</td>\n",
       "      <td>0.612127</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.617413</td>\n",
       "      <td>0.630709</td>\n",
       "      <td>0.687795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.153851</td>\n",
       "      <td>0.232463</td>\n",
       "      <td>0.313080</td>\n",
       "      <td>0.294069</td>\n",
       "      <td>0.172837</td>\n",
       "      <td>0.421127</td>\n",
       "      <td>0.234559</td>\n",
       "      <td>0.485732</td>\n",
       "      <td>0.576266</td>\n",
       "      <td>0.364929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451604</td>\n",
       "      <td>0.514005</td>\n",
       "      <td>0.491441</td>\n",
       "      <td>0.737952</td>\n",
       "      <td>0.654772</td>\n",
       "      <td>0.760460</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.781028</td>\n",
       "      <td>0.761569</td>\n",
       "      <td>0.767024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.321104</td>\n",
       "      <td>0.326055</td>\n",
       "      <td>0.222791</td>\n",
       "      <td>0.192897</td>\n",
       "      <td>0.210857</td>\n",
       "      <td>0.306321</td>\n",
       "      <td>0.453252</td>\n",
       "      <td>0.579383</td>\n",
       "      <td>0.420926</td>\n",
       "      <td>0.211889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>0.792095</td>\n",
       "      <td>0.669196</td>\n",
       "      <td>0.785608</td>\n",
       "      <td>0.766587</td>\n",
       "      <td>0.765732</td>\n",
       "      <td>0.724054</td>\n",
       "      <td>0.668746</td>\n",
       "      <td>0.780379</td>\n",
       "      <td>0.664922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.161212</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.113610</td>\n",
       "      <td>0.109178</td>\n",
       "      <td>0.031598</td>\n",
       "      <td>0.217324</td>\n",
       "      <td>0.285058</td>\n",
       "      <td>0.305341</td>\n",
       "      <td>0.336076</td>\n",
       "      <td>0.176941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120514</td>\n",
       "      <td>0.149064</td>\n",
       "      <td>0.291058</td>\n",
       "      <td>0.378719</td>\n",
       "      <td>0.436830</td>\n",
       "      <td>0.501809</td>\n",
       "      <td>0.437456</td>\n",
       "      <td>0.484619</td>\n",
       "      <td>0.537477</td>\n",
       "      <td>0.501967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.489010</td>\n",
       "      <td>0.543733</td>\n",
       "      <td>0.350587</td>\n",
       "      <td>0.390935</td>\n",
       "      <td>0.395234</td>\n",
       "      <td>0.257436</td>\n",
       "      <td>0.395347</td>\n",
       "      <td>0.687178</td>\n",
       "      <td>0.582960</td>\n",
       "      <td>0.485252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225750</td>\n",
       "      <td>0.372828</td>\n",
       "      <td>0.251196</td>\n",
       "      <td>0.566662</td>\n",
       "      <td>0.555083</td>\n",
       "      <td>0.548357</td>\n",
       "      <td>0.554499</td>\n",
       "      <td>0.596409</td>\n",
       "      <td>0.580638</td>\n",
       "      <td>0.543759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.185180</td>\n",
       "      <td>0.191157</td>\n",
       "      <td>0.184828</td>\n",
       "      <td>0.133391</td>\n",
       "      <td>0.093971</td>\n",
       "      <td>0.380398</td>\n",
       "      <td>0.378637</td>\n",
       "      <td>0.367537</td>\n",
       "      <td>0.273682</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.190103</td>\n",
       "      <td>0.180878</td>\n",
       "      <td>0.342567</td>\n",
       "      <td>0.311679</td>\n",
       "      <td>0.446827</td>\n",
       "      <td>0.428373</td>\n",
       "      <td>0.472539</td>\n",
       "      <td>0.446805</td>\n",
       "      <td>0.427421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.414097</td>\n",
       "      <td>0.510722</td>\n",
       "      <td>0.425591</td>\n",
       "      <td>0.181123</td>\n",
       "      <td>0.265320</td>\n",
       "      <td>0.422467</td>\n",
       "      <td>0.621261</td>\n",
       "      <td>0.663371</td>\n",
       "      <td>0.673855</td>\n",
       "      <td>0.530631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063118</td>\n",
       "      <td>0.619816</td>\n",
       "      <td>0.472299</td>\n",
       "      <td>0.642770</td>\n",
       "      <td>0.627223</td>\n",
       "      <td>0.611157</td>\n",
       "      <td>0.661854</td>\n",
       "      <td>0.577225</td>\n",
       "      <td>0.562157</td>\n",
       "      <td>0.486051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.273835</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.241518</td>\n",
       "      <td>0.214933</td>\n",
       "      <td>0.224630</td>\n",
       "      <td>0.373993</td>\n",
       "      <td>0.430920</td>\n",
       "      <td>0.463338</td>\n",
       "      <td>0.408759</td>\n",
       "      <td>0.311375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109942</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.587335</td>\n",
       "      <td>0.744851</td>\n",
       "      <td>0.788641</td>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.736138</td>\n",
       "      <td>0.645056</td>\n",
       "      <td>0.680889</td>\n",
       "      <td>0.663242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.203264</td>\n",
       "      <td>0.232998</td>\n",
       "      <td>0.201963</td>\n",
       "      <td>0.196347</td>\n",
       "      <td>0.174460</td>\n",
       "      <td>0.270483</td>\n",
       "      <td>0.359716</td>\n",
       "      <td>0.431221</td>\n",
       "      <td>0.409139</td>\n",
       "      <td>0.234844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.336214</td>\n",
       "      <td>0.530576</td>\n",
       "      <td>0.578884</td>\n",
       "      <td>0.612549</td>\n",
       "      <td>0.611728</td>\n",
       "      <td>0.638440</td>\n",
       "      <td>0.614772</td>\n",
       "      <td>0.440718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.251592</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.335980</td>\n",
       "      <td>0.289786</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>0.314233</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.396668</td>\n",
       "      <td>0.460233</td>\n",
       "      <td>0.298628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132073</td>\n",
       "      <td>0.600131</td>\n",
       "      <td>0.518616</td>\n",
       "      <td>0.636980</td>\n",
       "      <td>0.646519</td>\n",
       "      <td>0.649803</td>\n",
       "      <td>0.618439</td>\n",
       "      <td>0.720033</td>\n",
       "      <td>0.671382</td>\n",
       "      <td>0.634933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.271645</td>\n",
       "      <td>0.304407</td>\n",
       "      <td>0.292388</td>\n",
       "      <td>0.252096</td>\n",
       "      <td>0.232750</td>\n",
       "      <td>0.306492</td>\n",
       "      <td>0.460770</td>\n",
       "      <td>0.616482</td>\n",
       "      <td>0.699032</td>\n",
       "      <td>0.679384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217448</td>\n",
       "      <td>0.170441</td>\n",
       "      <td>0.328052</td>\n",
       "      <td>0.134530</td>\n",
       "      <td>0.137918</td>\n",
       "      <td>0.450345</td>\n",
       "      <td>0.450958</td>\n",
       "      <td>0.590293</td>\n",
       "      <td>0.503477</td>\n",
       "      <td>0.626183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.490170</td>\n",
       "      <td>0.222117</td>\n",
       "      <td>0.162691</td>\n",
       "      <td>0.465112</td>\n",
       "      <td>0.367150</td>\n",
       "      <td>0.521705</td>\n",
       "      <td>0.692028</td>\n",
       "      <td>0.587893</td>\n",
       "      <td>0.142993</td>\n",
       "      <td>0.263443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190133</td>\n",
       "      <td>0.333579</td>\n",
       "      <td>0.049493</td>\n",
       "      <td>0.616007</td>\n",
       "      <td>0.471484</td>\n",
       "      <td>0.619379</td>\n",
       "      <td>0.255625</td>\n",
       "      <td>0.440703</td>\n",
       "      <td>0.336795</td>\n",
       "      <td>0.483580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.345256</td>\n",
       "      <td>0.128816</td>\n",
       "      <td>0.291174</td>\n",
       "      <td>0.372169</td>\n",
       "      <td>0.250933</td>\n",
       "      <td>0.454495</td>\n",
       "      <td>0.435239</td>\n",
       "      <td>0.188780</td>\n",
       "      <td>0.390431</td>\n",
       "      <td>0.485244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368110</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.429646</td>\n",
       "      <td>0.426759</td>\n",
       "      <td>0.372834</td>\n",
       "      <td>0.264898</td>\n",
       "      <td>0.194954</td>\n",
       "      <td>0.314796</td>\n",
       "      <td>0.331587</td>\n",
       "      <td>0.561041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.321422</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>0.372139</td>\n",
       "      <td>0.360827</td>\n",
       "      <td>0.282884</td>\n",
       "      <td>0.236713</td>\n",
       "      <td>0.396311</td>\n",
       "      <td>0.557777</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.531124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149764</td>\n",
       "      <td>0.263484</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>0.590204</td>\n",
       "      <td>0.462965</td>\n",
       "      <td>0.657607</td>\n",
       "      <td>0.603839</td>\n",
       "      <td>0.674309</td>\n",
       "      <td>0.637826</td>\n",
       "      <td>0.538086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.135768</td>\n",
       "      <td>0.287887</td>\n",
       "      <td>0.313405</td>\n",
       "      <td>0.230236</td>\n",
       "      <td>0.059942</td>\n",
       "      <td>0.224986</td>\n",
       "      <td>0.342858</td>\n",
       "      <td>0.540299</td>\n",
       "      <td>0.432607</td>\n",
       "      <td>0.247073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254482</td>\n",
       "      <td>0.693262</td>\n",
       "      <td>0.533125</td>\n",
       "      <td>0.724634</td>\n",
       "      <td>0.691070</td>\n",
       "      <td>0.667851</td>\n",
       "      <td>0.670299</td>\n",
       "      <td>0.428083</td>\n",
       "      <td>0.617288</td>\n",
       "      <td>0.550690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.297288</td>\n",
       "      <td>0.423299</td>\n",
       "      <td>0.361215</td>\n",
       "      <td>0.191211</td>\n",
       "      <td>0.140233</td>\n",
       "      <td>0.408669</td>\n",
       "      <td>0.593002</td>\n",
       "      <td>0.585452</td>\n",
       "      <td>0.555680</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.669626</td>\n",
       "      <td>0.568575</td>\n",
       "      <td>0.671641</td>\n",
       "      <td>0.678171</td>\n",
       "      <td>0.447724</td>\n",
       "      <td>0.584199</td>\n",
       "      <td>0.499636</td>\n",
       "      <td>0.632267</td>\n",
       "      <td>0.638683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.269917</td>\n",
       "      <td>0.177213</td>\n",
       "      <td>0.212517</td>\n",
       "      <td>0.353025</td>\n",
       "      <td>0.326605</td>\n",
       "      <td>0.701159</td>\n",
       "      <td>0.648994</td>\n",
       "      <td>0.635989</td>\n",
       "      <td>0.667364</td>\n",
       "      <td>0.566267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023898</td>\n",
       "      <td>0.326023</td>\n",
       "      <td>0.183233</td>\n",
       "      <td>0.667199</td>\n",
       "      <td>0.555050</td>\n",
       "      <td>0.639707</td>\n",
       "      <td>0.663978</td>\n",
       "      <td>0.550821</td>\n",
       "      <td>0.612586</td>\n",
       "      <td>0.209511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.388268</td>\n",
       "      <td>0.345894</td>\n",
       "      <td>0.151175</td>\n",
       "      <td>0.054279</td>\n",
       "      <td>0.169849</td>\n",
       "      <td>0.281423</td>\n",
       "      <td>0.407204</td>\n",
       "      <td>0.417523</td>\n",
       "      <td>0.204821</td>\n",
       "      <td>0.132005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092592</td>\n",
       "      <td>0.408139</td>\n",
       "      <td>0.270076</td>\n",
       "      <td>0.517468</td>\n",
       "      <td>0.534059</td>\n",
       "      <td>0.437656</td>\n",
       "      <td>0.522537</td>\n",
       "      <td>0.466722</td>\n",
       "      <td>0.525504</td>\n",
       "      <td>0.562328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.362622</td>\n",
       "      <td>0.483993</td>\n",
       "      <td>0.499560</td>\n",
       "      <td>0.312557</td>\n",
       "      <td>0.083127</td>\n",
       "      <td>0.304393</td>\n",
       "      <td>0.492889</td>\n",
       "      <td>0.561032</td>\n",
       "      <td>0.542897</td>\n",
       "      <td>0.303674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220073</td>\n",
       "      <td>0.215437</td>\n",
       "      <td>0.094260</td>\n",
       "      <td>0.607257</td>\n",
       "      <td>0.568140</td>\n",
       "      <td>0.649109</td>\n",
       "      <td>0.628853</td>\n",
       "      <td>0.672990</td>\n",
       "      <td>0.658514</td>\n",
       "      <td>0.632774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.581605</td>\n",
       "      <td>0.513681</td>\n",
       "      <td>0.216636</td>\n",
       "      <td>0.081005</td>\n",
       "      <td>0.175197</td>\n",
       "      <td>0.369603</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.720398</td>\n",
       "      <td>0.544046</td>\n",
       "      <td>0.172056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256899</td>\n",
       "      <td>0.290731</td>\n",
       "      <td>0.112828</td>\n",
       "      <td>0.751939</td>\n",
       "      <td>0.695803</td>\n",
       "      <td>0.843906</td>\n",
       "      <td>0.858290</td>\n",
       "      <td>0.847155</td>\n",
       "      <td>0.876057</td>\n",
       "      <td>0.818823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.222386</td>\n",
       "      <td>0.173987</td>\n",
       "      <td>0.351586</td>\n",
       "      <td>0.339462</td>\n",
       "      <td>0.198676</td>\n",
       "      <td>0.454675</td>\n",
       "      <td>0.439366</td>\n",
       "      <td>0.366911</td>\n",
       "      <td>0.296860</td>\n",
       "      <td>0.167175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067230</td>\n",
       "      <td>0.159494</td>\n",
       "      <td>0.169361</td>\n",
       "      <td>0.754377</td>\n",
       "      <td>0.503374</td>\n",
       "      <td>0.732805</td>\n",
       "      <td>0.631216</td>\n",
       "      <td>0.772666</td>\n",
       "      <td>0.646068</td>\n",
       "      <td>0.744285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.444541</td>\n",
       "      <td>0.455418</td>\n",
       "      <td>0.422557</td>\n",
       "      <td>0.376933</td>\n",
       "      <td>0.319180</td>\n",
       "      <td>0.514372</td>\n",
       "      <td>0.485073</td>\n",
       "      <td>0.521098</td>\n",
       "      <td>0.554315</td>\n",
       "      <td>0.485092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481262</td>\n",
       "      <td>0.298456</td>\n",
       "      <td>0.478457</td>\n",
       "      <td>0.406082</td>\n",
       "      <td>0.297591</td>\n",
       "      <td>0.617381</td>\n",
       "      <td>0.383206</td>\n",
       "      <td>0.726699</td>\n",
       "      <td>0.582256</td>\n",
       "      <td>0.644394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.459095</td>\n",
       "      <td>0.282350</td>\n",
       "      <td>0.230584</td>\n",
       "      <td>0.429553</td>\n",
       "      <td>0.397075</td>\n",
       "      <td>0.500312</td>\n",
       "      <td>0.564350</td>\n",
       "      <td>0.428535</td>\n",
       "      <td>0.394207</td>\n",
       "      <td>0.587972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079869</td>\n",
       "      <td>0.179732</td>\n",
       "      <td>0.103639</td>\n",
       "      <td>0.430275</td>\n",
       "      <td>0.412702</td>\n",
       "      <td>0.517904</td>\n",
       "      <td>0.472276</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.479127</td>\n",
       "      <td>0.481460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.335911</td>\n",
       "      <td>0.302430</td>\n",
       "      <td>0.349833</td>\n",
       "      <td>0.290462</td>\n",
       "      <td>0.257008</td>\n",
       "      <td>0.444992</td>\n",
       "      <td>0.439600</td>\n",
       "      <td>0.481541</td>\n",
       "      <td>0.582117</td>\n",
       "      <td>0.469245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424028</td>\n",
       "      <td>0.515077</td>\n",
       "      <td>0.519322</td>\n",
       "      <td>0.554239</td>\n",
       "      <td>0.562185</td>\n",
       "      <td>0.578969</td>\n",
       "      <td>0.491088</td>\n",
       "      <td>0.665479</td>\n",
       "      <td>0.642151</td>\n",
       "      <td>0.665895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.242838</td>\n",
       "      <td>0.189017</td>\n",
       "      <td>0.151056</td>\n",
       "      <td>0.138595</td>\n",
       "      <td>0.138360</td>\n",
       "      <td>0.404109</td>\n",
       "      <td>0.490134</td>\n",
       "      <td>0.363649</td>\n",
       "      <td>0.329794</td>\n",
       "      <td>0.201837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.340637</td>\n",
       "      <td>0.351070</td>\n",
       "      <td>0.551454</td>\n",
       "      <td>0.396922</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>0.419849</td>\n",
       "      <td>0.546141</td>\n",
       "      <td>0.499602</td>\n",
       "      <td>0.510252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.328235</td>\n",
       "      <td>0.258763</td>\n",
       "      <td>0.255813</td>\n",
       "      <td>0.445829</td>\n",
       "      <td>0.611312</td>\n",
       "      <td>0.431975</td>\n",
       "      <td>0.600617</td>\n",
       "      <td>0.606533</td>\n",
       "      <td>0.705873</td>\n",
       "      <td>0.745688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148019</td>\n",
       "      <td>0.382024</td>\n",
       "      <td>0.197885</td>\n",
       "      <td>0.819744</td>\n",
       "      <td>0.654543</td>\n",
       "      <td>0.879947</td>\n",
       "      <td>0.919711</td>\n",
       "      <td>0.602768</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.835481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.218452</td>\n",
       "      <td>0.243740</td>\n",
       "      <td>0.330135</td>\n",
       "      <td>0.335441</td>\n",
       "      <td>0.337672</td>\n",
       "      <td>0.507544</td>\n",
       "      <td>0.419084</td>\n",
       "      <td>0.432047</td>\n",
       "      <td>0.466302</td>\n",
       "      <td>0.464015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170216</td>\n",
       "      <td>0.246070</td>\n",
       "      <td>0.225472</td>\n",
       "      <td>0.457008</td>\n",
       "      <td>0.409195</td>\n",
       "      <td>0.577883</td>\n",
       "      <td>0.523435</td>\n",
       "      <td>0.604901</td>\n",
       "      <td>0.631543</td>\n",
       "      <td>0.432019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.335002</td>\n",
       "      <td>0.281724</td>\n",
       "      <td>0.279052</td>\n",
       "      <td>0.229810</td>\n",
       "      <td>0.191256</td>\n",
       "      <td>0.351076</td>\n",
       "      <td>0.646360</td>\n",
       "      <td>0.657169</td>\n",
       "      <td>0.512431</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.664381</td>\n",
       "      <td>0.324030</td>\n",
       "      <td>0.733501</td>\n",
       "      <td>0.723098</td>\n",
       "      <td>0.743430</td>\n",
       "      <td>0.739063</td>\n",
       "      <td>0.750537</td>\n",
       "      <td>0.749831</td>\n",
       "      <td>0.730180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.345639</td>\n",
       "      <td>0.159881</td>\n",
       "      <td>0.259870</td>\n",
       "      <td>0.245762</td>\n",
       "      <td>0.060896</td>\n",
       "      <td>0.501267</td>\n",
       "      <td>0.452641</td>\n",
       "      <td>0.394119</td>\n",
       "      <td>0.484769</td>\n",
       "      <td>0.222012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227919</td>\n",
       "      <td>0.503628</td>\n",
       "      <td>0.496879</td>\n",
       "      <td>0.470791</td>\n",
       "      <td>0.468603</td>\n",
       "      <td>0.482474</td>\n",
       "      <td>0.481370</td>\n",
       "      <td>0.491323</td>\n",
       "      <td>0.544761</td>\n",
       "      <td>0.498562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.319675</td>\n",
       "      <td>0.260443</td>\n",
       "      <td>0.197880</td>\n",
       "      <td>0.133062</td>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.378758</td>\n",
       "      <td>0.492121</td>\n",
       "      <td>0.439531</td>\n",
       "      <td>0.262509</td>\n",
       "      <td>0.124266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>0.575324</td>\n",
       "      <td>0.614020</td>\n",
       "      <td>0.379273</td>\n",
       "      <td>0.579082</td>\n",
       "      <td>0.642218</td>\n",
       "      <td>0.587398</td>\n",
       "      <td>0.786474</td>\n",
       "      <td>0.595299</td>\n",
       "      <td>0.727544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.148045</td>\n",
       "      <td>0.192859</td>\n",
       "      <td>0.186775</td>\n",
       "      <td>0.130149</td>\n",
       "      <td>0.158366</td>\n",
       "      <td>0.170028</td>\n",
       "      <td>0.272623</td>\n",
       "      <td>0.313282</td>\n",
       "      <td>0.297090</td>\n",
       "      <td>0.288587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251610</td>\n",
       "      <td>0.399288</td>\n",
       "      <td>0.458763</td>\n",
       "      <td>0.531294</td>\n",
       "      <td>0.429982</td>\n",
       "      <td>0.578859</td>\n",
       "      <td>0.504011</td>\n",
       "      <td>0.610492</td>\n",
       "      <td>0.561359</td>\n",
       "      <td>0.536295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 37004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              102956    102957    102958    102959    102960    103046  \\\n",
       "subject_id                                                               \n",
       "116         0.229362  0.205727  0.053395  0.074691  0.113833  0.423250   \n",
       "139         0.109401  0.150143  0.197897  0.425160  0.362449  0.138988   \n",
       "147         0.162510  0.179246  0.263863  0.298417  0.158954  0.351168   \n",
       "135         0.153985  0.113712  0.141172  0.173383  0.114053  0.193699   \n",
       "101         0.364223  0.145639  0.089289  0.140574  0.196354  0.665556   \n",
       "150         0.246922  0.405237  0.310447  0.300769  0.206188  0.243030   \n",
       "122         0.204949  0.197069  0.196635  0.160092  0.044966  0.266371   \n",
       "146         0.175004  0.321799  0.394048  0.364054  0.238638  0.406729   \n",
       "138         0.188685  0.139497  0.121198  0.156062  0.143464  0.292154   \n",
       "134         0.151877  0.114629  0.086310  0.094285  0.038729  0.235435   \n",
       "123         0.226707  0.148323  0.145312  0.188839  0.132454  0.452179   \n",
       "149         0.451806  0.641478  0.613265  0.208954  0.049170  0.332716   \n",
       "137         0.323060  0.303734  0.241337  0.181746  0.083725  0.291007   \n",
       "118         0.166736  0.232807  0.228855  0.098563  0.142126  0.288010   \n",
       "114         0.212221  0.314303  0.273530  0.283591  0.244580  0.407417   \n",
       "145         0.294817  0.313914  0.148785  0.139622  0.229949  0.402298   \n",
       "120         0.153851  0.232463  0.313080  0.294069  0.172837  0.421127   \n",
       "103         0.321104  0.326055  0.222791  0.192897  0.210857  0.306321   \n",
       "119         0.161212  0.162602  0.113610  0.109178  0.031598  0.217324   \n",
       "148         0.489010  0.543733  0.350587  0.390935  0.395234  0.257436   \n",
       "144         0.185180  0.191157  0.184828  0.133391  0.093971  0.380398   \n",
       "115         0.414097  0.510722  0.425591  0.181123  0.265320  0.422467   \n",
       "121         0.273835  0.291100  0.241518  0.214933  0.224630  0.373993   \n",
       "102         0.203264  0.232998  0.201963  0.196347  0.174460  0.270483   \n",
       "105         0.251592  0.310680  0.335980  0.289786  0.044907  0.314233   \n",
       "109         0.271645  0.304407  0.292388  0.252096  0.232750  0.306492   \n",
       "126         0.490170  0.222117  0.162691  0.465112  0.367150  0.521705   \n",
       "143         0.345256  0.128816  0.291174  0.372169  0.250933  0.454495   \n",
       "131         0.321422  0.397050  0.372139  0.360827  0.282884  0.236713   \n",
       "104         0.135768  0.287887  0.313405  0.230236  0.059942  0.224986   \n",
       "127         0.297288  0.423299  0.361215  0.191211  0.140233  0.408669   \n",
       "108         0.269917  0.177213  0.212517  0.353025  0.326605  0.701159   \n",
       "113         0.388268  0.345894  0.151175  0.054279  0.169849  0.281423   \n",
       "142         0.362622  0.483993  0.499560  0.312557  0.083127  0.304393   \n",
       "130         0.581605  0.513681  0.216636  0.081005  0.175197  0.369603   \n",
       "124         0.222386  0.173987  0.351586  0.339462  0.198676  0.454675   \n",
       "128         0.444541  0.455418  0.422557  0.376933  0.319180  0.514372   \n",
       "107         0.459095  0.282350  0.230584  0.429553  0.397075  0.500312   \n",
       "133         0.335911  0.302430  0.349833  0.290462  0.257008  0.444992   \n",
       "141         0.242838  0.189017  0.151056  0.138595  0.138360  0.404109   \n",
       "110         0.328235  0.258763  0.255813  0.445829  0.611312  0.431975   \n",
       "125         0.218452  0.243740  0.330135  0.335441  0.337672  0.507544   \n",
       "106         0.335002  0.281724  0.279052  0.229810  0.191256  0.351076   \n",
       "129         0.345639  0.159881  0.259870  0.245762  0.060896  0.501267   \n",
       "111         0.319675  0.260443  0.197880  0.133062  0.010432  0.378758   \n",
       "140         0.148045  0.192859  0.186775  0.130149  0.158366  0.170028   \n",
       "\n",
       "              103047    103048    103049    103050  ...    797919    798009  \\\n",
       "subject_id                                          ...                       \n",
       "116         0.513379  0.377440  0.153252  0.007786  ...  0.463366  0.303836   \n",
       "139         0.176965  0.240504  0.407940  0.543465  ...  0.066427  0.405873   \n",
       "147         0.314347  0.409709  0.518645  0.382331  ...  0.110859  0.403632   \n",
       "135         0.248250  0.240887  0.267419  0.182920  ...  0.068370  0.154941   \n",
       "101         0.729897  0.594886  0.243001  0.039168  ...  0.227021  0.293693   \n",
       "150         0.413811  0.660632  0.502521  0.380426  ...  0.058324  0.354329   \n",
       "122         0.292215  0.281765  0.244403  0.121008  ...  0.118555  0.191085   \n",
       "146         0.353518  0.489140  0.512552  0.508472  ...  0.404712  0.447947   \n",
       "138         0.373723  0.256809  0.156228  0.161139  ...  0.211858  0.634101   \n",
       "134         0.249673  0.202294  0.165682  0.102519  ...  0.079227  0.257531   \n",
       "123         0.430163  0.223039  0.183372  0.328671  ...  0.296936  0.688628   \n",
       "149         0.510054  0.703606  0.744834  0.408025  ...  0.520716  0.559493   \n",
       "137         0.350302  0.347274  0.297372  0.188994  ...  0.243303  0.275874   \n",
       "118         0.312017  0.371248  0.411138  0.236513  ...  0.056186  0.454105   \n",
       "114         0.329300  0.388381  0.417070  0.453184  ...  0.328261  0.001577   \n",
       "145         0.477617  0.482576  0.334480  0.110366  ...  0.337665  0.366860   \n",
       "120         0.234559  0.485732  0.576266  0.364929  ...  0.451604  0.514005   \n",
       "103         0.453252  0.579383  0.420926  0.211889  ...  0.288900  0.792095   \n",
       "119         0.285058  0.305341  0.336076  0.176941  ...  0.120514  0.149064   \n",
       "148         0.395347  0.687178  0.582960  0.485252  ...  0.225750  0.372828   \n",
       "144         0.378637  0.367537  0.273682  0.133923  ...  0.269310  0.190103   \n",
       "115         0.621261  0.663371  0.673855  0.530631  ...  0.063118  0.619816   \n",
       "121         0.430920  0.463338  0.408759  0.311375  ...  0.109942  0.754897   \n",
       "102         0.359716  0.431221  0.409139  0.234844  ...  0.062602  0.435583   \n",
       "105         0.386800  0.396668  0.460233  0.298628  ...  0.132073  0.600131   \n",
       "109         0.460770  0.616482  0.699032  0.679384  ...  0.217448  0.170441   \n",
       "126         0.692028  0.587893  0.142993  0.263443  ...  0.190133  0.333579   \n",
       "143         0.435239  0.188780  0.390431  0.485244  ...  0.368110  0.395349   \n",
       "131         0.396311  0.557777  0.644295  0.531124  ...  0.149764  0.263484   \n",
       "104         0.342858  0.540299  0.432607  0.247073  ...  0.254482  0.693262   \n",
       "127         0.593002  0.585452  0.555680  0.434900  ...  0.217647  0.669626   \n",
       "108         0.648994  0.635989  0.667364  0.566267  ...  0.023898  0.326023   \n",
       "113         0.407204  0.417523  0.204821  0.132005  ...  0.092592  0.408139   \n",
       "142         0.492889  0.561032  0.542897  0.303674  ...  0.220073  0.215437   \n",
       "130         0.641618  0.720398  0.544046  0.172056  ...  0.256899  0.290731   \n",
       "124         0.439366  0.366911  0.296860  0.167175  ...  0.067230  0.159494   \n",
       "128         0.485073  0.521098  0.554315  0.485092  ...  0.481262  0.298456   \n",
       "107         0.564350  0.428535  0.394207  0.587972  ...  0.079869  0.179732   \n",
       "133         0.439600  0.481541  0.582117  0.469245  ...  0.424028  0.515077   \n",
       "141         0.490134  0.363649  0.329794  0.201837  ...  0.189394  0.340637   \n",
       "110         0.600617  0.606533  0.705873  0.745688  ...  0.148019  0.382024   \n",
       "125         0.419084  0.432047  0.466302  0.464015  ...  0.170216  0.246070   \n",
       "106         0.646360  0.657169  0.512431  0.305400  ...  0.247700  0.664381   \n",
       "129         0.452641  0.394119  0.484769  0.222012  ...  0.227919  0.503628   \n",
       "111         0.492121  0.439531  0.262509  0.124266  ...  0.539521  0.575324   \n",
       "140         0.272623  0.313282  0.297090  0.288587  ...  0.251610  0.399288   \n",
       "\n",
       "              798010    798099    798100    798190    798191    798281  \\\n",
       "subject_id                                                               \n",
       "116         0.372540  0.605460  0.464765  0.746839  0.739713  0.870503   \n",
       "139         0.192811  0.508609  0.499546  0.555987  0.478337  0.583788   \n",
       "147         0.583603  0.690095  0.910620  0.837578  0.951557  0.822104   \n",
       "135         0.097959  0.284367  0.265228  0.388628  0.386707  0.442965   \n",
       "101         0.213777  0.688021  0.515107  0.662774  0.660089  0.682468   \n",
       "150         0.274899  0.790549  0.449493  0.734528  0.539761  0.682080   \n",
       "122         0.216092  0.368782  0.331164  0.385139  0.412472  0.474175   \n",
       "146         0.505782  0.575915  0.614407  0.668394  0.675969  0.663611   \n",
       "138         0.550631  0.687401  0.573499  0.555129  0.571267  0.448494   \n",
       "134         0.202325  0.400190  0.422159  0.460475  0.419332  0.360247   \n",
       "123         0.525831  0.544609  0.617222  0.597075  0.581035  0.663114   \n",
       "149         0.642789  0.690123  0.721847  0.603151  0.397261  0.693217   \n",
       "137         0.253299  0.362273  0.330227  0.376047  0.304584  0.330178   \n",
       "118         0.360408  0.503277  0.446513  0.449002  0.356061  0.371000   \n",
       "114         0.164348  0.424535  0.220090  0.611743  0.583080  0.643023   \n",
       "145         0.341879  0.514223  0.546273  0.612127  0.616575  0.617413   \n",
       "120         0.491441  0.737952  0.654772  0.760460  0.728563  0.781028   \n",
       "103         0.669196  0.785608  0.766587  0.765732  0.724054  0.668746   \n",
       "119         0.291058  0.378719  0.436830  0.501809  0.437456  0.484619   \n",
       "148         0.251196  0.566662  0.555083  0.548357  0.554499  0.596409   \n",
       "144         0.180878  0.342567  0.311679  0.446827  0.428373  0.472539   \n",
       "115         0.472299  0.642770  0.627223  0.611157  0.661854  0.577225   \n",
       "121         0.587335  0.744851  0.788641  0.655971  0.736138  0.645056   \n",
       "102         0.336214  0.530576  0.578884  0.612549  0.611728  0.638440   \n",
       "105         0.518616  0.636980  0.646519  0.649803  0.618439  0.720033   \n",
       "109         0.328052  0.134530  0.137918  0.450345  0.450958  0.590293   \n",
       "126         0.049493  0.616007  0.471484  0.619379  0.255625  0.440703   \n",
       "143         0.429646  0.426759  0.372834  0.264898  0.194954  0.314796   \n",
       "131         0.219109  0.590204  0.462965  0.657607  0.603839  0.674309   \n",
       "104         0.533125  0.724634  0.691070  0.667851  0.670299  0.428083   \n",
       "127         0.568575  0.671641  0.678171  0.447724  0.584199  0.499636   \n",
       "108         0.183233  0.667199  0.555050  0.639707  0.663978  0.550821   \n",
       "113         0.270076  0.517468  0.534059  0.437656  0.522537  0.466722   \n",
       "142         0.094260  0.607257  0.568140  0.649109  0.628853  0.672990   \n",
       "130         0.112828  0.751939  0.695803  0.843906  0.858290  0.847155   \n",
       "124         0.169361  0.754377  0.503374  0.732805  0.631216  0.772666   \n",
       "128         0.478457  0.406082  0.297591  0.617381  0.383206  0.726699   \n",
       "107         0.103639  0.430275  0.412702  0.517904  0.472276  0.503700   \n",
       "133         0.519322  0.554239  0.562185  0.578969  0.491088  0.665479   \n",
       "141         0.351070  0.551454  0.396922  0.538767  0.419849  0.546141   \n",
       "110         0.197885  0.819744  0.654543  0.879947  0.919711  0.602768   \n",
       "125         0.225472  0.457008  0.409195  0.577883  0.523435  0.604901   \n",
       "106         0.324030  0.733501  0.723098  0.743430  0.739063  0.750537   \n",
       "129         0.496879  0.470791  0.468603  0.482474  0.481370  0.491323   \n",
       "111         0.614020  0.379273  0.579082  0.642218  0.587398  0.786474   \n",
       "140         0.458763  0.531294  0.429982  0.578859  0.504011  0.610492   \n",
       "\n",
       "              798282    798373  \n",
       "subject_id                      \n",
       "116         0.752853  0.769740  \n",
       "139         0.478562  0.429630  \n",
       "147         0.886667  0.739561  \n",
       "135         0.473160  0.499106  \n",
       "101         0.690582  0.717662  \n",
       "150         0.574928  0.593957  \n",
       "122         0.450113  0.474031  \n",
       "146         0.682129  0.510989  \n",
       "138         0.551988  0.422085  \n",
       "134         0.399696  0.351100  \n",
       "123         0.604873  0.565239  \n",
       "149         0.640636  0.903773  \n",
       "137         0.217936  0.257098  \n",
       "118         0.391057  0.408817  \n",
       "114         0.664146  0.650163  \n",
       "145         0.630709  0.687795  \n",
       "120         0.761569  0.767024  \n",
       "103         0.780379  0.664922  \n",
       "119         0.537477  0.501967  \n",
       "148         0.580638  0.543759  \n",
       "144         0.446805  0.427421  \n",
       "115         0.562157  0.486051  \n",
       "121         0.680889  0.663242  \n",
       "102         0.614772  0.440718  \n",
       "105         0.671382  0.634933  \n",
       "109         0.503477  0.626183  \n",
       "126         0.336795  0.483580  \n",
       "143         0.331587  0.561041  \n",
       "131         0.637826  0.538086  \n",
       "104         0.617288  0.550690  \n",
       "127         0.632267  0.638683  \n",
       "108         0.612586  0.209511  \n",
       "113         0.525504  0.562328  \n",
       "142         0.658514  0.632774  \n",
       "130         0.876057  0.818823  \n",
       "124         0.646068  0.744285  \n",
       "128         0.582256  0.644394  \n",
       "107         0.479127  0.481460  \n",
       "133         0.642151  0.665895  \n",
       "141         0.499602  0.510252  \n",
       "110         0.897084  0.835481  \n",
       "125         0.631543  0.432019  \n",
       "106         0.749831  0.730180  \n",
       "129         0.544761  0.498562  \n",
       "111         0.595299  0.727544  \n",
       "140         0.561359  0.536295  \n",
       "\n",
       "[46 rows x 37004 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuroimaging_df_2 = neuroimaging_df_2.reindex(neuroimaging_df_1.index).dropna()\n",
    "neuroimaging_df_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Statistical Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moderated Mediation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def calculate_confidence_intervals(ab_paths, mediators):\n",
    "    \"\"\"\n",
    "    Calculates the confidence intervals and p-value based on the bootstrapped samples.\n",
    "\n",
    "    Parameters:\n",
    "    - ab_paths: list of lists containing the bootstrapped ab paths for each mediator.\n",
    "    - total_indirect_effects: list of bootstrapped summed ab paths.\n",
    "    - mediators: list of mediator names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for each mediator and the total indirect effect.\n",
    "    \"\"\"\n",
    "    ab_path_values = np.array(ab_paths)\n",
    "\n",
    "    # Check if there's only one mediator\n",
    "    if isinstance(mediators, str):\n",
    "        mediators = [mediators]\n",
    "\n",
    "    # Calculate mean indirect effect and confidence intervals for each mediator\n",
    "    mean_ab_paths = np.mean(ab_path_values, axis=0)\n",
    "    lower_bounds = np.percentile(ab_path_values, 2.5, axis=0)\n",
    "    upper_bounds = np.percentile(ab_path_values, 97.5, axis=0)\n",
    "\n",
    "    # Calculate p-values for each mediator\n",
    "    ab_path_p_values = [np.mean(np.sign(mean_ab_paths) * ab_path_values <= 0)]\n",
    "\n",
    "    # Create DataFrame to store the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Point Estimate': mean_ab_paths,\n",
    "        '2.5th Percentile': lower_bounds,\n",
    "        '97.5th Percentile': upper_bounds,\n",
    "        'P-value': ab_path_p_values\n",
    "    }, index=mediators)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def perform_mediated_moderation_analysis(dataframe, exposure, mediator, moderator, dependent_variable, bootstrap_samples=5000):\n",
    "    \"\"\"\n",
    "    Performs a mediated moderation analysis by estimating the joint indirect effects of an exposure variable\n",
    "    through a mediator on a dependent variable using bootstrapping, considering the moderating effect of another variable.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame containing the data.\n",
    "    - exposure: str, column name of the exposure variable.\n",
    "    - mediator: str, column name of the mediator variable.\n",
    "    - moderator: str, column name of the moderator variable.\n",
    "    - dependent_variable: str, column name of the dependent variable.\n",
    "    - bootstrap_samples: int, optional, number of bootstrap samples to be used (default is 5000).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for the indirect effect.\n",
    "\n",
    "    Example Usage:\n",
    "    result_df = perform_mediated_moderation_analysis(data_df, exposure='Age',\n",
    "                                                     mediator='Brain_Lobe',\n",
    "                                                     moderator='Stimulation',\n",
    "                                                     dependent_variable='Outcome')\n",
    "    \"\"\"\n",
    "\n",
    "    ab_paths = []\n",
    "\n",
    "    # Loop over each bootstrap sample\n",
    "    for i in range(bootstrap_samples):\n",
    "        # Resample the data with replacement\n",
    "        sample = dataframe.sample(frac=1, replace=True)\n",
    "\n",
    "        # Fit the models and calculate the indirect effect for this bootstrap sample\n",
    "        model_M = ols(f\"{mediator} ~ {moderator}\", data=sample).fit()\n",
    "        model_Y = ols(f\"{dependent_variable} ~ {exposure} + {mediator} + {moderator} + {exposure}:{mediator} + {exposure}:{moderator}\", data=sample).fit()\n",
    "\n",
    "        indirect_effect = model_M.params[moderator] * model_Y.params[f'{exposure}:{mediator}']\n",
    "\n",
    "        # Append the indirect effect to the list\n",
    "        ab_paths.append(indirect_effect)\n",
    "    # Calculate confidence intervals and p-values\n",
    "    result_df = calculate_confidence_intervals(ab_paths, mediators=mediator)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def voxelwise_mediated_moderation_analysis(mediator_df, moderator_df, exposure_df, outcome_df, bootstrap_samples=5000):\n",
    "    \"\"\"\n",
    "    Perform voxelwise mediated moderation analysis between the corresponding voxels from\n",
    "    neuroimaging dataframes and clinical dataframes on a patient's outcome.\n",
    "    \n",
    "    Parameters:\n",
    "        mediator_df (pd.DataFrame): DataFrame containing the mediator variable with patients in rows and 'subject_id' as index.\n",
    "        moderator_df (pd.DataFrame): DataFrame containing the moderator variable with patients in rows and 'subject_id' as index.\n",
    "        exposure_df (pd.DataFrame): DataFrame containing the exposure variable with patients in rows and 'subject_id' as index.\n",
    "        outcome_df (pd.DataFrame): DataFrame containing the outcome variable in 'outcome' column with patients in rows and 'subject_id' as index.\n",
    "        bootstrap_samples (int): Number of bootstrap samples to use in mediated moderation analysis.\n",
    "    \n",
    "    Returns:\n",
    "        results_df (pd.DataFrame): DataFrame containing mediated moderation analysis results for each voxel.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of voxels\n",
    "    n_voxels = exposure_df.shape[1]\n",
    "\n",
    "    # Initialize a list to store the results for each voxel\n",
    "    results = []\n",
    "\n",
    "    # Loop through each voxel and perform mediated moderation analysis\n",
    "    for i in tqdm(range(n_voxels)):\n",
    "        # Create temporary dataframe with outcome, mediator, moderator, and exposure data for the current voxel\n",
    "        temp_df = pd.DataFrame({\n",
    "            'exposure': exposure_df.iloc[:, i] if exposure_df.shape[1] > 1 else exposure_df.iloc[:, 0],\n",
    "            'mediator': mediator_df.iloc[:, i] if mediator_df.shape[1] > 1 else mediator_df.iloc[:, 0],\n",
    "            'moderator': moderator_df.iloc[:, i] if moderator_df.shape[1] > 1 else moderator_df.iloc[:, 0],\n",
    "            'outcome': outcome_df['outcome']\n",
    "        })\n",
    "\n",
    "        # Perform mediated moderation analysis on the temporary dataframe\n",
    "        result_df = perform_mediated_moderation_analysis(dataframe = temp_df,\n",
    "                                                         exposure = 'exposure', \n",
    "                                                         mediator = 'mediator', \n",
    "                                                         moderator = 'moderator', \n",
    "                                                         dependent_variable ='outcome', \n",
    "                                                         bootstrap_samples=bootstrap_samples)\n",
    "        # Append voxel index to result_df\n",
    "        result_df['voxel_index'] = i\n",
    "        results.append(result_df)\n",
    "\n",
    "    # Concatenate all result dataframes into one\n",
    "    results_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = voxelwise_mediated_moderation_analysis(mediator_df=neuroimaging_df_2,\n",
    "                                                    moderator_df=clinical_df_1, \n",
    "                                                    exposure_df=neuroimaging_df_1, \n",
    "                                                    outcome_df=outcomes_df, \n",
    "                                                    bootstrap_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Multiprocssed Voxelwise Mediated Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def calculate_confidence_intervals(ab_paths, mediators):\n",
    "    \"\"\"\n",
    "    Calculates the confidence intervals and p-value based on the bootstrapped samples.\n",
    "\n",
    "    Parameters:\n",
    "    - ab_paths: list of lists containing the bootstrapped ab paths for each mediator.\n",
    "    - total_indirect_effects: list of bootstrapped summed ab paths.\n",
    "    - mediators: list of mediator names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for each mediator and the total indirect effect.\n",
    "    \"\"\"\n",
    "    ab_path_values = np.array(ab_paths)\n",
    "\n",
    "    # Check if there's only one mediator\n",
    "    if isinstance(mediators, str):\n",
    "        mediators = [mediators]\n",
    "\n",
    "    # Calculate mean indirect effect and confidence intervals for each mediator\n",
    "    mean_ab_paths = np.mean(ab_path_values, axis=0)\n",
    "    lower_bounds = np.percentile(ab_path_values, 2.5, axis=0)\n",
    "    upper_bounds = np.percentile(ab_path_values, 97.5, axis=0)\n",
    "\n",
    "    # Calculate p-values for each mediator\n",
    "    ab_path_p_values = [np.mean(np.sign(mean_ab_paths) * ab_path_values <= 0)]\n",
    "\n",
    "    # Create DataFrame to store the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Point Estimate': mean_ab_paths,\n",
    "        '2.5th Percentile': lower_bounds,\n",
    "        '97.5th Percentile': upper_bounds,\n",
    "        'P-value': ab_path_p_values\n",
    "    }, index=mediators)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def perform_mediated_moderation_analysis(dataframe, exposure, mediator, moderator, dependent_variable, bootstrap_samples=5000):\n",
    "    \"\"\"\n",
    "    Performs a mediated moderation analysis by estimating the joint indirect effects of an exposure variable\n",
    "    through a mediator on a dependent variable using bootstrapping, considering the moderating effect of another variable.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame containing the data.\n",
    "    - exposure: str, column name of the exposure variable.\n",
    "    - mediator: str, column name of the mediator variable.\n",
    "    - moderator: str, column name of the moderator variable.\n",
    "    - dependent_variable: str, column name of the dependent variable.\n",
    "    - bootstrap_samples: int, optional, number of bootstrap samples to be used (default is 5000).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for the indirect effect.\n",
    "\n",
    "    Example Usage:\n",
    "    result_df = perform_mediated_moderation_analysis(data_df, exposure='Age',\n",
    "                                                     mediator='Brain_Lobe',\n",
    "                                                     moderator='Stimulation',\n",
    "                                                     dependent_variable='Outcome')\n",
    "    \"\"\"\n",
    "\n",
    "    ab_paths = []\n",
    "\n",
    "    # Loop over each bootstrap sample\n",
    "    for i in range(bootstrap_samples):\n",
    "        # Resample the data with replacement\n",
    "        sample = dataframe.sample(frac=1, replace=True)\n",
    "\n",
    "        # Fit the models and calculate the indirect effect for this bootstrap sample\n",
    "        model_M = ols(f\"{mediator} ~ {moderator}\", data=sample).fit()\n",
    "        model_Y = ols(f\"{dependent_variable} ~ {exposure} + {mediator} + {moderator} + {exposure}:{mediator} + {exposure}:{moderator}\", data=sample).fit()\n",
    "\n",
    "        indirect_effect = model_M.params[moderator] * model_Y.params[f'{exposure}:{mediator}']\n",
    "        ab_paths.append(indirect_effect)\n",
    "    # Calculate confidence intervals and p-values\n",
    "    result_df = calculate_confidence_intervals(ab_paths, mediators=mediator)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def process_voxel(i, exposure_df, mediator_df, moderator_df, outcome_df, bootstrap_samples):\n",
    "    # This function will be applied to each voxel\n",
    "\n",
    "    # Compose the voxelwise data dictionary\n",
    "    temp_dict = {\n",
    "        'exposure': exposure_df.iloc[:, i] if exposure_df.shape[1] > 1 else exposure_df.iloc[:, 0],\n",
    "        'mediator': mediator_df.iloc[:, i] if mediator_df.shape[1] > 1 else mediator_df.iloc[:, 0],\n",
    "        'moderator': moderator_df.iloc[:, i] if moderator_df.shape[1] > 1 else moderator_df.iloc[:, 0],\n",
    "        'outcome': outcome_df['outcome']\n",
    "    }\n",
    "    \n",
    "    # Perform the mediated moderation analysis for the voxel\n",
    "    voxel_result = perform_mediated_moderation_analysis(dataframe = pd.DataFrame(temp_dict),\n",
    "                                                         exposure = 'exposure', \n",
    "                                                         mediator = 'mediator', \n",
    "                                                         moderator = 'moderator', \n",
    "                                                         dependent_variable ='outcome', \n",
    "                                                         bootstrap_samples=10)\n",
    "\n",
    "    return voxel_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator       -0.015589         -0.041651           0.005475      0.2\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator        0.006017         -0.012571           0.028055      0.4\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator       -0.006671         -0.064615           0.045726      0.4\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator        0.013123         -0.024497           0.055083      0.4\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator        0.004044         -0.012499           0.018868      0.1\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator        0.015002         -0.000784           0.042877      0.1\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator        0.010937          -0.01924           0.042054      0.3\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator        0.017839         -0.007352           0.039854      0.1\n",
      "          Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
      "mediator        0.002419          -0.02101            0.02496      0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    1.7s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    1.7s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed:    1.7s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    1.7s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:    1.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point Estimate</th>\n",
       "      <th>2.5th Percentile</th>\n",
       "      <th>97.5th Percentile</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015589</td>\n",
       "      <td>-0.041651</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006017</td>\n",
       "      <td>-0.012571</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006671</td>\n",
       "      <td>-0.064615</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013123</td>\n",
       "      <td>-0.024497</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004044</td>\n",
       "      <td>-0.012499</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015002</td>\n",
       "      <td>-0.000784</td>\n",
       "      <td>0.042877</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010937</td>\n",
       "      <td>-0.019240</td>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.017839</td>\n",
       "      <td>-0.007352</td>\n",
       "      <td>0.039854</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002419</td>\n",
       "      <td>-0.021010</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Point Estimate  2.5th Percentile  97.5th Percentile  P-value\n",
       "0       -0.015589         -0.041651           0.005475      0.2\n",
       "1        0.006017         -0.012571           0.028055      0.4\n",
       "2       -0.006671         -0.064615           0.045726      0.4\n",
       "3        0.013123         -0.024497           0.055083      0.4\n",
       "4        0.004044         -0.012499           0.018868      0.1\n",
       "5        0.015002         -0.000784           0.042877      0.1\n",
       "6        0.010937         -0.019240           0.042054      0.3\n",
       "7        0.017839         -0.007352           0.039854      0.1\n",
       "8        0.002419         -0.021010           0.024960      0.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def voxelwise_mediated_moderation_analysis(exposure_df, mediator_df, moderator_df, outcome_df, bootstrap_samples):\n",
    "    n_voxels = exposure_df.shape[1]\n",
    "\n",
    "    # Define the iterable inputs\n",
    "    iterable = range(n_voxels)\n",
    "\n",
    "    # Initialize a parallel joblib instance with verbose=10 to get progress updates\n",
    "    results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(process_voxel)(i, exposure_df, mediator_df, moderator_df, outcome_df, bootstrap_samples) for i in iterable\n",
    "    )\n",
    "\n",
    "    # Combine the results and return\n",
    "    combined_df = pd.concat([result.reset_index(drop=True) for result in results], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Run the voxel-wise analysis\n",
    "results_df = voxelwise_mediated_moderation_analysis(mediator_df=neuroimaging_df_2.iloc[:,1:10],\n",
    "                                                    moderator_df=clinical_df_1, \n",
    "                                                    exposure_df=neuroimaging_df_1.iloc[:,1:10], \n",
    "                                                    outcome_df=outcomes_df, \n",
    "                                                    bootstrap_samples=2)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "(91, 109, 91)\n",
      "(902629,)\n",
      "Image saved to: \n",
      " /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/response_topology/voxelwise_mediated_moderation/age_mediated_by_grey_matter\n",
      "Point Estimate\n",
      "(91, 109, 91)\n",
      "(902629,)\n",
      "Image saved to: \n",
      " /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/response_topology/voxelwise_mediated_moderation/age_mediated_by_grey_matter\n",
      "2.5th Percentile\n",
      "(91, 109, 91)\n",
      "(902629,)\n",
      "Image saved to: \n",
      " /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/response_topology/voxelwise_mediated_moderation/age_mediated_by_grey_matter\n",
      "97.5th Percentile\n",
      "(91, 109, 91)\n",
      "(902629,)\n",
      "Image saved to: \n",
      " /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/response_topology/voxelwise_mediated_moderation/age_mediated_by_grey_matter\n",
      "P-value\n",
      "(91, 109, 91)\n",
      "(902629,)\n",
      "Image saved to: \n",
      " /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/study_metadata/derivative_metadata/quantitative_atrophy/grey_matter_damage_score_and_outcomes/response_topology/voxelwise_mediated_moderation/age_mediated_by_grey_matter\n"
     ]
    }
   ],
   "source": [
    "# mask_path = None #'/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_gm_mask_resampled.nii'\n",
    "# masking_df = None\n",
    "\n",
    "results_df = pd.read_csv('/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/mediated_moderation/age_mediated_by_grey_matter/P-value_mediated_moderation_analysis_results.csv')\n",
    "\n",
    "mask_threshold=0\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "#Prepare Indices to Unmask\n",
    "from calvin_utils.matrix_utilities import unmask_matrix\n",
    "from nimlab import datasets as nimds\n",
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "from nilearn import image\n",
    "\n",
    "#Perform Unmasking\n",
    "if mask_path is not None:\n",
    "    mni_mask = image.load_img(mask_path).get_fdata().flatten()\n",
    "    brain_indices = np.where(mni_mask > mask_threshold)[0]\n",
    "elif masking_df is not None:\n",
    "    mni_mask = nimds.get_img(\"mni_icbm152\").get_fdata().flatten()\n",
    "    mask = masking_df.transpose().reset_index(drop=True).copy()\n",
    "    mask['mask_index'] = mask.sum(axis=1)\n",
    "    brain_indices = np.where(mask['mask_index'] != 0)[0]\n",
    "else:\n",
    "    mni_mask = nimds.get_img(\"mni_icbm152\").get_fdata().flatten()\n",
    "    brain_indices = np.where(mni_mask > 0)[0]\n",
    "\n",
    "# Create a boolean mask for brain_indices\n",
    "bool_mask = np.zeros_like(mni_mask, dtype=bool)\n",
    "bool_mask[brain_indices] = True\n",
    "\n",
    "for statistic in results_df.columns:\n",
    "    try:\n",
    "        print(statistic)\n",
    "        \n",
    "        # Initialize the output mask with NaN values\n",
    "        output_mask = np.full_like(mni_mask, np.nan)\n",
    "        \n",
    "        # Reinstate the values at brain_indices\n",
    "        output_mask[bool_mask] = results_df[statistic]\n",
    "        \n",
    "        # View and save\n",
    "        view_and_save_nifti(output_mask, out_dir=out_dir, output_name=statistic)\n",
    "    except:\n",
    "        print(f\"Couldn't convert {statistic} to nifti\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voxelwise Regression Using Multiple Neuroimaging Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def voxelwise_multiple_neuroimages_regression(outcome_df, neuroimaging_df, another_voxelwise_df, model_type='linear', include_interaction=False):\n",
    "    \"\"\"\n",
    "    Perform voxelwise regression with interactions between the corresponding voxels from \n",
    "    neuroimaging_df and another_voxelwise_df on a patient's outcome.\n",
    "    \n",
    "    Parameters:\n",
    "        outcome_df (pd.DataFrame): DataFrame containing the outcome variable in 'outcome' column with patients in rows and 'subject_id' as index. \n",
    "        neuroimaging_df (pd.DataFrame): DataFrame containing voxelwise neuroimaging data with patients in rows and 'subject_id' as index.\n",
    "        another_voxelwise_df (pd.DataFrame): DataFrame containing another set of voxelwise data with patients in rows and 'subject_id' as index.\n",
    "        model_type (str): Specifies the type of regression model to use ('linear' or 'logistic').\n",
    "        include_interaction (bool): If True, includes the interaction between the voxels in the regression model.\n",
    "    \n",
    "    Returns:\n",
    "        results_df (pd.DataFrame): DataFrame containing p-values, coefficient values, t-values, \n",
    "                                   F-statistics, p-values of the F-statistic, and R-squared values for each voxel.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure that the number of voxels is the same in both neuroimaging_df and another_voxelwise_df\n",
    "    assert neuroimaging_df.shape[1] == another_voxelwise_df.shape[1], \"Mismatch in number of voxels\"\n",
    "    \n",
    "    # Number of voxels\n",
    "    n_voxels = neuroimaging_df.shape[1]\n",
    "\n",
    "    # Initialize a list to store the results for each voxel\n",
    "    results = []\n",
    "\n",
    "    # Loop through each voxel and perform regression\n",
    "    for i in tqdm(range(0, n_voxels)):\n",
    "        # Create temporary dataframe with outcome and corresponding voxel from both dataframes\n",
    "        temp_df = outcome_df[['outcome']].merge(\n",
    "            neuroimaging_df[[neuroimaging_df.columns[i]]], left_index=True, right_index=True).merge(\n",
    "            another_voxelwise_df[[another_voxelwise_df.columns[i]]], left_index=True, right_index=True)\n",
    "        \n",
    "        # Rename the columns\n",
    "        temp_df.columns = ['outcome', 'dataframe_1_voxel_i', 'dataframe_2_voxel_i']\n",
    "        \n",
    "        # Include interaction term if specified\n",
    "        if include_interaction:\n",
    "            temp_df['voxel_i_interaction'] = temp_df['dataframe_1_voxel_i'] * temp_df['dataframe_2_voxel_i']\n",
    "\n",
    "        # Construct the regression formula based on the model type and inclusion of interaction term\n",
    "        formula = 'outcome ~ dataframe_1_voxel_i + dataframe_2_voxel_i'\n",
    "        if include_interaction:\n",
    "            formula += ' + voxel_i_interaction'\n",
    "                \n",
    "        # Fit the model\n",
    "        if model_type == 'linear':\n",
    "            model = smf.ols(formula, data=temp_df).fit()\n",
    "        elif model_type == 'logistic':\n",
    "            model = smf.logit(formula, data=temp_df).fit(disp=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "        # Store the results for the current voxel\n",
    "        voxel_results = {\n",
    "            'voxel_index': i,\n",
    "            'p_values': model.pvalues.tolist(),\n",
    "            'coeff_values': model.params.tolist(),\n",
    "            't_values': model.tvalues.tolist(),\n",
    "            'f_statistic': model.fvalue,\n",
    "            'f_p_value': model.f_pvalue\n",
    "        }\n",
    "        \n",
    "        # Store R-squared value for linear regression\n",
    "        if model_type == 'linear':\n",
    "            voxel_results['r_squared'] = model.rsquared\n",
    "\n",
    "        # Append the voxel_results dictionary to the results list\n",
    "        results.append(voxel_results)\n",
    "\n",
    "    # Convert the results list to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = voxelwise_multiple_neuroimages_regression(outcomes_df, \n",
    "                                                       neuroimaging_df_1, \n",
    "                                                       neuroimaging_df_2, \n",
    "                                                       model_type='linear', \n",
    "                                                       include_interaction=True)\n",
    "results_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unmask Dataframes\n",
    "from calvin_utils.matrix_utilities import unmask_matrix\n",
    "from nimlab import datasets as nimds\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "\n",
    "mask_data[brain_indices] = results_df['f_statistic']\n",
    "    \n",
    "# results_df = unmask_matrix(results_df, unmask_by='column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "view_and_save_nifti(mask_data, out_dir=out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voxelwise F-statistic Comparison of Model with Interaction Versus Without Interactions\n",
    "- this is for interaction of an arbritary number of neuroimaging datasets and clinical data.\n",
    "- Note - the F-statistic is not a pivotal statistic under heteroscedastic conditions, thus it is not ideal for permutation analysis unless the groups sizes are equivalent. \n",
    "    -  Given this analysis performs comparison of reduced versus full models between a single group, the f-statistic is acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.api import anova_lm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from scipy.stats import chi2, t, f\n",
    "\n",
    "\n",
    "def calculate_g_statistic(full_model, reduced_model):\n",
    "    #### WORK IN PROGRESS #####\n",
    "    \"\"\"\n",
    "    Calculates the G-statistic for a given model.\n",
    "    Please note, a G-statistic is comparable to various other statistics under various conditions, \n",
    "    but it is not meant to derive p-values analytically. It is meant to derive p-values using permutation testing. \n",
    "\n",
    "    Parameters:\n",
    "        full_model: A fitted model object from the full model.\n",
    "        reduced_model: A fitted model object from the reduced model.\n",
    "        heteroscedastic: Boolean. If True, the errors are assumed to be heteroscedastic, \n",
    "                         and a chi-square distribution is used to calculate the p-value. \n",
    "                         If False, the errors are assumed to be homoscedastic and a Student's \n",
    "                         t-distribution is used to calculate the p-value.\n",
    "\n",
    "    Returns:\n",
    "        G_statistic: The calculated G-statistic.\n",
    "        p_value: The p-value associated with the G-statistic.\n",
    "    \"\"\"\n",
    "    # ψ^: The estimated parameters from the full model, minus those from the reduced model\n",
    "    psi_hat = full_model.params - reduced_model.params\n",
    "    # C: The contrast matrix. This depends on your specific hypotheses and model.\n",
    "    # Assuming that full_model and reduced_model are statsmodels regression result objects\n",
    "    # Get the parameter names from both models\n",
    "    full_model_params = full_model.params.index\n",
    "    reduced_model_params = reduced_model.params.index\n",
    "\n",
    "    # Initialize the contrast matrix as a zero matrix with the length of the full model params\n",
    "    C = np.zeros(len(full_model_params))\n",
    "\n",
    "    # For each parameter in the full model, if it is not in the reduced model, set the corresponding\n",
    "    # element in the contrast matrix to 1\n",
    "    for i, param in enumerate(full_model_params):\n",
    "        if param not in reduced_model_params:\n",
    "            C[i] = 1\n",
    "\n",
    "    # Ensure that C remains a 2D array (i.e., a matrix), which is expected for matrix operations\n",
    "    C = C.reshape(-1, len(C))\n",
    "\n",
    "    # M: The design matrix from the full model\n",
    "    M = full_model.model.exog\n",
    "\n",
    "    # W: Diagonal weighting matrix.\n",
    "    # Compute the residuals from your full model\n",
    "    residuals = full_model.resid.to_numpy()\n",
    "\n",
    "    # Compute the variance of residuals\n",
    "    variances = np.reshape(np.var(residuals), -1)\n",
    "\n",
    "    # Assume gn contains the variance group assignments for each observation\n",
    "    # Assume R is the residual forming matrix\n",
    "    # Assume epsilon_hat contains the vector of residuals\n",
    "\n",
    "    # Initialize W as a zero matrix with the same shape as R\n",
    "    W = np.zeros_like(residuals)\n",
    "\n",
    "    # Iterate over each observation\n",
    "    for n in range(len(gn)):\n",
    "        # Get the variance group assignment for the n-th observation\n",
    "        variance_group = gn[n]\n",
    "\n",
    "        # Find the indices of observations belonging to the same variance group\n",
    "        group_indices = np.where(gn == variance_group)[0]\n",
    "\n",
    "        # Compute the sum of diagonal elements of R for the variance group\n",
    "        sum_R = np.sum(R[group_indices, group_indices])\n",
    "\n",
    "        # Compute the product of epsilon_hat for the variance group\n",
    "        product_epsilon_hat = np.prod(epsilon_hat[group_indices])\n",
    "\n",
    "        # Compute the diagonal element of W for the n-th observation\n",
    "        W_nn = sum_R / product_epsilon_hat\n",
    "\n",
    "        # Set the diagonal element of W for the n-th observation\n",
    "        W[n, n] = W_nn\n",
    "\n",
    "\n",
    "    # Calculate Λ and the inverse of it.\n",
    "    Lambda_inv = np.linalg.inv(C @ M.T @ W @ M @ C.T)\n",
    "\n",
    "    # Calculate the G-statistic\n",
    "    G_statistic = psi_hat.T @ C.T @ Lambda_inv @ C @ psi_hat\n",
    "\n",
    "    # Degrees of freedom is the rank of C\n",
    "    df = np.linalg.matrix_rank(C)\n",
    "\n",
    "    # Compute 1-tailed p-value to assess if full model is significant better than reduced model\n",
    "    # Assess heteroscedasticity with the Breusch-Pagan test, p-value <0.05 indicates the linear model is heteroscedastic\n",
    "    _, p_value, _, _ = het_breuschpagan(residuals, full_model.model.exog)\n",
    "    print('6')\n",
    "    if p_value < 0.05:\n",
    "        if df == 1:\n",
    "            p_value = np.NaN\n",
    "            #This is equivalent to Welch's v^2, which does not have an analytical distribution\n",
    "        else:\n",
    "            p_value = np.NaN\n",
    "            #This is equivalent to Aspen-Welch v, which does not have an analytical distribution\n",
    "        print('7')\n",
    "    else:\n",
    "        print('8')\n",
    "        if df == 1:\n",
    "            print('9')\n",
    "            p_value = 2 * (1 - t.cdf(np.sqrt(G_statistic), df))\n",
    "            #This is equivalent to student's T, which does have an analytical distribution\n",
    "        else:\n",
    "            print('10')\n",
    "            p_value = 1 - f.cdf(G_statistic, df, full_model.df_resid - df)\n",
    "            #This is equivalent to F-ratio, which does have an analytical distribution\n",
    "\n",
    "    return G_statistic, p_value\n",
    "\n",
    "\n",
    "\n",
    "def handle_nan_p_values(p_value_series):\n",
    "    \"\"\"\n",
    "    Function to handle NANs in p-values by backward filling.\n",
    "    \n",
    "    Parameters:\n",
    "        p_value_series (pd.Series): Series containing the p-values.\n",
    "    \n",
    "    Returns:\n",
    "        p_value_series (pd.Series): Series with NANs handled.\n",
    "    \"\"\"\n",
    "    \n",
    "    if p_value_series.isna().any():\n",
    "        p_value_series.fillna(method='bfill', inplace=True)\n",
    "        print('WARNING: p-values containing NAN values')\n",
    "        if p_value_series.isna().any():\n",
    "            p_value_series.fillna(1.0, inplace=True)\n",
    "    \n",
    "    return p_value_series\n",
    "\n",
    "\n",
    "def fdr_correct_p_values_and_threshold_r_squared(results_df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs FDR correction on the p-values in the results DataFrame and thresholds R-squared values based on the corrected p-values.\n",
    "    \n",
    "    Parameters:\n",
    "        results_df (pd.DataFrame): DataFrame containing the p-values and R-squared values.\n",
    "        alpha (float): Significance level for FDR correction.\n",
    "        \n",
    "    Returns:\n",
    "        results_df (pd.DataFrame): DataFrame with FDR corrected p-values and thresholded R-squared values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Correct for multiple comparisons using FDR\n",
    "    p_values = results_df['one_way_p_value'].values\n",
    "    _, pvals_fdr, _, _ = multipletests(p_values, alpha=alpha, method='fdr_bh')\n",
    "    \n",
    "    # Add FDR corrected p-values to the DataFrame\n",
    "    results_df['fdr_corrected_p_value'] = pvals_fdr\n",
    "    \n",
    "    # Threshold R-squared values based on FDR corrected p-values\n",
    "    try:\n",
    "        results_df['adj_r_squared_thresholded'] = results_df['adj_r_squared']\n",
    "        results_df.loc[results_df['fdr_corrected_p_value'] > alpha, 'adj_r_squared_thresholded'] = 0.0\n",
    "    except:\n",
    "        print(' results_df[\"adj_r_squared_thresholded\"]  not found')\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def voxelwise_interaction_f_stat(outcome_df, predictor_neuroimaging_dfs, predictor_clinical_dfs, model_type='linear', manual_f_stat=False, manual_g_stat=True):\n",
    "    \"\"\"\n",
    "    Perform voxelwise regression with interactions between the corresponding voxels from\n",
    "    neuroimaging dataframes and clinical dataframes on a patient's outcome and use F-test to compare models with and without interactions.\n",
    "    The F-test is the proportion of mean squared errors. When comparing two different models, F-statistic is the proprtion of the change in\n",
    "    the mean squared error between the two models compared to the full model. \n",
    "    However, this means that if the second model is much worse than the first model (Larger MSE), the F-statistic can be negative. Thus, \n",
    "    negative F-statistic is considered to be equivalent to and F-statistic of zero. \n",
    "    \n",
    "    degrees_of_freedom is equivalent to sample size. \n",
    "    F-statistic = ((sum_squared_residuals_1 - sum_squared_residuals_2)/(df_residuals_1 - df_residuals_2)) / (sum_squared_residuals_2/(df_residuals_2)\n",
    "    MSE = sum_squared_residuals/degrees_of_freedom \n",
    "    F-statistic = delta_MSE/full_model_MSE\n",
    "    \n",
    "    Parameters:\n",
    "        outcome_df (pd.DataFrame): DataFrame containing the outcome variable in 'outcome' column with patients in rows and 'subject_id' as index.\n",
    "        predictor_neuroimaging_dfs (list of pd.DataFrame): List of DataFrames containing voxelwise neuroimaging data with patients in rows and 'subject_id' as index.\n",
    "        predictor_clinical_dfs (list of pd.DataFrame): List of DataFrames containing clinical data with patients in rows and 'subject_id' as index.\n",
    "        model_type (str): Specifies the type of regression model to use ('linear' or 'logistic').\n",
    "        manual_f_stat (bool): If True, use the manual calculation for F-statistic and p-value. Otherwise, use anova_lm function.\n",
    "    \n",
    "    Returns:\n",
    "        results_df (pd.DataFrame): DataFrame containing F-statistics and p-values for each voxel.\n",
    "        \n",
    "    Cite: \n",
    "    chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://sites.duke.edu/bossbackup/files/2013/02/FTestTutorial.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of voxels in the first neuroimaging dataframe\n",
    "    n_voxels = predictor_neuroimaging_dfs[0].shape[1]\n",
    "\n",
    "    # Initialize a list to store the results for each voxel\n",
    "    results = []\n",
    "\n",
    "    # Define lambda functions for standardization\n",
    "    standardize_within_patient = lambda df: df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)\n",
    "    standardize_across_patients = lambda df: df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    # Standardize outcome data across patients\n",
    "    outcome_df = standardize_across_patients(outcome_df)\n",
    "    if predictor_neuroimaging_dfs[0] is not None:\n",
    "        # Standardize neuroimaging data within each patient\n",
    "        predictor_neuroimaging_dfs = [standardize_within_patient(df) for df in predictor_neuroimaging_dfs]\n",
    "    if predictor_clinical_dfs[0] is not None:\n",
    "        # Standardize clinical data across patients\n",
    "        predictor_clinical_dfs = [standardize_across_patients(df) for df in predictor_clinical_dfs]\n",
    "\n",
    "    # Loop through each voxel and perform regression\n",
    "    for i in tqdm(range(0, n_voxels)):\n",
    "        # Create temporary dataframe with outcome and corresponding voxel from all neuroimaging dataframes and clinical data\n",
    "        temp_df = outcome_df[['outcome']].copy()\n",
    "        variable_names = []\n",
    "        \n",
    "        if predictor_neuroimaging_dfs[0] is not None:\n",
    "            for j, neuroimaging_df in enumerate(predictor_neuroimaging_dfs):\n",
    "                temp_df[f'dataframe_{j}_voxel_i'] = neuroimaging_df.iloc[:, i]\n",
    "                variable_names.append(f'dataframe_{j}_voxel_i')\n",
    "        \n",
    "        if predictor_clinical_dfs[0] is not None:\n",
    "            for j, clinical_df in enumerate(predictor_clinical_dfs):\n",
    "                temp_df = temp_df.merge(clinical_df, left_index=True, right_index=True)\n",
    "                variable_names.extend(clinical_df.columns.tolist())\n",
    "            \n",
    "        # Construct the regression formulas dynamically\n",
    "        variables_combined = \" + \".join(variable_names)\n",
    "        interaction_terms = \" + \".join([f\"{var1}:{var2}\" for idx, var1 in enumerate(variable_names) for var2 in variable_names[idx+1:]])\n",
    "        \n",
    "        formula_no_interaction = f'outcome ~ {variables_combined}'\n",
    "        formula_interaction = f'outcome ~ {variables_combined} + {interaction_terms}'\n",
    "                \n",
    "        # Fit the models\n",
    "        if model_type == 'linear':\n",
    "            model_no_interaction = smf.ols(formula_no_interaction, data=temp_df).fit()\n",
    "            model_interaction = smf.ols(formula_interaction, data=temp_df).fit()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "        if manual_f_stat:\n",
    "            # Calculate the F-statistic manually\n",
    "            sum_square_1 = model_no_interaction.ssr\n",
    "            sum_square_2 = model_interaction.ssr\n",
    "            degrees_freedom_1 = model_no_interaction.df_resid\n",
    "            degrees_freedom_2 = model_interaction.df_resid\n",
    "\n",
    "            F_statistic = ((sum_square_1 - sum_square_2) / (degrees_freedom_1 - degrees_freedom_2)) / (sum_square_2 / degrees_freedom_2)\n",
    "            if F_statistic < 0:\n",
    "                F_statistic = 0 \n",
    "            # Calculate the p-value using the cumulative distribution function of the F-distribution\n",
    "            if np.isinf(F_statistic):\n",
    "                print(\"Warning: Infinite F-statistic detected. Setting p-value to zero.\")\n",
    "                P_value = 0\n",
    "            else:\n",
    "                P_value = 1 - f.cdf(F_statistic, degrees_freedom_1 - degrees_freedom_2, degrees_freedom_2)\n",
    "            statistic = 'manual_f_statistic'\n",
    "        elif manual_g_stat:\n",
    "            # This assesses heteroscedasticity at every voxel and decides what distribution the G-statistic should use\n",
    "            calculate_g_statistic(model_interaction, model_no_interaction)\n",
    "            statistic = 'manual_g_statistic'\n",
    "        else:\n",
    "            # Calculate the F-statistic and p-value using anova_lm function\n",
    "            table = anova_lm(model_no_interaction, model_interaction)\n",
    "            F_statistic = table['F'][1]\n",
    "            if np.isinf(F_statistic):\n",
    "                print(\"Warning: Infinite F-statistic detected. Setting p-value to zero.\")\n",
    "                P_value = 0.0\n",
    "            else:\n",
    "                P_value = table['Pr(>F)'][1]\n",
    "            statistic = 'statsmodels_f_statistic'\n",
    "        # Store the results for the current voxel\n",
    "        # voxel_results = {\n",
    "        #     'statistic_value': F_statistic,\n",
    "        # }\n",
    "        voxel_results = {\n",
    "            'voxel_index': i,\n",
    "            'statistic_value': F_statistic,\n",
    "            'statistic_type': statistic,\n",
    "            'one_way_p_value': P_value,\n",
    "            'unc_r_squared': model_interaction.rsquared,\n",
    "            'adj_r_squared': model_interaction.rsquared_adj\n",
    "        }\n",
    "        # Append the voxel_results dictionary to the results list\n",
    "        results.append(voxel_results)\n",
    "\n",
    "    # Convert the results list to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print('\\n Example formula without interaction: ', formula_no_interaction)\n",
    "    print('Example formula with interaction: ', formula_interaction)\n",
    "    return results_df, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = outcomes_df\n",
    "neuroimaging_dfs = [neuroimaging_df_1]  # List of neuroimaging DataFrames\n",
    "clinical_dfs = [clinical_df_1]  # List of clinical DataFrames\n",
    "# Note that this will only perform up to 2 way interactions. \n",
    "#----------------------------------------------------------------DO NOT MODIFY!----------------------------------------------------------------\n",
    "# Function calls\n",
    "# Perform voxelwise regression and F-test\n",
    "results_df, temp_df = voxelwise_interaction_f_stat(outcome_df, \n",
    "                                                   neuroimaging_dfs, \n",
    "                                                   clinical_dfs,\n",
    "                                                   manual_f_stat=False, \n",
    "                                                   manual_g_stat=False)\n",
    "\n",
    "# Handle NaN in p-values\n",
    "results_df['one_way_p_value'] = handle_nan_p_values(results_df['one_way_p_value'])\n",
    "\n",
    "# FDR correction and thresholding R-squared values\n",
    "results_df = fdr_correct_p_values_and_threshold_r_squared(\n",
    "    results_df=results_df,\n",
    ")\n",
    "\n",
    "# Output the results DataFrame\n",
    "results_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['statistic_value'].to_csv(os.path.join(out_dir, 'observed_f_stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max statistic: ', results_df['statistic_value'].max())\n",
    "print('Min uncorrected p-value: ', results_df['one_way_p_value'].min())\n",
    "print('Min corrected p-value: ', results_df['fdr_corrected_p_value'].min())\n",
    "print('Max uncorrected r-squared: ', results_df['unc_r_squared'].max())\n",
    "print('Max adjusted r-squared: ', results_df['adj_r_squared'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Resulting Data as niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_path = None #'/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_gm_mask_resampled.nii'\n",
    "# masking_df = None\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "#Prepare Indices to Unmask\n",
    "from calvin_utils.matrix_utilities import unmask_matrix\n",
    "from nimlab import datasets as nimds\n",
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "from nilearn import image\n",
    "\n",
    "# unmask_matrix\n",
    "# from calvin_utils.matrix_utilities import unmask_matrix\n",
    "# results_df = unmask_matrix(masking_df, \n",
    "#                            mask_path=None, \n",
    "#                            mask_threshold=0.2, \n",
    "#                            unmask_by='columns', \n",
    "#                            dataframe_to_unmask_by=masking_df)\n",
    "# results_df\n",
    "\n",
    "#Perform Unmasking\n",
    "if mask_path is not None:\n",
    "    mni_mask = image.load_img(mask_path).get_fdata().flatten()\n",
    "    brain_indices = np.where(mni_mask > 0.2)[0]\n",
    "elif masking_df is not None:\n",
    "    mni_mask = nimds.get_img(\"mni_icbm152\").get_fdata().flatten()\n",
    "    mask = masking_df.transpose().reset_index(drop=True).copy()\n",
    "    mask['mask_index'] = mask.sum(axis=1)\n",
    "    brain_indices = np.where(mask['mask_index'] != 0)[0]\n",
    "else:\n",
    "    mni_mask = nimds.get_img(\"mni_icbm152\").get_fdata().flatten()\n",
    "    brain_indices = np.where(mni_mask > 0)[0]\n",
    "\n",
    "# Create a boolean mask for brain_indices\n",
    "bool_mask = np.zeros_like(mni_mask, dtype=bool)\n",
    "bool_mask[brain_indices] = True\n",
    "\n",
    "for statistic in results_df.columns:\n",
    "    try:\n",
    "        print(statistic)\n",
    "        \n",
    "        # Initialize the output mask with NaN values\n",
    "        output_mask = np.full_like(mni_mask, np.nan)\n",
    "        \n",
    "        # Reinstate the values at brain_indices\n",
    "        output_mask[bool_mask] = results_df[statistic]\n",
    "        \n",
    "        # View and save\n",
    "        view_and_save_nifti(output_mask, out_dir=out_dir, output_name=statistic)\n",
    "    except:\n",
    "        print(f\"Couldn't convert {statistic} to nifti\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voxelwise Regression Using 1 Neuroimaging File and 1 Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "def voxelwise_regression(data_df, outcome_col, clinical_vars, voxel_start_index, model_type='linear', interaction_effects=None):\n",
    "    # Replace column names with their index\n",
    "    data_df.columns = list(range(len(data_df.columns)))\n",
    "    \n",
    "    n_voxels = len(data_df.columns[voxel_start_index:])\n",
    "    print(n_voxels)\n",
    "    \n",
    "    p_values = [[] for _ in range(n_voxels)]\n",
    "    coeff_values = [[] for _ in range(n_voxels)]\n",
    "    t_values = [[] for _ in range(n_voxels)]\n",
    "\n",
    "    indep_vars_str = \" + \".join(f\"var{x}\" for x in clinical_vars)\n",
    "\n",
    "    if interaction_effects:\n",
    "        interaction_terms_str = \" + \".join([f\"var{data_df.columns[a]}_interact_connectivity\" for a in interaction_effects])\n",
    "        indep_vars_str = f\"{indep_vars_str} + connectivity + {interaction_terms_str}\"\n",
    "\n",
    "    if model_type == 'linear':\n",
    "        formula = f'outcome ~ {indep_vars_str}'\n",
    "        print(\"Regression formula (linear):\", formula)\n",
    "    elif model_type == 'logistic':\n",
    "        formula = f'outcome ~ {indep_vars_str}'\n",
    "        print(\"Regression formula (logistic):\", formula)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "    for i in tqdm(range(0, n_voxels)):\n",
    "        temp_df = data_df.iloc[:, [outcome_col] + clinical_vars + [voxel_start_index + i]]\n",
    "        temp_df.columns = ['outcome'] + [f\"var{x}\" for x in clinical_vars] + ['connectivity']\n",
    "\n",
    "        # Add interaction columns to the temp_df\n",
    "        if interaction_effects:\n",
    "            for idx in interaction_effects:\n",
    "                interaction_col_name = f'var{data_df.columns[idx]}_interact_connectivity'\n",
    "                temp_df[interaction_col_name] = temp_df[f\"var{data_df.columns[idx]}\"] * temp_df['connectivity']\n",
    "\n",
    "        if model_type == 'linear':\n",
    "            model = smf.ols(formula, data=temp_df).fit()\n",
    "        elif model_type == 'logistic':\n",
    "            temp_df['outcome'] = (temp_df['outcome'] > 0.5).astype(int)\n",
    "            model = smf.logit(formula, data=temp_df).fit(disp=0)\n",
    "        elif model_type == 'ridge':\n",
    "            ridge = Ridge(alpha=1.0)\n",
    "            X = sm.add_constant(temp_df.drop(columns='outcome'))\n",
    "            y = temp_df['outcome']\n",
    "            ridge.fit(X, y)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "        if model_type =='ridge':\n",
    "            # Perform p and t value extraction for the ridge regressions\n",
    "            n = len(temp_df)\n",
    "            k = len(temp_df.columns)\n",
    "            dof = n - k\n",
    "            y_pred = ridge.predict(X)\n",
    "            residuals = y - y_pred\n",
    "            mse = np.sum(residuals**2) / dof\n",
    "            se = np.sqrt(np.diagonal(mse * np.linalg.inv(np.dot(X.T, X))))\n",
    "            t_values_ridge = ridge.coef_ / se\n",
    "            p_values_ridge = [2 * (1 - stats.t.cdf(abs(t_value), dof)) for t_value in t_values_ridge]\n",
    "\n",
    "            for j, (p_value, coef, t_value) in enumerate(zip(p_values_ridge, ridge.coef_, t_values_ridge)):\n",
    "                p_values[i].append(p_value)\n",
    "                coeff_values[i].append(coef)\n",
    "                t_values[i].append(t_value)\n",
    "        else:\n",
    "            for j, (p_value, coef, t_value) in enumerate(zip(model.pvalues, model.params, model.tvalues)):\n",
    "                p_values[i].append(p_value)\n",
    "                coeff_values[i].append(coef)\n",
    "                t_values[i].append(t_value)\n",
    "\n",
    "    columns = ['Intercept'] + [f\"var{x}\" for x in clinical_vars] + ['connectivity'] + [f'var{var}_interact_connectivity' for var in interaction_effects]\n",
    "    p_values_df = pd.DataFrame(p_values, columns=columns)\n",
    "    coeff_values_df = pd.DataFrame(coeff_values, columns=columns)\n",
    "    t_values_df = pd.DataFrame(t_values, columns=columns)\n",
    "\n",
    "    return p_values_df, coeff_values_df, t_values_df, model\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from nilearn.glm import fdr_threshold\n",
    "from calvin_utils.z_score_matrix import z_score_matrix\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check input for NANs and Constant values\n",
    "regression_df.isnull().values.any()\n",
    "test_df = regression_df.loc[:, regression_df.apply(pd.Series.nunique) != 1]\n",
    "if test_df.shape != regression_df.shape:\n",
    "    print('Note, there are constant columns in the regression dataframe. This may cause unstable regression results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrix input should be oriented such that voxels and other clinical information are in columns, with patients in rows\n",
    "p_values_df, coeff_values_df, t_values_df, model = voxelwise_regression(data_df=regression_df, outcome_col=0, clinical_vars=[1], voxel_start_index=2, model_type='linear', interaction_effects=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of p_values_df:\", p_values_df.shape)\n",
    "print(\"Shape of coeff_values_df:\", coeff_values_df.shape)\n",
    "print(\"Shape of t_values_df:\", t_values_df.shape)\n",
    "print(\"Shape of regression_df:\", regression_df.shape)\n",
    "print(model.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn.glm import fdr_threshold\n",
    "from calvin_utils.z_score_matrix import z_score_matrix\n",
    "from scipy.stats import zscore\n",
    "from statsmodels.stats import multitest\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "\n",
    "def insert_outcomes_to_matrix(p_values_df, coeff_values_df, t_values_df, brain_indices, mask_data, view_and_save_nifti, out_dir, adjustment_method='nilearn', strict=False):\n",
    "    '''\n",
    "    This function takes the outcomes of the voxelwise regression and generates NIfTI images from them.\n",
    "    It also calculates FDR-adjusted p-values and masks the coefficients based on the adjusted p-values.\n",
    "    \n",
    "    Parameters:\n",
    "    p_values_df (pd.DataFrame): DataFrame containing p-values.\n",
    "    coeff_values_df (pd.DataFrame): DataFrame containing coefficients.\n",
    "    t_values_df (pd.DataFrame): DataFrame containing t-values.\n",
    "    brain_indices (array): Indices of the brain voxels.\n",
    "    mask_data (array): Mask data for the brain.\n",
    "    view_and_save_nifti (function): Function to view and save NIfTI images.\n",
    "    out_dir (str): Output directory for saving the NIfTI images.\n",
    "    adjustment_method (str, optional): Method to use for FDR adjustment. Defaults to 'nilearn'.\n",
    "                                      Accepted values are 'nilearn' and 'statsmodels'.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If adjustment_method is not 'nilearn' or 'statsmodels'.\n",
    "    '''\n",
    "    \n",
    "    # Convert DataFrames to NumPy arrays\n",
    "    p_values = p_values_df.to_numpy()\n",
    "    coeff_values = coeff_values_df.to_numpy()\n",
    "    t_values = t_values_df.to_numpy()\n",
    "\n",
    "    # Iterate over statistical values\n",
    "    for stat_name, stat_values in zip([\"p_values\", \"coeff_values\", \"t_values\"], [p_values, coeff_values, t_values]):\n",
    "        for col_idx, col_name in enumerate(p_values_df.columns):\n",
    "            matrix = mask_data.copy()\n",
    "            matrix[brain_indices] = stat_values[:, col_idx]\n",
    "\n",
    "            # Generate NIfTI image for the current statistical value and term\n",
    "            out_file = f\"{out_dir}/{col_name}/{stat_name}.nii\"\n",
    "            view_and_save_nifti(matrix=matrix, out_dir=out_file)\n",
    "\n",
    "            if stat_name == 't_values':\n",
    "                if adjustment_method == 'nilearn':\n",
    "                    # Calculate FDR-adjusted p-values based on t-values\n",
    "                    z_scored_t_values = zscore(np.nan_to_num(t_values[:, col_idx]))\n",
    "                    z_scored_t_values = np.nan_to_num(z_scored_t_values, nan=0, posinf=0, neginf=0)\n",
    "                    print(np.max(z_scored_t_values), np.min(z_scored_t_values))\n",
    "                    threshold = fdr_threshold(z_scored_t_values, 0.05)\n",
    "                    print('FDR Threshold at : ', threshold)\n",
    "                    \n",
    "                    # Mask the coefficients based on FDR-adjusted z_scored_t_values\n",
    "                    fdr_masked_coeff = np.where(z_scored_t_values < threshold, coeff_values[:, col_idx], 0)\n",
    "                                        \n",
    "                elif adjustment_method == 'statsmodels':\n",
    "                    # Calculate FDR-adjusted p-values using statsmodels\n",
    "                    if strict:\n",
    "                        method = 'poscor'\n",
    "                    else:\n",
    "                        method = 'indep'\n",
    "                    _, fdr_adj_p_values = fdrcorrection(p_values[:, col_idx], method='indep')\n",
    "                    print('unadjusted p-values min and max at : ', np.min(p_values[:, col_idx]), np.max(p_values[:, col_idx]))\n",
    "                \n",
    "                    print('FDR adjusted p-values min and max at : ', np.min(fdr_adj_p_values), np.max(fdr_adj_p_values))\n",
    "                    # Mask the coefficients based on FDR-adjusted p-values\n",
    "                    fdr_masked_coeff = np.where(fdr_adj_p_values < 0.05, coeff_values[:, col_idx], 0)\n",
    "                \n",
    "                else:\n",
    "                    raise ValueError(f\"adjustment_method model_type: {adjustment_method}, nilearn or 'statsmodels only currently supported\")\n",
    "                \n",
    "                # Generate NIfTI image for FDR-masked coefficients\n",
    "                matrix = mask_data.copy()\n",
    "                matrix[brain_indices] = fdr_masked_coeff\n",
    "                out_file = f\"{out_dir}/{col_name}/fdr_masked_coeff_{stat_name}.nii\"\n",
    "                view_and_save_nifti(matrix=matrix, out_dir=out_file)\n",
    "                \n",
    "                # Generate NIfTI image for FDR-madjusted p-values\n",
    "                new_matrix = mask_data.copy()\n",
    "                new_matrix[brain_indices] = fdr_adj_p_values\n",
    "                out_file = f\"{out_dir}/{col_name}/fdr_adjusted_p_values.nii\"\n",
    "                view_and_save_nifti(matrix=new_matrix, out_dir=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming p_values_df, coeff_values_df, and t_values_df are obtained from voxelwise_regression function\n",
    "# Assuming brain_indices and mask_data are predefined\n",
    "# Assuming view_and_save_nifti function is predefined\n",
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "out_dir = out_dir\n",
    "\n",
    "#only operate within the brain mask\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "\n",
    "insert_outcomes_to_matrix(p_values_df, coeff_values_df, t_values_df, brain_indices, mask_data, view_and_save_nifti, out_dir, adjustment_method='statsmodels', strict=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Coefficient by PALM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeff_values_df.iloc[:, -1] = np.where(palm_p_values.iloc[:, -1] < 0.05, coeff_values_df.iloc[:, -1], 0)\n",
    "mask_data[brain_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palm_p_values = pd.read_csv('/Users/cu135/Dropbox (Partners HealthCare)/memory/final_analyses/interaction_analysis/whole_brain_analysis/permutation_results/10185_summed_coefficient_pp_values (2).csv')\n",
    "# coeff_values_df.iloc[:, -1] = np.where(palm_p_values.iloc[:, -1] < 0.05, coeff_values_df.iloc[:, -1], 0)\n",
    "mask_data[brain_indices] = coeff_values_df.iloc[:, -1]\n",
    "#Generate a nifti for coefficients thresholded to uncorrected p-values\n",
    "view_and_save_nifti(mask_data, (out_dir+'/coefficient_thresholded_to_palm_p_values'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Permutation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is generally best done with submission to a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.multiprocessing import permute_brain\n",
    "#Permute the data, returning a matrix organized such that shape = [voxels, patient, permutation]\n",
    "#Convert dataframe to numpy for time savings\n",
    "#Is actually receiving the float values, not the indices. \n",
    "permuted_array = permute_brain(prepped_matrix.to_numpy(), n_permutations=1)\n",
    "\n",
    "#---Visualize a given permutation\n",
    "# retrive brain mask\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "\n",
    "#Retrieve patient data\n",
    "test_matrix = prepped_matrix.iloc[:,0].to_numpy()\n",
    "\n",
    "#reindex patient data by permutation\n",
    "permutation = permuted_array[:,0,0]\n",
    "test_matrix[brain_indices] = permutation\n",
    "view_and_save_nifti(test_matrix, (out_dir+'/verification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def calculate_empirical_p(observed_t_value, sim_t_values):\n",
    "    \"\"\"\n",
    "    Calculate empirical p-value from a distribution of empiric t-values and an observed t-value.\n",
    "    \"\"\"\n",
    "    # count the number of simulated t-values that are as extreme or more extreme than the critical t-value\n",
    "    extreme_count = np.sum(np.abs(sim_t_values) >= observed_t_value)\n",
    "\n",
    "    # divide the number of extreme values by the total number of simulated values to get the empirical p-value\n",
    "    empirical_p = extreme_count / len(sim_t_values)\n",
    "\n",
    "    return empirical_p\n",
    "\n",
    "def process_voxel(i):\n",
    "    #Do not calculate on zero values as intercept will be applied in the regressoin\n",
    "    if np.sum(prepped_matrix.iloc[i,:]) != 0:\n",
    "        #Assign a temporary dataframe with values that the statsmodels model is expecting\n",
    "        ##the plan is to use patient ID to intersect the voxelwise data to the associated clinical data\n",
    "        temp_df = data_df.copy()\n",
    "        #Names of the columns are as per data_df. The voxel coumn's name is the integer of the voxel\n",
    "        temp_df = temp_df.merge(prepped_matrix.iloc[i,:].transpose(), left_index=True, right_index=True)\n",
    "        #Rename the column of the voxel to 'connectivity' to prepare it for the statsmodels input requirements\n",
    "        temp_df = temp_df.rename(columns={i: \"connectivity\"}, errors=\"raise\")\n",
    "        \n",
    "        #Fit model. Outcomes are always first\n",
    "        results = smf.ols(f'{temp_df.columns[0]} ~ {temp_df.columns[1]}*{temp_df.columns[2]}', data=temp_df).fit()\n",
    "        #Extract the t statistic of relevance from the model at this voxel. Interaction effect is len(indep_vars)+1 (intercept, main1, main2, interaction)\n",
    "        voxel_t_value = results.tvalues[3]\n",
    "        \n",
    "        #Assess the t value against the permutation's distribution \n",
    "        t_value_list = []       \n",
    "        for j in range(permuted_array.shape[2]):\n",
    "            # Assign a temporary dataframe with values that the statsmodels model is expecting\n",
    "            temp_df_permuted = data_df.copy()\n",
    "            #Permute the associated data\n",
    "            temp_df_permuted[temp_df.columns[1]] = np.random.permutation(temp_df[temp_df.columns[1]])\n",
    "            #Retrive the already permuted voxel for all patients at this permutation\n",
    "            temp_df_permuted[temp_df.columns[2]] = permuted_array[i,:,j]\n",
    "            \n",
    "            # Fit model. Outcomes are always first\n",
    "            results_permuted = smf.ols(f'{temp_df_permuted.columns[0]} ~ {temp_df_permuted.columns[1]}*{temp_df_permuted.columns[2]}', data=temp_df_permuted).fit()\n",
    "            # Extract the t statistic of relevance from the model at this voxel. Interaction effect is len(indep_vars)+1 (intercept, main1, main2, interaction)\n",
    "            voxel_t_value_permuted = results_permuted.tvalues[3]\n",
    "            t_value_list.append(voxel_t_value_permuted)\n",
    "            \n",
    "        #Calculate the p-value from the observed t-value copmared to the empiric permuted distribution of t-values\n",
    "        voxelwise_p_value = calculate_empirical_p(voxel_t_value_permuted, t_value_list)\n",
    "    else:\n",
    "        #If voxel is zero-connectivity, assign zero so as to avoid application of intercept\n",
    "        voxelwise_p_value = 0\n",
    "    return voxelwise_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def calculate_empirical_p(observed_t_value, sim_t_values):\n",
    "    \"\"\"\n",
    "    Calculate empirical p-value from a distribution of empiric t-values and an observed t-value.\n",
    "    \"\"\"\n",
    "    # count the number of simulated t-values that are as extreme or more extreme than the critical t-value\n",
    "    extreme_count = np.sum(np.abs(sim_t_values) >= observed_t_value)\n",
    "\n",
    "    # divide the number of extreme values by the total number of simulated values to get the empirical p-value\n",
    "    empirical_p = extreme_count / len(sim_t_values)\n",
    "\n",
    "    return empirical_p\n",
    "\n",
    "def permutation_testing(matrix_to_test, t_matrix):\n",
    "    '''\n",
    "    The plan will be to create one dataframe which can be used to evaluate. \n",
    "    Permuted age will go in the first column\n",
    "    Connectivity will be transposed and attached to the second column\n",
    "    the 'connectivity' column name will move for every voxel and the t value will be calculated\n",
    "    \n",
    "    args: \n",
    "    matrix_to_test is the isolated prepared dataframe to utilize.\n",
    "    t_matrix is the pre-calculated matrix of t values from the non-permuted brains\n",
    "    \n",
    "    performs:\n",
    "    Will calculate t-value for each voxel. Then, it will assess if the t-value is less than the t-value from the non-permuted brain\n",
    "    If the permuted t-value is less than the t-value from the non-permuted brain, then that voxels is set to 0. \n",
    "    \n",
    "    returns:\n",
    "    simply a binary matrix of 1s and 0s\n",
    "    '''\n",
    "    print('in function')\n",
    "    #Permute outcomes\n",
    "    permuted_outcomes = np.apply_along_axis(np.random.permutation, 0, matrix_to_test[:,0])\n",
    "    \n",
    "    #Permute the age\n",
    "    permuted_age = np.apply_along_axis(np.random.permutation, 0, matrix_to_test[:,1])    \n",
    "    \n",
    "    #Permute the Voxels across and within patients (PALM default)\n",
    "    permuted_across = np.apply_along_axis(np.random.permutation, 0, matrix_to_test[:,2:])\n",
    "    permuted_within = np.apply_along_axis(np.random.permutation, 1, permuted_across)\n",
    "    print('permutations complete')\n",
    "    #Reconstruct a dataframe\n",
    "    permuted_dataframe = pd.DataFrame(np.concatenate((permuted_outcomes.reshape(-1, 1), permuted_age.reshape(-1, 1), permuted_within), axis=1))\n",
    "    print('dataframe completed')\n",
    "    #Perform calculation of t values for each voxel\n",
    "    permuted_t_values = []\n",
    "    for i in tqdm(range(len(t_matrix)), desc='Subprocess Progress'):\n",
    "        print('on loop ', i)\n",
    "        #The dataframe has the structure: outcome, age, voxels\n",
    "        #Fit the model. Voxel columns must be strings. \n",
    "        results_permuted = smf.ols(f'{permuted_dataframe.columns[0]} ~ {permuted_dataframe.columns[1]}*{permuted_dataframe.columns[i+2]}', data=permuted_dataframe).fit()\n",
    "        permuted_t_values.append(results_permuted.tvalues[3])\n",
    "    \n",
    "    #Binarize permuted t-values by comparison to non-permuted t-values\n",
    "    #Any t-values that are higher are not significant, so that are = 1.\n",
    "    return np.where(permuted_t_values>t_matrix, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prepare data for analysis\n",
    "\n",
    "# Retrieve brain mask\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "t_matrix = t_df.to_numpy()[brain_indices, -1]\n",
    "\n",
    "# Isolate only the values of interest from the associated data\n",
    "matrix_to_test = prepped_matrix.iloc[brain_indices, :]\n",
    "\n",
    "if 'response_df' in locals():\n",
    "    t_df = response_df['t_values_topology'].to_numpy()[brain_indices]\n",
    "else:\n",
    "    print('not found in locals, must import')\n",
    "    t_df = pd.read_csv('/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/response_topology/voxelwise_glm/age_interaction_rios_vtas/t_values_topology/t_values.csv', index_col=None)\n",
    "#index t matrix at last column to make sure no index included \n",
    "t_matrix = t_df.to_numpy()[brain_indices, -1]\n",
    "\n",
    "#Prepare the data for assessment\n",
    "matrix_to_test = data_df.merge(matrix_to_test.transpose(), left_index=True, right_index=True)\n",
    "#Reduce size of data to ease computations\n",
    "matrix_to_test = matrix_to_test.astype(np.float16)\n",
    "\n",
    "n_permutations = 100\n",
    "display(matrix_to_test)\n",
    "# matrix_to_test.to_csv(out_dir+'/t_values_topology/matrix_to_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(t_matrix))\n",
    "print(np.shape(matrix_to_test))\n",
    "# for i in range(len(t_matrix)):\n",
    "#     print(matrix_to_test.columns[i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform analysis\n",
    "from tqdm import tqdm\n",
    "import concurrent\n",
    "from calvin_utils.multiprocessing import whole_brain_permutation_test\n",
    "#----------------------------------------------------------------Do not Touch Below\n",
    "# Multiprocess Results\n",
    "p_matrix = np.ones_like(t_matrix)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    #Begin submitting the masked data to the permutor\n",
    "    results = []\n",
    "    for i in tqdm(range(n_permutations), desc=\"Jobs Launched\"):\n",
    "        #Assign the permuted data to a worker. return the result\n",
    "        result = executor.submit(whole_brain_permutation_test, matrix_to_test, t_matrix)\n",
    "        results.append(result)\n",
    "        \n",
    "        # Limit number of workers at given time to prevent memory pressure issues\n",
    "        # jobs[result] = i #Add job to dict of ongoing jobs\n",
    "        # if len(jobs) > max_jobs-1: #Check number of ongoing jobs\n",
    "        #     completed_jobs, _ = concurrent.futures.wait(jobs.keys(), return_when=concurrent.futures.FIRST_COMPLETED)\n",
    "        #     # Remove the completed job from the dict of ongoing jobs\n",
    "        #     del jobs[completed_jobs.pop()]\n",
    "\n",
    "    progress_bar = tqdm(total=n_permutations, desc=\"Jobs Finalized\")\n",
    "    for i, result in enumerate(concurrent.futures.as_completed(results)):\n",
    "        #Input the permuted data into the array\n",
    "        extracted_p_values = result.result()\n",
    "        p_matrix = p_matrix + extracted_p_values\n",
    "        \n",
    "        #Update visualization\n",
    "        progress_bar.update()\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = pd.DataFrame(p_matrix)\n",
    "p_df.to_csv(out_dir+'/t_values_topology/p_vals_2.csv',index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize PALM Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows recomposition of the PALM results from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "out_dir = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/voxelwise_glm/stim_by_age/palm_results'\n",
    "#data path\n",
    "p_values_dir = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/voxelwise_glm/stim_by_age/10000_summed_f_statp_values.csv'\n",
    "t_values_dir = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/voxelwise_glm/stim_by_age/observed_f_stats.csv'\n",
    "num_perms = 5\n",
    "\n",
    "#import data\n",
    "if 'response_df' in locals():\n",
    "    t_df = response_df['t_values_topology'].to_numpy()[brain_indices]\n",
    "else:\n",
    "    print('not found in locals, must import')\n",
    "    t_df = pd.read_csv(t_values_dir, index_col=None)\n",
    "p_df = pd.read_csv(p_values_dir, header=0, index_col=None)\n",
    "\n",
    "#Scale the p_values\n",
    "print('---Information on p-Values---')\n",
    "print('Nonzero p_values found: ', np.count_nonzero(p_df[p_df.iloc[:,-1] < 0.05]))\n",
    "print('Lowest p_values: ', np.min(p_df.iloc[:,-1]))\n",
    "display(p_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle NANs or Unclean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.dropna(inplace=True)\n",
    "p_df.dropna(inplace=True)\n",
    "t_df.pop('Unnamed: 0')\n",
    "t_df.max()\n",
    "p_df.max()\n",
    "# t_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unmask the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.matrix_utilities import unmask_matrix\n",
    "from nilearn import masking, image\n",
    "from nimlab import datasets as nimds\n",
    "from nilearn import image\n",
    "\n",
    "mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "\n",
    "#Insert \n",
    "p_unmasked = np.copy(mask_data)\n",
    "p_unmasked[brain_indices] = p_df.values.flatten()\n",
    "print(np.max(p_unmasked))\n",
    "\n",
    "other_unmasked = np.copy(mask_data)\n",
    "other_unmasked[brain_indices] = t_df.values.flatten()\n",
    "print(np.max(other_unmasked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask statistic of interest by p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold by p_values\n",
    "other_unmasked = np.where(p_unmasked < 0.05, other_unmasked, 0)\n",
    "print(np.max(p_unmasked))\n",
    "print(np.max(other_unmasked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Statistic of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_unmasked_img = view_and_save_nifti(other_unmasked, out_dir=(os.path.join(out_dir, f'palm_statistic_topology')))\n",
    "other_unmasked_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Base Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = view_and_save_nifti(other_unmasked, out_dir=(os.path.join(out_dir, f'unmasked_statistic_topo')))\n",
    "base_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "r_path = ''\n",
    "r2_img = image.load_img(r_path)\n",
    "r2_img_data = r2_img.get_fdata().flatten()\n",
    "r2_masked = np.where(p_unmasked < 0.05, r2_img_data, 0)\n",
    "\n",
    "masked_r2_img = view_and_save_nifti(r2_masked, out_dir=(os.path.join(out_dir, f'masked_r2')))\n",
    "masked_r2_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "adjr_path = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/voxelwise_glm/stim_by_age/adj_r_squared_generated_nifti.nii'\n",
    "adjr2_img = image.load_img(adjr_path)\n",
    "adjr2_img_data = adjr2_img.get_fdata().flatten()\n",
    "adjr2_masked = np.where(p_unmasked < 0.05, adjr2_img_data, 0)\n",
    "\n",
    "masked_adjr2_img = view_and_save_nifti(adjr2_masked, out_dir=(os.path.join(out_dir, f'masked_adjr2')))\n",
    "masked_adjr2_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
